%!TEX root = ../Thesis_example_compile_this.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Network Model of Regionalization Framework}
\label{ch:03framework}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This chapter introduces the \gls{NMR} paradigm and the framework for generating non-Gaussian spatial fields. The main idea of the \gls{NMR} is that capturing non-Gaussian spatial features requires reproduction of high-order statistics. Reproduction of high-order statistics should also reproduce two-point statistics such as the variogram. Multi-point measures of connectivity can be easily calculated from drillholes by considering them as sequences. The \gls{NMR} is ultimately a function that maps an unknown latent space to an interpretable observed space. The mapping of the latent space generates a univariate, but not multivariate, Gaussian spatial distribution with the correct high-order statistics. Inference of this mapping function is an inverse problem as we only observe the output of the system. The chapter begins by discussing inversion problems in a geostatistical context and touches on the relevant considerations for inversion problems. Next, connectivity and non-Gaussianity are discussed. Multi-point measures of spatial connectivity, like distributions of runs, are a core component of the \gls{NMR} framework. Measures of connectivity are critical in the context of extreme values; the spatial arrangement of these values are likely significant with respect to a transfer function. Connectivity of extremes may drive the project economics in some mining scenarios. Finally, an overview of the \gls{NMR} methodology is presented with a \gls{2D} synthetic example highlighting improved resources relative to \gls{SGS}.


\FloatBarrier
\section{Inverse Problems}
\label{sec:03inverse}

Inverse problems encompass a broad class of problems where the objective is to infer the underlying causes or parameters of a system from observed data or measurable outputs. These problems arise in various scientific disciplines, including physics, engineering, geosciences, medical imaging, and more. Geospatial inverse problems are common in both the fields of geophysics \citep{linde2015geological} and hydrogeology \citep{zhou2014inverse} where the underlying geologic model is unknown, however a set of measured responses, such as density or seismic properties, are known. The inverse problem involves inferring interpretable geologic properties of the unknown model, such as lithology or porosity, that satisfy the observed measurements. The process of solving inverse problems involves constructing a mathematical model that describes the relationship between the unknown parameters and the observed data; then using this model to infer the unknown parameters. A major challenge of inverse problems is ill-posedness, or the lack of unique solution \citep{tarantola2005inverse}. It is possible that there are multiple (or infinite) solutions that are valid given the observed data. As an exact solution is rarely possible in natural systems, one looks for possible solutions that are close to actual observations \citep{bardossy2016random}. For this reason many inverse problems are framed as an optimization problem, minimizing an objective function relevant to the problem at hand \citep{giraud2019integration,nava-flores2023high,athens2022stochastic}.






Due to the inherent complexity and potential non-uniqueness of these problems, careful consideration of data quality, noise, and computational stability is essential to obtain meaningful and reliable solutions.

\begin{enumerate}
    \item something about the forward problem
    \item prior knowledge is the specification of the pool
    \item prior knowledge is the conceptual geologic model
\end{enumerate}

\subsection{Inversion Considerations}
\label{subsec:03invconsider}


\FloatBarrier
\section{Connectivity and Non‐Gaussianity}
\label{sec:03connect}

A sequence is a collection of elements where the order of the elements matters. The arrangement or order of the elements can be used to characterize the connectivity within the sequence. A drillhole represents a one-dimensional sequence of real numbers in a geostatistical context. Connectivity of high and low values is often of practical importance, mainly when the transfer function is sensitive to extreme values. A one-dimensional sequence provides access to data-driven multiple-point configurations or patterns that would be difficult to infer in two- or three-dimensions. Connectivity is a different way of measuring correlation within a sequence. Each drillhole can be considered an exhaustive, one-dimensional training image from which $n\text{-point}$ statistics can be inferred.

A natural extension of this concept is the analysis of runs of binary sequences from linear strings of data \citep{ortiz2003characterization}. A binary sequence is either 0 or 1 and is achieved through the indicator transform of a continuous \gls{RV}. For a given threshold $z_{k}, \ k=1,\dots,K$:
\begin{equation}
    I(\mathbf{u}_{i};z_{k}) =
    \begin{cases}
        1, & \text{ if }z(\mathbf{u}_{i}) \leq z_{k} \\
        0, & \text{ otherwise }                      \\
    \end{cases}
    \label{eq:indicator}
\end{equation}

It is common to consider multiple thresholds resulting in multiple binary sequences. A run of length $L$ is defined as $L$ identical values bound on either end by an opposite value. Runs of consecutive values above or below the threshold can be assessed. The theory of the distributions of runs for random uniform sequences is well documented by \cite{mood1940distribution}; the moments of the distribution of runs have analytical expressions, and it is shown that the limit distributions are normal. Though useful in many applications like cryptography and random number generation \citep{rukhin2010statistical}, the assumption of independence between elements in the sequence is limiting in the spatially correlated scenario.

\cite{ortiz2003characterization} shows that the analytical derivation of multi-point events is only possible when the multivariate spatial law is known. Practically, this is either the random or multivariate Gaussian case. A run of length $L$ above a threshold $z_{k}$ consists of $L+2$ elements where the first and last elements are below the threshold. In the general case, the probability of a run of length $L$ is defined as:
\begin{align}
    \begin{split}
        P\{\text{run L}\} & =                                                                                                                                                                \\
                          & P\{Z(\mathbf{u}) \leq z_{k}| Z(\mathbf{u + h}) > z_{k},\dots, Z(\mathbf{u} + L \cdot \mathbf{h}) > z_{k}, Z(\mathbf{u} + (L+1)) \leq z_{k}\} \cdot ,\dots, \cdot \\
                          & P\{Z(\mathbf{u} + L \cdot \mathbf{h}) > z_{k} | Z(\mathbf{u} + (L+1)) \leq z_{k}\} \cdot                                                                         \\
                          & P\{Z(\mathbf{u} + (L+1)) \leq z_{k}\}
    \end{split}
\end{align}

The separation distance between elements is $\mathbf{h}$. This definition amounts to a recursive application of Bayes' Law to determine the joint probability of the multiple-point event. In the multivariate Gaussian case, the conditional probabilities are calculated using simple indicator kriging \citep{journel1989nongaussian}. With correlated sequences, the range of correlation influences the frequencies of runs. As correlation increases, there are fewer short runs and more long ones relative to random \citep{ortiz2003characterization}.

Correlated Gaussian sequences with an arbitrary covariance structure can be easily generated using any stochastic simulation algorithm and the indicator formalism of Equation~\ref{eq:indicator}. The total number of runs and frequencies of run lengths can be determined experimentally for the multivariate Gaussian scenario. If the covariance structure of the Gaussian realizations matches that of the true one-dimensional drillhole sequence, multiple-point run-based statistics could be used to measure non-Gaussianity. Section \ref{subsec:03ngmeasures} presents this idea further. If the number or frequency of runs in the data deviates significantly from the Gaussian case, one may investigate the sequence as non-Gaussian. These measures can provide insight into domain sub-regions that exhibit non-Gaussian behaviour and warrant further investigation. Run based measures of connectivity in the following sections provide access to high-order statistics to characterize non-Gaussianity.

\FloatBarrier
\subsection{Distribution of Runs}
\label{subsec:03runs}

Multiple-point statistics characterize the spatial relationship between multiple points. In contrast to two-point statistics, such as the variogram, multiple-point statistics can reproduce curvilinear features and more complex ordering \citep{guardiano1993multivariate}. Runs are one-dimensional patterns or a type of multi-point statistic that can be applied to data sequences like drillholes \citep{boisvert2007multiplepoint}.

Binary sequences are generated by applying the indicator formalism to linear, one-dimensional drill strings (Figure~\ref{fig:gauss_indicators}). This transform characterizes each element in the sequence as a binary event relative to thresholds $z_{k}, \ k=1,\dots,K$. It is assumed that the elements in the sequence are equidistant; that is, the drillhole has been composited. Multiple-point configurations such as runs can then be extracted from the sequences. In practice, one may have to adapt tolerances such that statistics are inferred from approximately linear or equidistant sequence elements \citep{ortiz2003characterization}.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.5, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/gauss_indicators.png}
    \caption{Indicator transform of a Gaussian \gls{RV} using the 0.1, 0.5, and 0.9 quantiles as thresholds. }
    \label{fig:gauss_indicators}
\end{figure}

Runs are calculated in a cumulative or ``overlapping'' fashion. That is, one run of 3 is also two runs of 2 and three runs of 1; Figure~\ref{fig:cumulative_runs} shows this nesting. This generalizes to a run of length $L$ being $i$ runs of length $L-i+1, \ i=1,\dots,L$. This cumulative approach accounts for the dependence between overlapping runs within the sequence \citep{mood1940distribution}. Considering cumulative runs generates a histogram of run lengths that decreases as run lengths increase. This controls long runs as a long run contains elements for all shorter runs \citep{ortiz2003characterization}.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.4, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/cumulative_runs.png}
    \caption{Example of lower-order runs for a single run of 3. One run of 3 is also two runs of 2 and three runs of 1.}
    \label{fig:cumulative_runs}
\end{figure}

It is interesting to note that the indicator transform results in nested sequences. Sequences that are above the current threshold are also above any lower threshold. Figure~\ref{fig:gauss_indicators} illustrates this concept where all sequences above (zeros) the 0.9 quantile are nested within a sequence above the 0.5 quantile, which is nested within a sequence above the 0.1 quantile. \cite{ortiz2003characterization} uses this property of sequences to simulate hierarchically as a run at one threshold can be used to condition the next threshold.

\FloatBarrier
\subsection{\textit{N}-point Connectivity Function}
\label{subsec:03npoint}

Connectivity of extreme values is commonly discussed as a shortcoming of a Gaussian \gls{RF} model \citep{journel1993entropy,journel1989nongaussian}. The maximum entropy characteristic of the Gaussian \gls{RF} model leads to maximum disorder for a given covariance structure; it does not allow for spatial correlation or connectivity of extreme quantile indicators \citep{journel1989nongaussian}. Furthermore, the nature of the bivariate Gaussian relationship leads to symmetric destructuring of the indicator variogram about the median. In practice, natural non-Gaussian distributions show asymmetric destructuring of indicator variograms \citep{vincent2021multipleindicator} and correlation need not approach zero as $z_{k}$ approaches an extreme quantile \citep{journel1989nongaussian}.

Connectivity within in sequence can be quantified by a connectivity function \citep{renard2011conditioning}. Two-point connectivity is characterized by the expected value of the product of indicators $I(\mathbf{u}; z_{k})$ and $I(\mathbf{u}+\mathbf{h}; z_{k})$. The $n\text{-point}$ connectivity function, proposed by \cite{journel1989nongaussian}, in a given direction can be generalized as the expected value of the product of $n$ indicators where the lag distance $\mathbf{h}$ is the distance between sequence elements:
\begin{equation}
    \psi_{z_{k}}(n;\mathbf{h}) = E\left\{\prod_{j=1}^{n} I(\mathbf{u} + (j-1)\mathbf{h}; z_{k})\right\}
    \label{eq:npt}
\end{equation}

The $n\text{-point}$ connectivity function describes the probability of $n$ successive elements in the sequence being jointly \emph{below} the threshold $z_{k}$. To consider the probability of being jointly \emph{above} the threshold $z_{k}$, Equation \ref{eq:npt} becomes:
\begin{equation}
    \psi_{z_{k}}(n;\mathbf{h}) = E\left\{\prod_{j=1}^{n} 1 - I(\mathbf{u} + (j-1)\mathbf{h}; z_{k})\right\}
    \label{eq:npt2}
\end{equation}

\cite{journel1989nongaussian} show that the $n\text{-point}$ connectivity function for a \gls{RV} with connected extreme values simulated with a Gaussian \gls{RF} model is much less than the true connectivity. Figure~\ref{fig:npt_connectivity} shows an example of an $n\text{-point}$ connectivity function for a non-Gaussian one-dimensional string data (red) and a Gaussian realization of the same string (gray). The Gaussian realizations are generated with LU matrix simulation \citep{davis1987production} and have the same covariance structure as the non-Gaussian string. The $n$-point connectivity function shows the probability of connected steps within the Gaussian realizations is less than the non-Gaussian data for the first 20 steps.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.7, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/npt_connectivity.png}
    \caption{$n$-Point connectivity function for a string of non-Gaussian data (red) and the expected value of Gaussian realizations (gray) with the same covariance structure.}
    \label{fig:npt_connectivity}
\end{figure}

As properties of the Gaussian \gls{RF} model lead to maximum disorder, one could use a connectivity measure to assess non-Gaussianity from sequences. The idea is that a Gaussian \gls{RV} would have a different distribution of runs relative to a non-Gaussian \gls{RV}. The multi-point spatial arrangement would differ depending on the underlying \gls{RV}. \Glspl{RV} with more connectivity, will have fewer but longer runs. This connectivity concept applies to sequences with structured extreme values that are not well fit by a Gaussian distribution. It seems reasonable to assume there is some degree of connectivity of extremes in mineral systems; the underlying spatial phenomena are not entirely disorganized.

It is notable that the $n\text{-point}$ connectivity function considering runs \emph{above} the threshold (Equation \ref{eq:npt2}) is analogous to cumulative run-length frequencies of runs above the threshold scaled to the fraction of total elements in the sequence. Considering the $n\text{-point}$ connectivity function above a quantile results in the same measure as considering the cumulative run-length frequency above that same quantile.

\FloatBarrier
\subsection{Measures of Non‐Gaussianity}
\label{subsec:03ngmeasures}

Four measures of non-Gaussianity are proposed. Three based on the concepts of runs and connectivity within drill string sequences, and one based on the volume-variance relation:
\begin{enumerate}[noitemsep]
    \item Total Runs: the total number of unique runs above or below a particular threshold.
    \item Run Length Frequencies: the frequency of cumulative run lengths above or below a particular threshold.
    \item $N$-Point connectivity: the number of connected steps above or below a particular threshold.
    \item Change of Support: the relationship between continuous variance and scale.
\end{enumerate}

The first measure calculates the total number of cumulative runs within the binary sequence. As connectivity within the sequence increases, there are fewer but longer \emph{total} runs. This connectivity translates to a greater number of \emph{cumulative} runs as each longer run contains $\{L-i+1, \ i=1,\dots,L\}$ lower-order runs. It is expected that a non-Gaussian sequence with connectivity of extremes will exhibit a greater number of cumulative runs than a Gaussian sequence. The second measure calculates the cumulative run-length frequencies within the binary sequence. Increased connectivity within the sequence leads to fewer but longer run lengths. Similar to the first measure of total runs, it is expected that a non-Gaussian sequence with connectivity of extremes will exhibit a greater frequency of longer run lengths. The nature of cumulative run lengths leads to a histogram of lengths that decreases as run-length increases, facilitating a more straightforward comparison of distributions. The third measure is the $n\text{-point}$ connectivity of the binary sequence. The $n\text{-point}$ connectivity function quantifies the probability of $n$ successive elements in the sequence being below (or optionally above) the indicator thresholds. Only elements below the threshold contribute to the probability in Equation~\ref{eq:npt}. As connectivity within the sequence increases, the probability of successive elements being jointly below the given threshold increases. It is expected that a highly structured non-Gaussian sequence will have a greater probability of $n$ connected steps compared to a maximum entropy Gaussian sequence as $n$ increases. Figure~\ref{fig:npt_connectivity} highlights this characteristic.

The fourth measure is not sequence based, but rather calculates the change of support for the original continuous variable. This measure is quantified by averaging $n$ consecutive elements within the sequence and calculating the change in variance. As volume increases, the variance of the elements within the sequence decreases. The idea is that if the sequence has structured or connected extreme values, the variance of the sequence should be less sensitive to scale. The more structured the extremes, the less the sensitivity to volume averaging. It is expected that a non-Gaussian sequence with connected extreme values will show a less drastic reduction in variance as scale increases compared to a maximum entropy Gaussian sequence.

To calculate the measure of non-Gaussianity the covariance structure of each sequence is calculated from the exhaustive drill string. This covariance is used to generate multivariate Gaussian realizations with the exact covariance of the original sequence. The Gaussian realizations are back-transformed to original units and indicator transformed with Equation~\ref{eq:indicator}. Each metric is calculated for each one-dimensional data string and compared to the distribution of metrics observed from the Gaussian realizations. The deviation between the original sequence and the Gaussian distribution is used to measure non-Gaussianity. The general workflow for calculating the proposed measures of non-Gaussianity on a drillhole-by-drillhole basis is as follows:
\begin{enumerate}[noitemsep]
    \item Indicator transform all drillholes for given quantiles.
    \item Calculate cumulative runs and run-length frequencies for all thresholds for all drillholes.
    \item Calculate the $n$-point connectivity function for all thresholds for all drillholes.
    \item Down-sample the continuous variable by given scale factors and calculate the variance versus scale curve.
    \item Normal score transform all drillholes.
    \item Calculate the autocovariance matrix for each drillhole and simulate $l=1,\dots,L$ unconditional Gaussian realizations of each drillhole.
    \item Back transform Gaussian realizations to original units.
    \item Repeat steps 1-4 for each realization of each drillhole.
    \item Calculate the score for each measure as $y = \frac{z_{dh}-\mu_{r}}{\sigma_{r}}$ where $z_{dh}$ is the measure from the original drillhole and $\mu_{r}$ and $\sigma_{r}$ are the mean and standard deviation of the distribution of measures from the realizations, respectively.
    \item The final $y$ score is taken as $\lvert y \rvert$ such that only the magnitude, not the sign, is considered.
\end{enumerate}

The $y$ score measures how many standard deviations away from the Gaussian distribution the original drillhole is. Figure~\ref{fig:score} illustrates $y$-score calculation. This score indicates the appropriateness of a Gaussian \gls{RF} model as the Gaussian realizations are simulated with the exact covariance structure of the original drillhole. Any drillhole with a $y$ value greater than 2.5 is considered highly non-Gaussian.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/score.png}
    \caption{Schematic illustrating the calculation of the non-Gaussian Score $y$ where $z_{dh}$ is the metric from the drillhole, and $\mu_{r}$ and $\sigma_{r}$ are the mean and standard deviation of the Gaussian distribution.}
    \label{fig:score}
\end{figure}

Consider a \gls{2D} synthetic example generated from an image of a meandering river system. The RGB colour channels are averaged to generate a grey scale image which is then normalized $\in [0,1]$. The main river channels show highly structured high values relative to the background flood plane and abandoned channels (Figure \ref{fig:non_gauss4_grid}). These features are a natural example of non-Gaussian characteristics in geospatial data. The image is ``drilled'' resulting in 10 drill strings or sequences to calculate measures of non-Gaussianity.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.5, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/non_gauss4_grid.png}
    \caption{Image of a meandering river system sampled in ten locations to generate sequences of pixel data. DHID = drillhole ID, px = pixel. }
    \label{fig:non_gauss4_grid}
\end{figure}

Table \ref{tab:ng_metrics} shows the expected non-Gaussian scores for each sequence across 100 realizations for the 0.1 and 0.9 quantile indicator transforms. As the structured regions are predominantly high-grade, the 0.1 quantile indicators do not show significant non-Gaussianity. Drillholes 5 and 7 show strong non-Gaussianity for all connectivity metrics, while holes 8 and 9 are moderately non-Gaussian. These drillholes intersect structured high-grade river channel in the eastern portion of Figure \ref{fig:non_gauss4_grid} and subsequently exhibit connectivity features above the 0.9 quantile that cannot be reproduced by a multivariate Gaussian \gls{RF}. Abrupt transitions between high- and low-grade regions are difficult to capture with a maximum entropy \gls{RF} that leads to increased connectivity of median values and disconnected extremes.

\begin{table}[!htb]
    \centering
    \caption{Non-Gaussian metrics calculated for 10 drillholes considering the 0.1 and 0.9 quantile indicator transforms. $y$-scores $\geq 2.5$ are considered strongly non-Gaussian. DHID corresponds to Figure \ref{fig:non_gauss4_grid}.}
    \resizebox{1\width}{!}{\input{0-Tables/ng_metrics.tex}}
    \label{tab:ng_metrics}
\end{table}

There is likely a spectrum of non-Gaussianity and the practitioner must decide on appropriate thresholds. The example shows drillholes with strongly non-Gaussian behaviour though no explicit ranges of $y$-scores have been defined. The proposed measures indicate that some regions within the domain have non-Gaussian features. It is intended that these sub-regions be identified for further investigation. The \gls{NMR} is designed to capture these non-Gaussian connectivity measures. The goal of \gls{NMR} is to develop a framework for incorporation of two- and $n$-point statistics. Two-point statistics come from the continuous variogram and some number of indicator variograms, and the $n$-point statistics come from drillhole sequences.


\FloatBarrier
\section{Network Methodology}
\label{sec:method}

Sections \ref{subsec:03runs} and \ref{subsec:03npoint} present methodology for accessing higher-order statistics from drillhole sequences. Section \ref{subsec:03ngmeasures} shows that these statistics can effectively characterize non-Gaussianity. This section presents the overall \gls{NMR} framework and the generation of non-Gaussian spatial fields. Achieving higher-order connectivity is a key component of the \gls{NMR} framework. Two-point, variogram based statistics alone cannot capture the complex multi-point relationships we seek in a non-Gaussian \gls{RF}. The indicator transform of drill strings provides access to binary sequences that permit calculation multi-point connectivity statistics.

% Reproduction of high-order statistics in theory should reproduce all lower-order statistics, however the \gls{NMR} explicitly enforces two- and multi-point statistics.

\FloatBarrier
\subsection{Notation}
\label{subsec:03notation}

An overview of the \gls{NMR} mathematical notation and definitions are shown here, while further details are presented in Chapters \ref{ch:04implement} and \ref{ch:05impute}. Consider a continuous \gls{RF}:
\begin{equation}
    \{Z(\mathbf{u}), \ \forall \mathbf{u} \in \mathcal{D}\}
    \label{eq:zu}
\end{equation}

Where $\mathcal{D}$ is a domain of interest. The location vector $\mathbf{u}$ could be either data or grid node locations. Next, consider a set of $M+1$ latent variables characterized by a Gaussian \gls{RF}:
\begin{equation}
    \{\mathbf{Y}(\mathbf{u}) = (Y_{0}(\mathbf{u}), \dots, Y_{M}(\mathbf{u})), \ \forall \mathbf{u} \in \mathcal{D}\}
    \label{eq:gpool}
\end{equation}

Finally, consider a forward mapping function $\mathcal{F}_{\theta}$ that defines the mapping from the real valued latent space to the real valued observed space:
\begin{equation}
    \{\mathcal{F}_{\theta}: \mathbb{R}^{M} \mapsto \mathbb{R} \}
    \label{eq:fmap}
\end{equation}

Where $\theta$ is a parameter vector that characterizes $\mathcal{F}$, and $\mathcal{F}_{\theta}$ is such that the mapping of the latent space to the observed space reproduces the observed data values:
\begin{equation}
    \{\mathcal{F}_{\theta}(\mathbf{Y}(\mathbf{u})) = Z(\mathbf{u}), \ \forall \mathbf{u} \in \mathcal{D}\}
    \label{eq:ftheta}
\end{equation}

The \gls{NMR} approximates the forward mapping function $\mathcal{F}_{\theta}$. Chapter \ref{ch:04implement} discusses inference of the parameter vector, $\theta$, and Chapter \ref{ch:05impute} presents imputation of the Gaussian \glspl{RF} such that Equation \ref{eq:ftheta} holds true.

\subsection{NMR Inversion}
\label{subsec:03nmrinverse}

The \gls{NMR} approximates the forward mapping function from latent to observed space. The parameters of this function are unknown, and they must be inferred from the available data. The prediction of a response is a forward problem, while the use of a response, or observed measurements to infer the properties of a model is an inverse problem \citep{tarantola2005inverse}. In this context, the observed measurements are drillhole data. The goal is to find the model parameters, $\theta$, such that desired spatial characteristics, and the actual data observations are reproduced.


\begin{enumerate}
    \item to capture uncertainty multiple solutions (realizations) are generated?
    \item approached with optimization, presented in Chapter 4
    \item objective function considers two- and multi-point statistics
    \item considers non-linearity
\end{enumerate}


\FloatBarrier
\subsection{Latent Spatial Structure}
\label{subsec:03latent}

The set of latent Gaussian variables of Equation \ref{eq:gpool} is the foundation of the \gls{NMR}. This set is referred to as the Gaussian ``pool'' throughout this text; the components of the pool are referred to as latent ``factors''. It is a pool in the sense there is a collection of Gaussian \glspl{RF} to be shared with the goal of reproducing high-order statistics. This pooling is analogous to a \gls{GMM} in the spatial context. The idea of a \gls{GMM} is that a continuous distribution (as in Equation \ref{eq:zu}) could be approximated by a finite mixture of Gaussian densities \citep{mclachlan2019finite}. Furthermore, \cite{silva2018multivariate} show that a mixture of Gaussian components is capable of fitting complex non-Gaussian uni- and multivariate distributions. The \gls{NMR} is an extension of this concept; rather than a mixture of Gaussian densities, $Z(\mathbf{u})$ is approximated by a mixture of Gaussian \glspl{RF}. Rather than using the \gls{EM} algorithm to fit the parameters of each Gaussian component \citep{mclachlan2019finite}, $M$ standard Gaussian \glspl{RF}, with covariance structures specified by $\gamma_{m}(\mathbf{h})$, are explicitly chosen. The factors are chosen such that:
\begin{enumerate}[noitemsep]
    \item Latent factors are standard normal: $E\left\{Y_{m}(\mathbf{u})\right\}=0$, \ $E\left\{Y_{m}(\mathbf{u})^{2}\right\}=1, \ \forall \ \mathbf{u}$
    \item Latent factors are independent: $E\left\{Y_{m}(\mathbf{u}_{i})Y_{n}(\mathbf{u}_{j})\right\}=0, \ \ \forall \ m\neq n, \ \forall \ i \neq j$
    \item Latent factors reproduce their respective variogram model $\gamma_m(\mathbf{h}), \ \forall \ \mathbf{h}$
\end{enumerate}
The output of the mapping function $\mathcal{F}_{\theta}$ is a spatial mixture of the latent factor components of $\mathbf{Y}(\mathbf{u})$.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/uncond_f1_f2_grid.png}
    \caption{Unconditional realizations of Gaussian \glspl{RF} with orthogonal directions of continuity.}
    \label{fig:uncond_f1_f2_grid}
\end{figure}

Consider a hypothetical scenario where the modeling goal is to have highly continuous low-grades in the east-west direction and highly continuous high-grade continuity in the north-south direction. This is challenge for a multivariate Gaussian simulation algorithm as a normal score variogram cannot capture both directions of continuity simultaneously. The \gls{NMR} has the ability to draw different spatial structures from different latent factors within the pool; the sharing of structures being a core concept of the \gls{NMR} approach. Consider the \gls{2D} realizations of two unconditional Gaussian \glspl{RF} in Figure \ref{fig:uncond_f1_f2_grid}. It is possible to achieve the modeling goals if we can draw high-grade continuity from factor 1 and low-grade continuity from factor 2. A simple linear combination of the factors, analogous to the \gls{LMC}, is not able to capture the orthogonal continuities as high and low values cancel when combined. What we require is the ability to emphasize the high values in factor 1 (and mute the low values), and the low values in factor 2 (and mute the high values), before performing the mix. This ``extraction'' of specific factor features requires introduction of a non-linearity.


\FloatBarrier
\subsection{Non-Linearity and Mapping}
\label{subsec:03nonlinear}

Emphasizing a portion of a range of values requires the definition of a threshold. Given item (1) in the list above, zero is logical value to threshold a Gaussian distribution. A straightforward approach to introducing non-linearity is the application of a power law function. The non-linear value is the original value raised to a power, $\omega$. If we want to emphasize the high values, all values $> 0$ are raised to the exponent $\omega \geq 1$ while the values $< 0$ are raised to the exponent $\frac{1}{\omega}$. The non-linearity effectively mutes the magnitude of values below zero and exponentially increases values above zero. The opposite is true if we wish to emphasize low values; all values $< 0$ are raised to the exponent $\frac{1}{\omega}$ while the values $> 0$ are raised to the exponent $\omega$, where $\omega < 1$. Figure \ref{fig:powerlaw_f1_f2} shows this power law relationship graphically for the two realizations shown in Figure \ref{fig:uncond_f1_f2_grid} using $\omega_{1}=4$ and $\omega_{2}=0.25$. Where factor 1 is greater than zero, the values $> 1$ are emphasized significantly. Where factor 1 is less than zero, the values $< -1$ are muted significantly. This non-linearity advantageously isolates the high-grade structure from factor 1. The opposite is true for factor 2. The complete details of the non-linearity are presented in Chapter \ref{ch:04implement}.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.5, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/powerlaw_f1_f2.png}
    \caption{Power law relationship between the linear input $y$ and the non-linear output $\phi(y, \omega)$, where $\phi(\dots)$ is the power law function. }
    \label{fig:powerlaw_f1_f2}
\end{figure}

Figure \ref{fig:activate_f1_f2_grid} (left, center) shows the spatial distribution of factors 1 and 2 after applying the power law function. Note the magnitude of the colour bars between the plots. The power law function is able to isolate the desired components of each factor and can be thought of as an ``activation'' function. Figure \ref{fig:activate_f1_f2_stats} (left, center) shows the histograms of factors 1 and 2 after transformation. As expected $\phi(y_{1}, \omega_{1})$ is strongly positively skewed, and $\phi(y_{2}, \omega_{2})$ is strongly negatively skewed. $\phi(\dots)$ results in a distribution of arbitrary activation units. These units are not interpretable and require mapping to an observed space in Gaussian units. Combining the ``activated'' realizations is then a weighted, linear combination, followed by a normal score transform. The weights, for the sake of the example, are $\mathbf{a} = [1,1]$. The final model is then $\mathbf{z} = G^{-1}(\phi(\mathbf{Y}, \boldsymbol{\omega}) \cdot \mathbf{a}^{T})$, where $G^{-1}$ is the inverse of the Gaussian \gls{CDF}.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/activate_f1_f2_grid.png}
    \caption{Factors 1 (left) and 2 (center) after application of the power law function, and the final mapped, normal score transformed realization (right).}
    \label{fig:activate_f1_f2_grid}
\end{figure}

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/activate_f1_f2_stats.png}
    \caption{Histograms of factors 1 (left) and 2 (center) after application of the power law function, and the final mapped, normal score transformed realization (right).}
    \label{fig:activate_f1_f2_stats}
\end{figure}

Figure \ref{fig:activate_f1_f2_grid} (right) shows the spatial distribution of the final model, while Figure \ref{fig:activate_f1_f2_stats} (right) shows the histogram. Note that the spatial distribution is complex and non-multivariate Gaussian, however the univariate histogram is perfectly Gaussian. The high values show north-south continuity while the lows show east-west continuity. The overprinting of the factors appears natural, and the result is spatial structure that cannot be generated with a single variogram model. These steps provide an overview of the forward pass through the \gls{NMR}. In summary, they are:
\begin{enumerate}[noitemsep]
    \item Simulate latent factors to form the Gaussian pool
    \item Activate the factors with $\boldsymbol{\omega}$ to emphasize certain features
    \item Linearly combine the activated factors with weights $\mathbf{a}$
    \item Normal score transform the combination
\end{enumerate}

In practice, parameters $\boldsymbol{\omega}$ and $\mathbf{a}$ are unknown and must be inferred. As discussed in Section \ref{sec:03inverse}, inverse problems are commonly approached by optimization. The optimization problem consists of determining $\boldsymbol{\omega}$ and $\mathbf{a}$ for a given Gaussian pool such that an objective function is minimized. The objective function in this context is the reproduction of desired two- and multi-point statistics in the final model produced by the steps above.

\FloatBarrier
\subsection{Two-Point Statistics}
\label{subsec:03twopt}

Two-point statistics are the experimental normal score, and indicator variograms. The experimental variogram is the expected squared difference between pairs of data separated by lag vector $\mathbf{h}$. Figure \ref{fig:varios_activate_f1_f2} shows the normal score variogram (blue), the 0.1 quantile indicator variogram (black), and the 0.9 indicator variogram (red) of the mapped model in the north-south (left) and east-west (right) directions, respectively. The final model achieves its goals from the perspective of two-point statistics. The indicator variograms show increased low-grade continuity in the east-west direction and high-grade continuity in the north-south direction. The normal score variogram is a blend of the indicator variograms; in the north-south direction it has the continuity of the highs with the cyclicity of the lows, and the range of the lows and cyclicity of the highs in the east-west direction. This blending of directional features further emphasizes how the \gls{NMR} complexity cannot be captured by a single variogram.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/varios_activate_f1_f2.png}
    \caption{Normal score experimental variogram (blue), the 0.1 quantile indicator experimental variogram (black), and the 0.9 indicator experimental variogram (red) of the mapped model in the north-south (left) and east-west (right) directions, respectively.}
    \label{fig:varios_activate_f1_f2}
\end{figure}

An interesting experiment to confirm this hypothesis is to generate a realization with a multivariate Gaussian simulation algorithm using the normal score variogram from Figure \ref{fig:varios_activate_f1_f2} and compare to the final \gls{NMR} model. That is, how visually different are the two realizations though they share the same normal score variogram model. Figure \ref{fig:nmr_sgs_grid} shows the same \gls{NMR} realization from above (left) and a realization generated with \gls{SGS} (right). The \gls{SGS} model uses the same variogram model fitted to the blue experimental variogram in Figure \ref{fig:varios_activate_f1_f2}. The \gls{NMR} and \gls{SGS} models are significantly different, though they share the same two-point covariance structure. The \gls{SGS} model shows less connectivity in both low and high values, and generally shows more disorder. The normal score variogram shows some degree of mixing between the orthogonal structures and cannot adequately capture multiple anisotropies when considering the full range of values. In contrast, the \gls{NMR} isolates a particular covariance structure to values above and below zero.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/nmr_sgs_grid.png}
    \caption{ The final \gls{NMR} model (left) and a \gls{SGS} model generated with the same normal score variogram model. }
    \label{fig:nmr_sgs_grid}
\end{figure}

Beyond two-point statistics, the network approach also considers the multi-point statistics discussed in Section \ref{sec:03connect}. A non-Gaussian \gls{RF} should show increased mulit-point connectivity of extreme values over a Gaussian \gls{RF}. Whether it is connectivity of high or lows depends on the structure of the latent pool and power law exponents, $\omega$.


\FloatBarrier
\subsection{Multi-Point Statistics}
\label{subsec:03multipt}

Consider the \gls{2D} models above as sections, rather than plan view. We can ``drill'' the realizations to generate sequences of data. Sampling the realization results in 32 synthetic drillholes, each with 64 samples. Figure \ref{fig:nmr_sgs_dh_cont_ind} shows the drillhole configuration and the corresponding 0.9 quantile indicator transform for the \gls{NMR} (left) and \gls{SGS} models (right). The direction of continuity of the high-grade factor corresponds with the direction of drilling.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/nmr_sgs_dh_cont_ind.png}
    \caption{ Synthetic drillhole samples and corresponding 0.9 quantile indicator transform for the \gls{NMR} model (left) and the \gls{SGS} model (right).}
    \label{fig:nmr_sgs_dh_cont_ind}
\end{figure}

As expected, the \gls{NMR} model visually shows increased high-grade connectivity. The more structured high-features result in fewer total, but longer connected sequences. The \gls{SGS} model is more disorganized, resulting shorter connected sequences. This visual discrepancy in quantified by the $n$-point connectivity function in Figure \ref{fig:nmr_sgs_grid_runs}. The probability of connection above the 0.9 quantile for the multivariate Gaussian model steeply declines in the first five steps and is effectively zero at seven steps. The probability of connection in the non-Gaussian model decreases at a notably slower rate and remains $> 0$ at 20 connected steps.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/nmr_sgs_grid_runs.png}
    \caption{ $N$-point connectivity function for the 0.9 quantile indicator transform of the drillholes in Figure \ref{fig:nmr_sgs_dh_cont_ind}.}
    \label{fig:nmr_sgs_grid_runs}
\end{figure}

Connectivity measures are calculated globally, that is, considering all drillholes. The primary orientation of drilling is an important consideration when designing latent factors with the goal of high-order connectivity. In practice high grade structures are generally orthogonal to the primary orientation of drilling, so specific factors aligned with the tertiary variogram direction may be required.


\FloatBarrier
\subsection{Latent Imputation}
\label{subsec:03impute}

The previous sections consider the use of unconditional realizations to infer the mapping function $\mathcal{F}_{\theta}$. The ultimate goal is to generate gridded realizations conditional to the observed data that have non-Gaussian spatial features characterized by $\theta$. This requires gridded conditional realizations of each latent factor in the pool. As the latent factors are a synthetic construct of the \gls{NMR} model and not directly observed, they must be imputed \citep{little2019statistical}. The imputed factors have the same conditions listed in Section \ref{subsec:03latent} plus the addition constraint that they must reproduce the observed data (within a specified tolerance) when mapped through $\mathcal{F}_{\theta}$:
\begin{equation}
    \mathcal{F}_{\theta}(\mathbf{y}(\mathbf{u})) = \mathbf{z}(\mathbf{u}) \pm \alpha, \ \forall \mathbf{u}
    \label{eq:ftheta0}
\end{equation}

Where $\alpha$ is a data matching tolerance. A straightforward approach to satisfying Equation \ref{eq:ftheta0} is to simply assign random Gaussian values to the vector $\mathbf{y}(\mathbf{u})$ until the equality is met \citep{silva2018enhanced}. This approach ensures the collocated multivariate relationship between the latent factors is correct, however it does not ensure each regionalized factor has the correct spatial variability. If the imputed latent factors do not have the correct spatial variability defined by the pool, the mapping function $\mathcal{F}_{\theta}$ is no longer valid. Directly sampling the high-dimensional multivariate distribution is difficult, though sampling the marginal conditional distributions is possible. This problem is typically approached by Gibbs sampling \citep{geman1984stochastic} and commonly employed in the truncated Gaussian simulation paradigm \citep{arroyo2020iterative,madani2021enhanced}. Noted Gibbs sampler convergence issues with spatially correlated data motivates the development of a novel imputation algorithm presented in Chapter \ref{ch:05impute}. The algorithm combines components of sequential simulation and rejection sampling to iteratively sample the marginal distributions resulting in latent factors that satisfy Equation \ref{eq:ftheta0} and have the correct covariance structure.

The solution to Equation \ref{eq:ftheta0} is non-unique. There are multiple combinations of latent variables that can reproduce the observed value when mapped. Figure \ref{fig:imputed_scatters_example} shows the relationship between two imputed factors and the observed value, $z(\mathbf{u})$. In this example, if $z(\mathbf{u})$ is high, say 1.5, factor 2 is constrained to be high, however factor 1 can take any value from the range of $[-2.5, 2.5]$. The opposite is true for low values, and factor 1 is constrained. The \gls{NMR} framework utilizes multiple imputation to transfer uncertainty related to non-uniqueness to the final gridded realizations. Multiple latent factor realizations are imputed and each gridded realization is conditioned by a unique data realization.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.8, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/imputed_scatters_example.png}
    \caption{Bivariate scatter plots comparing the observed value, $z$, and factors 1 and 2. The histograms are the marginal distributions of each variable. }
    \label{fig:imputed_scatters_example}
\end{figure}

The complete details of the imputation algorithm and checking latent data realizations are presented in Chapter \ref{ch:05impute}. The algorithm shows stable convergence for spatially correlated variables and correctly reproduces the collocated multivariate relationships and covariance structure of the latent pool.

\FloatBarrier
\subsection{Simulation and Mapping}
\label{subsec:03simulate}

After imputation of all latent factors at the data locations, they can be conditionally simulated at grid node locations. Any conditional simulation algorithm is valid; different algorithms could be used for different structures depending on the range of correlation, structure type and anisotropies \citep{pinto2020independent}. Once the latent factors are defined at all grid nodes, the gridded realization are mapped from latent to observed space with $\mathcal{F}_{\theta}$. The mapping function includes a normal score transform based on a reference distribution of activation values output by the network. The corresponding normal score values of these activations are used as a transform table to transform the gridded realizations to Gaussian units.

After transformation to observed space, the gridded \gls{NMR} realizations should reproduce all specified two- and multi-point spatial features while being univariate Gaussian. Transforming the realizations to original units is simply the inverse of the normal score transform. Chapter \ref{ch:05impute} presents further details regarding the checking and validation of both latent and mapped gridded realizations.


\FloatBarrier
\section{Effects of High-Order Continuity}
\label{sec:03effect}

The \gls{NMR} framework permits a flexible approach to continuous simulation in the presence of non-stationary geologic domains. One can design latent factors to account for difference between background and high-grade mineralization or changes in the orientation of continuity if sub-domains cannot be defined. The flexibility of the latent pool is advantageous, providing $M \cdot 7$ orientation, range and covariance structure parameters, compared to the 7 of a single variogram model in a traditional multivariate Gaussian simulation algorithm. The following section presents a small synthetic, non-stationary example to highlight the effect of multi-point connectivity on expected mineral resources. \Gls{NMR} resources are contrasted against those from \gls{SGS}.

The reference truth comes from a natural image of fork lightning, rotated 90 degrees. The image is chosen as it exhibits narrow, highly connected, high value dendritic features with abrupt changes in grade between the lightning and the background features. It is reasonable to suggest similarities exist between the image and narrow vein type mineral deposits. The image is rotated 90 degrees so the synthetic drillholes are roughly orthogonal to the lightning structures. The \gls{RBG} colour channels are averaged generating a gray scale image. The gray scale image is normalized $\in [0, 1]$ and then transformed to a log-normal distribution with a $\mu = 1$ and $\sigma = 2$. Data with a \gls{CV} of 2 is common in mineral systems with positively skewed distributions, such as precious metals. 20 synthetic drillholes are sampled from the image, extracting every third pixel, resulting in 1560 total samples. Figure \ref{fig:lightning_dhs} shows the reference image (left) and the synthetic drillhole configuration (right). The drillhole data is strongly non-stationary; the high grade features are vertically continuous in some areas and horizontally in other areas. The dip of the structures also changes locally. The goal of the \gls{NMR} model is to capture these non-stationary features and correctly characterize the connectivity of high and extreme values observed in the true image. Though synthetic, this scenario provides an excellent opportunity to highlight the capabilities of the \gls{NMR}.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.5, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/lightning_dhs.png}
    \caption{The non-stationary reference truth image of fork lightning (left) and the drillhole samples extracted from the image (right). }
    \label{fig:lightning_dhs}
\end{figure}

The normal score variogram model plus two additional highly anisotropic factors comprise the Gaussian pool. The normal score variogram model exhibits strong zonal anisotropy where the range in the direction parallel to the sampling is larger than the domain size. The first of the highly anisotropic factors is oriented 100 degrees with a $10:1$ anisotropy ratio and the second is oriented 45 degrees with a  $5:1$ anisotropy ratio. The normal score variogram factor is free to influence any grade range with $\omega \in [0.25, 4.0]$ while the additional factors are constrained to influence high values with $\omega \in [2.0, 4.0]$. The idea is that the first factor can capture the orientation of medium to high-grade values while factors two and three capture the orientation of the highest-grade structures. The mapping function, $\mathcal{F}_{\theta}$, is inferred by minimizing the sum of squared errors between the objective function components and the two and multi-point statistics extracted from the synthetic data. Complete details of the objective function and optimization algorithm are given in Chapter \ref{ch:04implement}. 100 realizations of each latent factor are imputed at the data locations such that Equation \ref{eq:ftheta0} holds true using $\alpha = 0.01$. Once the latent factors are defined at the data locations, they are conditionally simulated on 1 x 1 pixel point scale grid using \gls{SGS}. The point scale latent realizations are mapped through the same function resulting in a univariate Gaussian spatial mixture with features characterized by $\theta$.

The point scale realizations are back transformed from Gaussian to original units and block averaged to a 5 x 5 pixel \gls{SMU} scale grid. The \gls{SMU} scale realizations post processed to calculate the e-type mean. Figure \ref{fig:lightning_indicators} shows the block averaged reference truth (top left) and corresponding 0.9 quantile indicator transform (bottom left), with the \gls{SMU} scale \gls{NMR} e-type model and indicators (top middle, bottom middle), and the \gls{SMU} scale \gls{SGS} e-type model and indicators (top right, bottom right). An outcome of correctly characterizing the point scale, high-grade continuity is the \gls{SMU} scale realizations should appear more connected. As discussed in Section \ref{subsec:03ngmeasures}, disordered realizations are more sensitive to changes in scale; connected or organized features should remain as scale increases. The is evident in the 0.9 quantile indicator transform of the \gls{NMR} e-type model. The indicator model exhibits increases east-west high grade continuity over the \gls{SGS} model, particularly in the central and top portions of the grid. The \gls{SGS} model effectively captures the vertical high-grade continuity however the east-west structures are visibly more disconnected.

\begin{figure}[htb!]
    \centering
    \includegraphics[scale=0.6, max size={\textwidth}{\textheight}]{./0-Figures/03-Ch03/lightning_indicators.png}
    \caption{The reference truth block averaged to a 5 x 5 pixel \gls{SMU} (top left) and corresponding 0.9 quantile indicator transform (bottom left), with the \gls{SMU} scale \gls{NMR} model and indicators (top middle, bottom middle), and the \gls{SMU} scale \gls{SGS} model and indicators (top right, bottom right)}
    \label{fig:lightning_indicators}
\end{figure}

Table \ref{tab:lightning_resources} summarizes the resources of the \gls{SMU} scale \gls{NMR} and \gls{SGS} models above the 0.1, 0.5, and 0.9 quantiles as a fraction of true resources. The resources assume the synthetic variable is measured in grams per metric tonne, priced in troy ounces, and density is a constant value of $2.6 g/cm^{3}$. The \gls{NMR} and \gls{SGS} models show similar resources for the 0.1 and 0.5 quantile cutoffs; however the  \gls{NMR} model shows improvement in both tonnes and grade above the 0.9 quantile cutoff, leading to a 9\% increase in contained metal ounces relative to the \gls{SGS} model. The increase in tonnes above the true 0.9 quantile is attributed to the increase in east-west continuity imparted by factors two and three. A single covariance model considering the complete range of grade values cannot effectively capture the non-stationary features of the true image.

\begin{table}[!htb]
    \centering
    \caption{\Gls{SMU} scale resources above the 0.1, 0.5, and 0.9 quantiles as a fraction of the true resources. Cutoff values are calculated from the true image. g/t=grams per tonne.}
    \resizebox{1\width}{!}{\input{0-Tables/lightning_resources.tex}}
    \label{tab:lightning_resources}
\end{table}

Drill hole data may exhibit non-Gaussian features that are difficult to capture with a single covariance model based on two-point statistics. The \gls{NMR} model permits generating multiple realizations that consider both two- and multi-point statistics present in the observed data. These considerations allow for extreme values that are more structured than what is possible with a multivariate Gaussian simulation algorithm. This small example emphasizes the importance of the connectivity of extreme values with respect to \gls{SMU} scale resources. Correctly characterizing the connectivity of extremes has a significant impact on the contained metal of a resource estimate.

\FloatBarrier
\section{Discussion}
\label{sec:03discuss}