%!TEX root = ../Thesis_example_compile_this.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusions and Future Work}
\label{ch:07conclusions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The connectivity of extreme values is of great practical importance. In most real-world scenarios, transfer functions are sensitive to extreme values, and correctly characterizing their two- and multi-point spatial connectivity can have significant downstream impacts. A small proportion of extreme gold grades may be the economic foundation of a mine, while extremely low permeability facies may preclude the production of a hydrocarbon reservoir. The geologic processes responsible for generating these features are not completely disorganized; strings of connected extreme values exist in nature are likely the most consequential spatial features. Traditional estimation and simulation algorithms are maximum entropy models based on multivariate Gaussian assumptions. Though practical from a dimensionality perspective, using Gaussian \glspl{RF} smooths high grades and tends toward disconnected extreme values. These reasons motivate the development of the \gls{NMR} framework. A mixture of Gaussian \gls{RF} components may result in a highly non-Gaussian \gls{RV}. The \gls{NMR} exploits this idea while considering high-order connectivity measures from strings data and the potential spatial asymmetry between extreme highs and lows.


\FloatBarrier
\section{Summary of Contributions}
\label{sec:07contrib}

The main contribution of this thesis is the development of the \gls{NMR} framework for simulating continuous non-Gaussian spatial fields. The framework includes important contributions to quantifying non-Gaussianity from spatial data and multiple imputation for latent Gaussian factors.

\subsection{Extreme Value Connectivity}
\label{subsec:07connect}

The connectivity of extreme values is an important metric for understanding the potential shortcomings of multivariate Gaussian models. Extracting multi-point connectivity measures from drill strings is not a new idea \citep{ortiz2003characterization,boisvert2007multiplepoint}; however, using the $n$-point connectivity function and distribution of runs to calculate a proxy for non-Gaussianity is a contribution of this thesis. This non-Gaussianity metric can provide valuable insight into spatial regions poorly modeled by a Gaussian \gls{RF}. These regions could be sub-domained or simply warrant further investigation.

Extreme value connectivity is a defining feature of the \gls{NMR} framework that sets it apart from traditional multivariate Gaussian simulation algorithms. Introducing high-order statistics to the mixing model overcomes the maximum entropy characteristics of a Gaussian \gls{RF}. It is shown that generating \gls{NMR} realizations with explicit consideration of extreme value connectivity results in spatial connectivity features that a traditional algorithm cannot reproduce. The $n$-point connectivity function and distribution of runs provide straightforward access to high-order statistics without using a training image.

\subsection{Network Model of Regionalization}
\label{subsec:07nmr}

The \gls{NMR} is a material contribution to this thesis. It expands the \gls{LMR} concept for univariate spatial modeling. Both models construct a random function as a combination of independent, standard normal factors, each with its basic covariance model operating at different spatial scales. The key difference with the \gls{NMR} is that the combination of factors is not limited to be linear. Activation of the latent factors with a novel \gls{MPL} function prior to the linear combination permits the spatial structure of certain features to be imparted on the distribution's tails. Traditionally, the \gls{LMR} is limited to four or five factors, while there is no practical limit with the \gls{NMR}. This flexibility allows the creative mixing of latent covariance structures, achieving complex modeling goals. Structures with various anisotropies and orientations can be combined to reproduce non-stationary features. A key concept of the \gls{NMR} is that a mixture of Gaussian factors can be highly non-Gaussian.

The \gls{NMR} is parameterized by $2 \cdot (M+1)$ parameters: $M+1$ weights and $M+1$ power law exponents. Inference of these parameters is an inverse problem. The spatial features of the observed data are known. However, the parameters that map the latent space to the observed space are unknown—framing this as an optimization problem permits using a multi-component objective function. Through this objective function, the \gls{NMR} gains the ability to reproduce statistics beyond the second order. Two- and multi-point statistics are introduced directly through the optimization process. The network parameters are optimized such that the \gls{NMR} output has the correct continuous and indicator variogram models, $n$-point connectivity function, and distributions of runs. The \gls{NMR} approximates the non-linear mapping function between the latent factor space and the observed data space. The approach is highly flexible, with no limitations on the number of latent factors or objective function components. The \gls{NMR} is an important contribution to geostatistics, particularly for continuous simulation of high-order connectivity features.

\subsection{Sequential Gaussian Rejection Imputation}
\label{subsec:07sgri}

\Gls{SGRI} is a novel algorithm for multiple imputation of latent factors within the \gls{NMR} framework and is a practical alternative for the Gibbs sampler. The algorithm is designed to overcome Gibbs sampler convergence issues with spatially correlated data \citep{silva2018enhanced}. \Gls{SGRI} combines elements of \gls{SGS} and rejection sampling to impute spatially correlated latent variables that reproduce data observations when mixed through the \gls{NMR}. The algorithm directly samples all univariate conditional distributions of the $M$-dimensional latent distribution until the mapped value is within a specified tolerance. Sampling the conditional distributions ensures variogram reproduction. Next, each sampled value is iteratively perturbed until the mapped value matches the observed value. The algorithm rejects samples anytime they do not improve the solution. Iterative refinement of the solution ensures the collocated multivariate relationships are correct while still honouring the spatial covariance structure of each factor.

When constrained and unconstrained, the algorithm shows stable convergence, correctly reproducing factor variogram models and collocated multivariate relationships. \Gls{SGRI} is a notable contribution concerning latent imputation. One could adapt it (with an appropriate mapping function) to truncated Gaussian categorical modeling techniques such as hierarchical truncated pluri-Gaussian simulation.

\subsection{Simulation of Continuous High-Order Features}
\label{subsec:07hosim}

The complete \gls{NMR} framework for the continuous simulation of high-order spatial features consists of the \gls{NMR} forward model and the \gls{SGRI} algorithm. This framework is the primary contribution of this thesis. The \gls{NMR} methodology is developed to overcome the maximum entropy characteristic of multivariate Gaussian \glspl{RF}. The \gls{NMR} permits the simulation of continuous variables with connectivity features beyond the second order. These multi-point spatial connectivity features are critical when characterizing the continuity of extreme values. A key differentiator from existing high-order simulation methodologies \citep{mustapha2011hosim} is that the \gls{NMR} framework does not require a training image. All high-order statistics are extracted from strings of drillhole data and embedded in the parameterization of the latent-observed mapping function. The order of these statistics is practically limited by drillhole length; however, conceptually, the $n$-point connectivity function can consider any number of steps $n$. Another key component is that the \gls{NMR} framework leverages the simplicity of the Gaussian \gls{RF} model for generating non-Gaussian spatial structures. This spatial Gaussian mixture model concept simplifies the implementation of the framework as both unconditional and conditional Gaussian realization can be generated with any algorithm.

Imputation of latent factors proceeds after defining all parameters of the \gls{NMR}. Considering the mapping function during imputation ensures that the latent factors used for conditioning have the correct spatial features. Finally, mapping the gridded latent realizations to observed space with the \gls{NMR} ensures the models reproduce all target two- and multi-point statistics. Practical considerations for inference of \gls{NMR} parameters are discussed in detail, including (1) latent factor design, (2) \gls{MPL} activation function parameterization, (3) objective function design, (4) potential non-uniqueness of the solution, and (5) checking of forward model outputs. A detailed discussion of the practical aspects of latent imputation is also provided, including the minimum acceptance criteria for imputed realizations. Examples show the \gls{NMR} framework can effectively characterize multi-point high-grade connectivity features in a range of two- and three-dimensional scenarios, with the ability to adapt to highly non-stationary domains. The framework is demonstrated on a dataset from a producing underground mine, where the non-Gaussian \gls{NMR} realizations show up to a 7\% improvement in contained metal over a conventional \gls{SGS} workflow in high-grade stopes. Though a modest improvement, improving forecasts of local high-grade resources is of great practical importance.

\subsection{Spatial Outlier Detection}
\label{subsec:07outlier}

An algorithm is presented to address the spatial component of outlier detection. Traditionally, the mining industry has employed graphical outlier detection techniques that neglect the spatial neighbourhood of potential outliers. The spatial correlation of geoscience data is pertinent information for describing a sample's degree of outlierness. The algorithm considers the relationship of each sample within a local neighbourhood plus its probability density from a fitted \gls{GMM}. The idea is that true outliers should be either sufficiently different from their spatial neighbours, be from a low density region of the \gls{GMM}, or a combination of both. The algorithm also considers the data configuration through an area of influence. Extremely high- or low-grade samples in sparse data regions pose a risk of overestimation, and the outlier score considers the area of influence. A drawback of the approach, and others from Section \ref{subsec:02tools}, is that a subjective threshold must be selected to delineate inliers and outliers. Selecting this threshold may be challenging in some instances, though practice shows that clustering of outliers is generally apparent. The algorithm is shown to effectively identify both outliers and extreme values in one- and two-dimensional examples. The algorithm is not intended to replace existing methodologies but to be an additional tool in the practitioners' toolbox. Best practice dictates the identification of outliers with an ensemble of methodologies.

\FloatBarrier
\section{Limitations}
\label{sec:07limit}

Despite the developments made in this thesis, limitations exist with the proposed methodologies. The following sections discuss the limitations of the \gls{NMR} framework and latent variable imputation.

\subsection{Network Model of Regionalization}
\label{subsec:07nmr2}

A limitation of the \gls{NMR} approach is that the final models reproduce linear features. The model cannot adapt to non-linear features as two-point and linear sequences of \gls{MPS} characterize the objective function. Limiting \gls{MPS} to \gls{1D} sequences is a practical trade-off for the use of a \gls{TI}. However, this precludes the generation of curvilinear features. One could conceivably generate curvilinear features with a sufficient number of latent factors at appropriate orientations, however the objective function components remain linear. This linear nature is a limitation compared to other high-order simulation algorithms. Another challenge is that even though a mixture of Gaussian \glspl{RF} can be non-Gaussian, the mixture may experience destructured extreme values depending on the conditioning data. Structuring the extreme values can be controlled through the objective function components. However, this may not be possible with sparse data.

Another limitation of the \gls{NMR} methodology is the necessity of numerical inversion. The outputs of the forward model are known; however, the mapping parameters that yield the correct forward outputs are unknown. Inverse problems are generally ill-posed or lack a unique solution. This non-uniqueness means the solution is sensitive to initial parameter choices like the latent Gaussian pool, $\boldsymbol{\omega}$, and $\boldsymbol{a}$ parameters. The potential exists for the algorithm to converge on a numerically reasonable but geologically unreasonable solution. The practitioner must make initial parameter choices to ensure the optimization process explores an appropriate solution space. The potential exists for conflicting objective function components or components with confounding relationships. There may be uncertainty in the objective components if they are derived from experimental statistics. The practitioner must ensure a carefully crafted objective function, suitable conversion criteria, and appropriate regularization through prior geologic knowledge and parameter bounds.

Numerical inversion is an iterative process and is typically computationally expensive. The speed of \gls{NMR} convergence negatively correlates with the number of available data. As each inversion iteration generates a newly parameterized network, experimental variograms must be recalculated each time. Though data paring is only performed once, updating each variogram lag is computationally expensive. This expense is somewhat counteracted by parallelization of \gls{DE}, yet algorithm run times may be significant with greater than 10000 data.

% \begin{enumerate}
%     \item Still linear, no curvilinear features
%     \item uncertainty in objective components, relationship to number of data
%     \item conflicting objectives
%     \item lots of hyperparameters
%     \item choice of Gaussian pool
%     \item might be hard to get away from Gaussianity with strong conditioning
%     \item MPS are 1D
%     \item slow, variogram is expensive calculation repeatedly
%     \item solution non-unique
%     \item inverse considerations in general
% \end{enumerate}

\subsection{Latent Imputation}
\label{subsec:07impute}

Though the \gls{SGRI} algorithm shows stable convergence in many scenarios, a limitation of the methodology is the somewhat ``brute-force'' approach to imputation. Sequentially sampling the conditional distributions can lead to scenarios where imputed values at one data location yield local conditional \glspl{CDF} at another location that does not permit convergence. This non-convergence is practically overcome by resetting all imputed values in a neighbourhood about the location and resimulating. However, the algorithm relies on sufficient iterations to overcome this issue. For these reasons, the rejection sampling approach may necessitate many iterations for convergence at each data location. Like the \gls{NMR} workflow, conversion may be slow with many data.

\Gls{SGRI} is a practical alternative to the Gibbs sampler paradigm for imputation. However, the implementation is not general and requires a fully parameterized \gls{NMR} to impute latent variables. Overall, this is not a limitation of the methodology but a consideration for adaptation to other workflows featuring latent imputation.

% \begin{enumerate}
%     \item SGRI not general, requires NMR for mapping, lots of iterations
%     \item imputation requires restarts to prevent non-convergence
%     \item iteration heavy - not really a problem
% \end{enumerate}

\FloatBarrier
\section{Future Work}
\label{sec:07fwork}

Future work should address the known limitations of the proposed methodology. The \gls{NMR} framework poses challenges as the solution space is non-unique and necessitates a numerical approach. Another algorithm for parameter inference may perform better than \gls{DE}. \Gls{DE} is chosen due to its ease of implementation and widespread use in engineering problems, though another heuristic algorithm may perform well. Regardless of the chosen optimization algorithm, future work could improve the computational efficiency of both the \gls{NMR} and \gls{SGRI} algorithms. An efficient approximation of the experimental variogram could drastically speed up \gls{NMR} parameter inference. As the \gls{NMR} objective function may contain any number of components, one could explore additional components such as directional asymmetry or third-order spatial moments from $[\mathbf{h}_{1}, \mathbf{h}_{2}]$ triplets \citep{lauzon2020sequential}.

Another area of future research is exploring more complex network structures. The current network architecture is simple, and there is no interaction of latent factors before the output layer. A more complex or classical multi-layer perceptron architecture could capture even more complex, non-Gaussian, or non-linear spatial features.

% \begin{enumerate}
%     \item something other than DE
%     \item overall efficiency of both algorithms
%     \item deeper dive into more complex network structures
%     \item additional objective components? \cite{lauzon2020sequential}
% \end{enumerate}

