@book{armstrong2011plurigaussian,
  title     = {Plurigaussian {{Simulations}} in {{Geosciences}}},
  author    = {Armstrong, Margaret and Galli, Alain and Beucher, H{\'e}l{\`e}ne and Loc'h, Gaelle and Renard, Didier and Doligez, Brigitte and Eschard, R{\'e}mi and Geffroy, Francois},
  year      = {2011},
  publisher = {{Springer}},
  address   = {{Berlin, Heidelberg}},
  doi       = {10.1007/978-3-642-19607-2},
  urldate   = {2024-02-14},
  isbn      = {978-3-642-19606-5 978-3-642-19607-2},
  langid    = {english},
  keywords  = {Geostatistics,Mining,Petroleum,Simulations},
  file      = {D:\03 UofA\06 Reading\_zotfile\Armstrong et al\armstrong2011plurigaussian.pdf}
}

@article{arroyo2020iterative,
  title    = {Iterative Algorithms for Non-Conditional and Conditional Simulation of {{Gaussian}} Random Vectors},
  author   = {Arroyo, Daisy and Emery, Xavier},
  year     = {2020},
  month    = oct,
  journal  = {Stochastic Environmental Research and Risk Assessment},
  volume   = {34},
  number   = {10},
  pages    = {1523--1541},
  issn     = {1436-3259},
  doi      = {10.1007/s00477-020-01875-0},
  urldate  = {2024-02-13},
  abstract = {The conditional simulation of Gaussian random vectors is widely used in geostatistical~applications to quantify uncertainty in regionalized phenomena that have been observed at finitely many sampling locations. Two iterative algorithms are presented to deal with such a simulation. The first one is a variation of the propagative version of the Gibbs sampler aimed at simulating the random vector without any conditioning data. The novelty of the presented algorithm stems from the introduction of a relaxation parameter that, if adequately chosen, allows quickening the rates of convergence and mixing of the sampler. The second algorithm is meant to convert the non-conditional simulation into a conditional one, based on the successive over-relaxation method. Again, a relaxation parameter allows quickening the convergence in distribution to the desired conditional random vector. Both algorithms are applicable in a very general setting and avoid the pivoting, inversion, square rooting or decomposition of the variance-covariance matrix of the vector to be simulated, thus reduce the computation costs and memory requirements with respect to other discrete~geostatistical simulation approaches.},
  langid   = {english},
  keywords = {Gauss-Seidel method,Gaussian random fields,Gibbs sampler,Mixing,Successive over-relaxation method},
  file     = {D:\03 UofA\06 Reading\_zotfile\Arroyo_Emery\arroyo2020iterative.pdf}
}

@techreport{artemis2020,
  title    = {Blackwater Gold Project British Columbia - {{NI}} 43-101 Technical Report on Pre-Feasibility Study},
  author   = {{Artemis Gold Inc.}},
  year     = {2020},
  keywords = {thesis_02}
}

@techreport{banyan2020,
  title    = {{{TECHNICAL REPORT ON THE AURMAC PROPERTY}}, {{MAYO MINING DISTRICT YUKON TERRITORY}}, {{CANADA}}},
  author   = {{Banyan Gold Corp.}},
  year     = {2020},
  keywords = {thesis_02}
}

@article{barnett2014projection,
  title    = {Projection {{Pursuit Multivariate Transform}}},
  author   = {Barnett, Ryan M. and Manchuk, John G. and Deutsch, Clayton V.},
  year     = {2014},
  month    = apr,
  journal  = {Mathematical Geosciences},
  volume   = {46},
  number   = {3},
  pages    = {337--359},
  issn     = {1874-8953},
  doi      = {10.1007/s11004-013-9497-7},
  urldate  = {2022-09-20},
  abstract = {Transforming complex multivariate geological data to a Gaussian distribution is an important and challenging problem in geostatistics. A~variety of transforms are available for this goal, but struggle with high dimensional data sets. Projection pursuit density estimation (PPDE) is a well-established nonparametric method for estimating the joint density of multivariate data. A~central component of the PPDE algorithm transforms the original data toward a multivariate Gaussian distribution. The PPDE approach is modified to map complex data to a multivariate Gaussian distribution within a geostatistical modeling context. Traditional modeling may then take place on the transformed Gaussian data, with a back-transform used to return simulated variables to their original units. This approach is referred to as the projection pursuit multivariate transform (PPMT). The PPMT shows the potential to be an effective means for modeling high dimensional and complex geologic data. The PPMT algorithm is developed before discussing considerations and limitations. A~case study compares modeling results against more common techniques to demonstrate the value and place of the PPMT within geostatistics.},
  langid   = {english},
  keywords = {Geostatistical Modeling,Kernel Density Estimation,Projection Index,Projection Pursuit,Radial Point Interpolation Method},
  file     = {D:\03 UofA\06 Reading\_zotfile\Barnett et al\barnett2014projection.pdf}
}

@article{barnett2015multivariate,
  title    = {Multivariate {{Imputation}} of {{Unequally Sampled Geological Variables}}},
  author   = {Barnett, Ryan M. and Deutsch, Clayton V.},
  year     = {2015},
  month    = oct,
  journal  = {Mathematical Geosciences},
  volume   = {47},
  number   = {7},
  pages    = {791--817},
  issn     = {1874-8953},
  doi      = {10.1007/s11004-014-9580-8},
  urldate  = {2023-08-14},
  abstract = {Unequally sampled data pose a practical and significant problem for geostatistical modeling. Multivariate transformations are frequently applied in modeling workflows to reproduce the multivariate relationships of geological data. Unfortunately, these transformations may only be applied to data observations that sample all of the variables. In the case of unequal sampling, practitioners must decide between excluding incomplete observations and imputing (inferring) the missing values. While imputation is recommended by missing data theorists, the use of deterministic methods such as regression is generally discouraged. Instead, techniques such as multiple imputation (MI) are advocated to increase the accuracy, decrease the bias, and capture the uncertainty of imputed values. As missing data theory has received little attention within geostatistical literature and practice, MI has not been adapted from its conventional form to be suitable for geological data. To address this, geostatistical algorithms are integrated within an MI framework to produce parametric and non-parametric methods. Synthetic and geometallurgical case studies are used to demonstrate the feasibility of each method, where techniques that use both spatial and colocated information are shown to outperform the alternatives.},
  langid   = {english},
  keywords = {Geostatistics,Missing data analysis,Modeling,Statistics,thesis_05},
  file     = {D:\03 UofA\06 Reading\_zotfile\Barnett_Deutsch\barnett2015multivariate.pdf}
}

@techreport{cardinal2019,
  title    = {Namdini Gold Project Feasibility Study {{NI}} 43-101 Technical Report, Ghana, West Africa},
  author   = {{Cardinal Resources}},
  year     = {2019},
  keywords = {thesis_02}
}

@techreport{cartier2020,
  title    = {{{NI}} 43-101 Technical Report and Mineral Resource Estimate for the Central, North and South Gold Corridors on the Chimo Mine Project, Qu{\'e}bec, Canada},
  author   = {{Cartier Resources Inc.}},
  year     = {2020},
  keywords = {thesis_02}
}

@misc{carvalho2017overview,
  title        = {An {{Overview}} of {{Multiple Indicator Kriging}}},
  author       = {Carvalho, Dhaniel and Deutsch, Clayton V},
  year         = {2017},
  month        = jan,
  urldate      = {2022-10-03},
  howpublished = {https://geostatisticslessons.com/lessons/mikoverview},
  keywords     = {thesis_02},
  file         = {C:\Users\benha\Zotero\storage\J53QYQC4\mikoverview.html}
}

@techreport{cim2019,
  title       = {{{CIM}} Estimation of Mineral Resources \& Mineral Reserves Best Practice Guidelines},
  author      = {{CIM Mineral Resource \& Mineral Reserve Committee}},
  year        = {2019},
  month       = nov,
  institution = {{Canadian Institute of Mining, Metallurgy and Petroleum}},
  keywords    = {thesis_02}
}

@techreport{eldorado2020,
  title    = {Technical Report Ki{\c s}lada{\u g} Gold Mine Turkey},
  author   = {{Eldorado Gold Corporation}},
  year     = {2020},
  keywords = {thesis_02}
}

@article{emery2014simulating,
  title    = {Simulating {{Large Gaussian Random Vectors Subject}} to {{Inequality Constraints}} by {{Gibbs Sampling}}},
  author   = {Emery, Xavier and Arroyo, Daisy and Pel{\'a}ez, Mar{\'i}a},
  year     = {2014},
  month    = apr,
  journal  = {Mathematical Geosciences},
  volume   = {46},
  number   = {3},
  pages    = {265--283},
  issn     = {1874-8953},
  doi      = {10.1007/s11004-013-9495-9},
  urldate  = {2023-08-14},
  abstract = {The Gibbs sampler is an iterative algorithm used to simulate Gaussian random vectors subject to inequality constraints. This algorithm relies on the fact that the distribution of a vector component conditioned by the other components is Gaussian, the mean and variance of which are obtained by solving a kriging system. If the number of components is large, kriging is usually applied with a moving search neighborhood, but this practice can make the simulated vector not reproduce the target correlation matrix. To avoid these problems, variations of the Gibbs sampler are presented. The conditioning to inequality constraints on the vector components can be achieved by simulated annealing or by restricting the transition matrix of the iterative algorithm. Numerical experiments indicate that both approaches provide realizations that reproduce the correlation matrix of the Gaussian random vector, but some conditioning constraints may not be satisfied when using simulated annealing. On the contrary, the restriction of the transition matrix manages to satisfy all the constraints, although at the cost of a large number of iterations.},
  langid   = {english},
  keywords = {Gaussian random field,Gibbs sampler,Kriging neighborhood,Markov chain,Restriction of transition matrix,Simulated annealing,thesis_05},
  file     = {D:\03 UofA\06 Reading\_zotfile\Emery et al\emery2014simulating.pdf}
}

@book{everitt2010cambridge,
  title     = {The Cambridge Dictionary of Statistics},
  author    = {Everitt, B.S. and Skrondal, A.},
  year      = {2010},
  publisher = {{Cambridge University Press}},
  isbn      = {978-0-521-76699-9},
  lccn      = {2010502891},
  keywords  = {thesis_05},
  file      = {D:\03 UofA\06 Reading\_zotfile\Everitt_Skrondal\everitt2010cambridge.pdf}
}

@techreport{fiore2021,
  title    = {{{NI}} 43-101 Updated Technical Report on Resources and Reserves Pan Gold Project White Pine County, Nevada},
  author   = {{Fiore Gold Ltd.}},
  year     = {2021},
  keywords = {thesis_02}
}

@article{geman1984stochastic,
  title    = {Stochastic {{Relaxation}}, {{Gibbs Distributions}}, and the {{Bayesian Restoration}} of {{Images}}},
  author   = {Geman, Stuart and Geman, Donald},
  year     = {1984},
  month    = nov,
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume   = {PAMI-6},
  number   = {6},
  pages    = {721--741},
  issn     = {1939-3539},
  doi      = {10.1109/TPAMI.1984.4767596},
  abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution,thesis_05},
  file     = {D\:\\03 UofA\\06 Reading\\_zotfile\\Geman_Geman\\geman1984stochastic.pdf;C\:\\Users\\benha\\Zotero\\storage\\YY8YSXS4\\4767596.html}
}

@article{goovaerts1992factorial,
  title      = {Factorial Kriging Analysis: A Useful Tool for Exploring the Structure of Multivariate Spatial Soil Information},
  shorttitle = {Factorial Kriging Analysis},
  author     = {Goovaerts, P.},
  year       = {1992},
  journal    = {Journal of Soil Science},
  volume     = {43},
  number     = {4},
  pages      = {597--619},
  issn       = {1365-2389},
  doi        = {10.1111/j.1365-2389.1992.tb00163.x},
  urldate    = {2021-10-16},
  abstract   = {Most studies of relations between soil properties fail to take account of their regionalized nature because of the lack of appropriate methods. This paper describes a geostatistical technique, factorial kriging analysis, that bridges the gap between classical multivariate analysis and a univariate geostatistical approach. The basic feature of the method is the fitting of a linear model of coregionalization, i.e. all experimental simple and cross-variograms are modelled with a linear combination of basic variogram functions. A particular variance-covariance matrix, the coregionalization matrix, can then be associated with each spatial scale defined by the range of the basic variogram function. Each coregionalization matrix describes relationships between variables at a given spatial scale. A principal component analysis of these matrices produces a set of components, the regionalized factors, that reflect the main features of the multivariate information for each spatial scale and whose scores are estimated by cokriging. The technique is described and illustrated with three case studies based on a simulated data set and soil survey data. The results are compared with those of the principal component analysis of the variance-covariance matrix and the variogram matrices.},
  langid     = {english},
  keywords   = {thesis_05},
  file       = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Goovaerts\\goovaerts1992factorial.pdf;C\:\\Users\\benha\\Zotero\\storage\\RI54W7CF\\j.1365-2389.1992.tb00163.html}
}

@article{hadavand2023spatial,
  title    = {Spatial Multivariate Data Imputation Using Deep Learning and Lambda Distribution},
  author   = {Hadavand, Mostafa and Deutsch, Clayton V.},
  year     = {2023},
  month    = aug,
  journal  = {Computers \& Geosciences},
  volume   = {177},
  pages    = {105376},
  issn     = {0098-3004},
  doi      = {10.1016/j.cageo.2023.105376},
  urldate  = {2024-02-14},
  abstract = {Artificial neural networks (ANNs) are often used to establish a mapping between an input data set and a corresponding output. There are many applications that rely on quantifying the conditional distribution of the output given the input data set. This is often referred to as aleatoric uncertainty associated with variability of the outcome due to inherently random effects. In this paper, deep learning is used to quantify moments of the conditional distribution of a missing variable based on homotopic multivariate observations. The lambda distribution is then used to parametrize the conditional distribution based on the provided moments. Geostatistical quantification of spatial continuity complements the multivariate conditional distribution through Bayesian updating to inform multiple data imputation that accounts for the uncertainty associated with the missing variable(s). Geological data are often incomplete, and data imputation is an essential step to avoid excluding heterotopic data. The proposed data imputation framework trains multi layer perceptron (MLP) neural networks to characterize multivariate relationships inferred from homotopic training data. A case study is conducted using geological data from a lateritic Nickle deposit to demonstrate application of the proposed methodology.},
  keywords = {Gaussian mixture model,Geostatistics,Simulation},
  file     = {D\:\\03 UofA\\06 Reading\\_zotfile\\Hadavand_Deutsch\\hadavand2023spatial.pdf;C\:\\Users\\benha\\Zotero\\storage\\ZEKJPSLQ\\S0098300423000808.html}
}

@article{journel1983nonparametric,
  title    = {Nonparametric Estimation of Spatial Distributions},
  author   = {Journel, A. G.},
  year     = {1983},
  month    = jun,
  journal  = {Journal of the International Association for Mathematical Geology},
  volume   = {15},
  number   = {3},
  pages    = {445--468},
  issn     = {1573-8868},
  doi      = {10.1007/BF01031292},
  urldate  = {2021-10-22},
  abstract = {The indicator approach, whereby the data are used through their rank order, allows a nonparametric approach to the data bivariate distribution. Such rich structural information allows a nonparametric risk-qualified, estimation of local and global spatial distributions.},
  langid   = {english},
  keywords = {thesis_02},
  file     = {D:\03 UofA\04 Research\02 PhD\_zotfile\Journel\journel1983nonparametric.pdf}
}

@inproceedings{lantuejoul2012simulation,
  title     = {Simulation of a {{Gaussian}} Random Vector: A Propagative Version of the {{Gibbs}} Sampler},
  booktitle = {The 9th International Geostatistics Congress},
  author    = {Lantu{\'e}joul, Christian and Desassis, Nicolas},
  year      = {2012},
  pages     = {174--181},
  file      = {D:\03 UofA\06 Reading\_zotfile\Lantuéjoul_Desassis\lantuejoul2012simulation.pdf}
}

@article{lauzon2020calibration,
  title    = {Calibration of Random Fields by a Sequential Spectral Turning Bands Method},
  author   = {Lauzon, Dany and Marcotte, Denis},
  year     = {2020},
  month    = feb,
  journal  = {Computers \& Geosciences},
  volume   = {135},
  pages    = {104390},
  issn     = {0098-3004},
  doi      = {10.1016/j.cageo.2019.104390},
  urldate  = {2024-02-13},
  abstract = {A new algorithm for calibration of conditional realizations to measured or desired response functions is presented. The Sequential-Spectral Turning Bands Method (S-STBM) builds the field by choosing the phase of each new cosine function such that the observed field response functions become increasingly calibrated. The phase selection has little influence on the spatial correlation structure but can help to meet other objectives. Conditioning by kriging is used in the algorithm main loop to impose exact hard data reproduction. A first case study illustrates the performance of the algorithm for a cyclic and asymmetric field. S-STBM is shown to reproduce similarly or better the directional asymmetry than calibrated realizations obtained by FFTMA-SA. A training image (TI) with connected low values provides the second case study where the target is the reproduction of non-centered third-order spatial moments. A third case study shows the effectiveness of the S-STBM algorithm to calibrate a Gaussian field to tracer tests. Contrary to FFTMA-SA, S-STBM works on irregular grids. Its computational complexity of O(n) and small memory requirement makes it an attractive method for calibration.},
  keywords = {Conditional simulation,Constructive calibration,High-order statistics,Spectral turning bands},
  file     = {D\:\\03 UofA\\06 Reading\\_zotfile\\Lauzon_Marcotte\\lauzon2020calibration.pdf;C\:\\Users\\benha\\Zotero\\storage\\WKMIAIZG\\S0098300419306752.html}
}

@article{lauzon2020sequential,
  title    = {The Sequential Spectral Turning Band Simulator as an Alternative to {{Gibbs}} Sampler in Large Truncated- or Pluri- {{Gaussian}} Simulations},
  author   = {Lauzon, Dany and Marcotte, Denis},
  year     = {2020},
  month    = nov,
  journal  = {Stochastic Environmental Research and Risk Assessment},
  volume   = {34},
  number   = {11},
  pages    = {1939--1951},
  issn     = {1436-3259},
  doi      = {10.1007/s00477-020-01850-9},
  urldate  = {2024-02-13},
  abstract = {The Sequential Spectral Turning Bands Method (S-STBM) builds Gaussian random fields (GRF) calibrated to desired response functions. An interesting application of S-STBM concerns the simulation of GRF subject to inequality constraints. S-STBM works by choosing the phase of each cosine function of the STBM algorithm instead of perturbating nodes of the GRF many thousand times using conditional distributions as in Gibbs sampler. Each chosen phase increasingly constrains the nodes to the desired inequalities. A method based on the sequential Gaussian simulation is introduced to accelerate convergence at the end of the process. Examples shown compare S-STBM approach to Gibbs sampler. Orders of magnitude reduction in computation time is achieved with our spectral method. Furthermore, examples show that the phase selection has no significant influence on the spatial correlation. Our approach is easily generalized to pluriGaussian simulations. Compared to Gibbs sampler, S-STBM is not limited to small systems (no memory limitation) and its complexity of O(n) makes it an efficient tool to simulate large GRF subject to inequality constraints.},
  langid   = {english},
  keywords = {Gibbs Sampler,Inequality constraints,PluriGaussian simulation,Sequential Gaussian simulation,Spectral simulation,Truncated Gaussian random field},
  file     = {D:\03 UofA\06 Reading\_zotfile\Lauzon_Marcotte\lauzon2020sequential.pdf}
}

@article{lauzon2023joint,
  title    = {Joint Hydrofacies-Hydraulic Conductivity Modeling Based on a Constructive Spectral Algorithm Constrained by Transient Head Data},
  author   = {Lauzon, Dany and Marcotte, Denis},
  year     = {2023},
  month    = sep,
  journal  = {Hydrogeology Journal},
  volume   = {31},
  number   = {6},
  pages    = {1647--1664},
  issn     = {1435-0157},
  doi      = {10.1007/s10040-023-02638-1},
  urldate  = {2024-02-15},
  abstract = {A constructive spectral method is presented to jointly calibrate hydrofacies and hydraulic conductivity to transient pressure heads. The method iteratively constructs Gaussian random fields to model the spatial correlation of hydraulic conductivity and hydrofacies using pluriGaussian simulation. Borehole conditioning is done quickly by replacing the slow Gibbs sampler method with an approach that is based on calibrating the underlying Gaussian fields that are subject to inequality constraints. Calibration to transient pressure heads is performed by shallow optimization of the phase vectors of the continuous spectral method. A parameterization technique makes it possible to reduce phase vector optimization from multivariate to univariate. The algorithm is tested on two-dimensional (2D) and 3D synthetic regional aquifers made of three hydrofacies. It reduced the objective function by one order of magnitude in one hundred iterations. The tests on the 2D aquifers indicated that the transient hydraulic heads alone cannot provide much information about hydrofacies. However, combining them with hydrofacies observations from boreholes results in improved hydrofacies identification compared to when only borehole data are used. Similar results were obtained in the 3D aquifer case, although the improvement in aquifer identification was less pronounced. The spectral method presented makes it possible to calibrate complex aquifers to transient heads using a limited number of calls to the flow simulator. Doing so helps to characterize sub-surface heterogeneity and assess the uncertainty and geological risks associated with groundwater flow.},
  langid   = {english},
  keywords = {Data assimilation,Geostatistics,Inverse modeling,Parameter uncertainty assessment,Stochastic hydrogeology},
  file     = {D:\03 UofA\06 Reading\_zotfile\Lauzon_Marcotte\lauzon2023joint.pdf}
}

@article{leuangthong2015dealinga,
  title     = {Dealing with High-Grade Data in Resource Estimation},
  author    = {Leuangthong, O. and Nowak, M.},
  year      = {2015},
  journal   = {Journal of the Southern African Institute of Mining and Metallurgy},
  volume    = {115},
  number    = {1},
  pages     = {27--36},
  publisher = {{The Southern African Institute of Mining and Metallurgy}},
  keywords  = {thesis_02},
  file      = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Leuangthong_Nowak\\leuangthong2015dealing.pdf;C\:\\Users\\benha\\Zotero\\storage\\MIJ9JM8Z\\scielo.html}
}

@book{little2002statistical,
  title     = {Statistical {{Analysis}} with {{Missing Data}}},
  author    = {Little, Roderick J. A. and Rubin, Donald B.},
  year      = {2002},
  edition   = {1},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi       = {10.1002/9781119013563},
  urldate   = {2023-08-14},
  file      = {D\:\\03 UofA\\06 Reading\\_zotfile\\Little_Rubin\\little2002statistical.pdf;C\:\\Users\\benha\\Zotero\\storage\\T5FRK54J\\9781119013563.html}
}

@book{little2019statistical,
  title     = {Statistical Analysis with Missing Data},
  author    = {Roderick J. A. Little, Donald B. Rubin},
  year      = {2019},
  series    = {Wiley Series in Probability and Statistics},
  edition   = {3},
  publisher = {{Wiley}},
  isbn      = {0-470-52679-3 978-1-118-59601-2 978-1-118-59569-5 978-0-470-52679-8},
  file      = {D:\03 UofA\06 Reading\_zotfile\Roderick J. A. Little\little2019statistical.pdf}
}

@article{madani2021enhanced,
  title    = {Enhanced Conditional {{Co-Gibbs}} Sampling Algorithm for Data Imputation},
  author   = {Madani, Nasser and Bazarbekov, Talgatbek},
  year     = {2021},
  month    = mar,
  journal  = {Computers \& Geosciences},
  volume   = {148},
  pages    = {104655},
  issn     = {0098-3004},
  doi      = {10.1016/j.cageo.2020.104655},
  urldate  = {2024-02-14},
  abstract = {The Gibbs sampler is an iterative algorithm for data imputation of a random vector at locations where values of the variable of interest are missing. In this algorithm, the simulated values converge to a Gaussian random vector distribution with zero mean and a given covariance matrix obtained by solving a simple kriging system through several iterations. In a bivariate dataset, if the principal variable for imputation depends on an auxiliary variable that is more abundant at the sample locations, this algorithm fails to produce the local and spatial cross-correlation structures. To overcome this impediment, a variant of the Gibbs sampler, the conditional Co-Gibbs sampler, has been proposed in this study, where simple kriging is replaced by three alternative cokriging paradigms: multicollocated cokriging, collocated cokriging, and homotopic cokriging. The algorithm was examined for an actual case study to statistically evaluate its performance. The results indicate that the conditional Co-Gibbs sampler with multicollocated cokriging outperformed the alternatives, including simple kriging where data imputation occurred as a consequence of ignoring the influence of the auxiliary variable, partially or totally. In addition, a computer software, provided as an open-source executable file, was used to implement the proposed algorithm for data imputation in bivariate cases.},
  keywords = {Algorithms,Data processing,Geology,Geostatistics,Spatial statistics},
  file     = {D:\03 UofA\06 Reading\_zotfile\Madani_Bazarbekov\madani2021enhanced.pdf}
}

@techreport{matheron1982factorial,
  title       = {Pour Une Analyse Krigeante Des Donn{\'e}es R{\'e}gionalis{\'e}es},
  author      = {Matheron, Georges},
  year        = {1982},
  number      = {N-732},
  institution = {{Ecole des Mines de Paris}},
  urldate     = {2021-10-28},
  file        = {D:\03 UofA\04 Research\02 PhD\_zotfile\Matheron\matheron1982factorial.pdf}
}

@techreport{medgold2021,
  title    = {{{PRELIMINARY ECONOMIC ASSESSMENT AND NI}} 43-101 {{TECHNICAL REPORT FOR THE MEDGOLD TLAMINO PROJECT LICENCES}}, {{SERBIA}}},
  author   = {{Medgold Resources Corp.}},
  year     = {2021},
  keywords = {thesis_02}
}

@misc{mullner2011modern,
  title         = {Modern Hierarchical, Agglomerative Clustering Algorithms},
  author        = {M{\"u}llner, Daniel},
  year          = {2011},
  month         = sep,
  number        = {arXiv:1109.2378},
  eprint        = {1109.2378},
  primaryclass  = {cs, stat},
  publisher     = {{arXiv}},
  urldate       = {2023-12-11},
  abstract      = {This paper presents algorithms for hierarchical, agglomerative clustering which perform most efficiently in the general-purpose setup that is given in modern standard software. Requirements are: (1) the input data is given by pairwise dissimilarities between data points, but extensions to vector data are also discussed (2) the output is a "stepwise dendrogram", a data structure which is shared by all implementations in current standard software. We present algorithms (old and new) which perform clustering in this setting efficiently, both in an asymptotic worst-case analysis and from a practical point of view. The main contributions of this paper are: (1) We present a new algorithm which is suitable for any distance update scheme and performs significantly better than the existing algorithms. (2) We prove the correctness of two algorithms by Rohlf and Murtagh, which is necessary in each case for different reasons. (3) We give well-founded recommendations for the best current algorithms for the various agglomerative clustering schemes.},
  archiveprefix = {arxiv},
  keywords      = {62H30,Computer Science - Data Structures and Algorithms,I.5.3,Statistics - Machine Learning,thesis_06},
  file          = {D\:\\03 UofA\\06 Reading\\_zotfile\\Müllner\\mullner2011modern.pdf;C\:\\Users\\benha\\Zotero\\storage\\RBT9X7UZ\\1109.html}
}

@techreport{ngm2020,
  title    = {{{TECHNICAL REPORT ON THE CARLIN COMPLEX}}, {{EUREKA AND ELKO COUNTIES}}, {{STATE OF NEVADA}}, {{USA}}},
  author   = {{Nevada Gold Mines LLC}},
  year     = {2020},
  keywords = {thesis_02}
}

@inproceedings{nowak2013suggestions,
  title     = {Suggestions for Good Capping Practices from Historical Literature},
  booktitle = {Proceedings of the 23rd {{World Mining Congress}} 2013},
  author    = {Nowak, M. and Leuangthong, O. and Srivastava, R. M.},
  year      = {2013},
  publisher = {{Canadian Institute of Mining, Metallurgy and Petroleum Montreal}},
  keywords  = {thesis_02},
  file      = {D:\03 UofA\04 Research\02 PhD\_zotfile\Nowak et al\nowak2013suggestions.pdf}
}

@techreport{osiko2020,
  title    = {{{NI}} 43-101 Technical Report and Mineral Resource Estimate for the Cariboo Gold Project, British Columbia, Canada},
  author   = {{Osisko Gold Royalties Ltd}},
  year     = {2020},
  keywords = {thesis_02}
}

@article{parrish1997,
  title    = {Geologist's Gordian Knot: {{To}} Cut or Not to Cut},
  author   = {Parrish, I.S},
  year     = {1997},
  journal  = {Mining Engineering},
  volume   = {49},
  pages    = {45--49},
  keywords = {thesis_02},
  file     = {D:\03 UofA\04 Research\02 PhD\_zotfile\Parrish\parrish1997geologist.pdf}
}

@techreport{pasofino2020,
  title  = {{{DUGBE GOLD PROJECT}}, {{LIBERIA NI}} 43-101 {{TECHNICAL REPORT}}},
  author = {{Pasofino Gold Ltd.}},
  year   = {2020}
}

@techreport{pretium2020,
  title    = {Technical Report on the Brucejack Gold Mine, Northwest British Columbia},
  author   = {{Pretium Resources Inc.}},
  year     = {2020},
  keywords = {thesis_02}
}

@article{qu2018geostatistical,
  title    = {Geostatistical {{Simulation}} with a {{Trend Using Gaussian Mixture Models}}},
  author   = {Qu, Jianan and Deutsch, Clayton V.},
  year     = {2018},
  month    = jul,
  journal  = {Natural Resources Research},
  volume   = {27},
  number   = {3},
  pages    = {347--363},
  issn     = {1573-8981},
  doi      = {10.1007/s11053-017-9354-3},
  urldate  = {2022-09-20},
  abstract = {Geostatistics applies statistics to quantitatively describe geological sites and assess the uncertainty due to incomplete sampling. Strong assumptions are required regarding the location independence of statistical parameters to construct numerical models with geostatistical tools. Most geological data exhibit large-scale deterministic trends together with short-scale variations. Such location dependence violates the common geostatistical assumption of stationarity. The trend-like deterministic features should be modeled prior to conventional geostatistical prediction and accounted for in subsequent geostatistical calculations. The challenge of using a trend in geostatistical simulation algorithms for the continuous variable is the subject of this paper. A stepwise conditional transformation with a Gaussian mixture model is considered to provide a stable and artifact-free numerical model. The complex features of the regionalized variable in the presence of a trend are removed in the forward transformation and restored in the back transformation. The Gaussian mixture model provides a seamless bin-free approach to transformation. Data from a copper deposit were used as an example. These data show an apparent trend unsuitable for conventional geostatistical algorithms. The result shows that the proposed algorithm leads to improved geostatistical models.},
  langid   = {english},
  keywords = {Non-stationary regionalized variable,Sequential Gaussian simulation,Stepwise conditional transformation},
  file     = {D:\03 UofA\06 Reading\_zotfile\Qu_Deutsch\qu2018geostatistical.pdf}
}

@inproceedings{roscoe1996cutting,
  title     = {Cutting Curves for Grade Estimation and Grade Control in Gold Mines},
  booktitle = {98th Annual General Meeting},
  author    = {Roscoe, W.E},
  year      = {1996},
  month     = apr,
  publisher = {{Canadian Institute of Mining, Metallurgy and Petroleum}},
  keywords  = {thesis_02},
  file      = {D:\03 UofA\04 Research\02 PhD\_zotfile\Roscoe\roscoe1996cutting.pdf}
}

@article{silva2017multiple,
  title    = {Multiple Imputation Framework for Data Assignment in Truncated Pluri-{{Gaussian}} Simulation},
  author   = {Silva, Diogo S. F. and Deutsch, Clayton V.},
  year     = {2017},
  month    = nov,
  journal  = {Stochastic Environmental Research and Risk Assessment},
  volume   = {31},
  number   = {9},
  pages    = {2251--2263},
  issn     = {1436-3259},
  doi      = {10.1007/s00477-016-1309-4},
  urldate  = {2023-08-14},
  abstract = {Truncated pluri-Gaussian simulation (TPGS) is suitable for the simulation of categorical variables that show natural ordering as the TPGS technique can consider transition probabilities. The TPGS assumes that categorical variables are the result of the truncation of underlying latent variables. In practice, only the categorical variables are observed. This translates the practical application of TPGS into a missing data problem in which all latent variables are missing. Latent variables are required at data locations in order to condition categorical realizations to observed categorical data. The imputation of missing latent variables at data locations is often achieved by either assigning constant values or spatially simulating latent variables subject to categorical observations. Realizations of latent variables can be used to condition all model realizations. Using a single realization or a constant value to condition all realizations is the same as assuming that latent variables are known at the data locations and this assumption affects uncertainty near data locations. The techniques for imputation of latent variables in TPGS framework are investigated in this article and their impact on uncertainty of simulated categorical models and possible effects on factors affecting decision making are explored. It is shown that the use of single realization of latent variables leads to underestimation of uncertainty and overestimation of measured resources while the use constant values for latent variables may lead to considerable over or underestimation of measured resources. The results highlight the importance of multiple data imputation in the context of TPGS.},
  langid   = {english},
  keywords = {Geomodeling,Geostatistics,Gibbs sampler,Missing data analysis,thesis_05},
  file     = {D:\03 UofA\06 Reading\_zotfile\Silva_Deutsch\silva2017multiple.pdf}
}

@misc{silva2018enhanced,
  title        = {Enhanced {{Geologic Modeling}} of {{Multiple Categorical Variables}}},
  author       = {Silva, Diogo},
  year         = 2018,
  journal      = {ERA},
  doi          = {10.7939/R30G3HD9R},
  urldate      = {2023-08-15},
  abstract     = {Widely spaced data sets from drilling are used in the mining and petroleum industries to model subsurface resources. These data sets have...},
  howpublished = {https://era.library.ualberta.ca/items/9ab8ab60-cb8f-4d7d-9551-3c602956b0ad},
  langid       = {english},
  keywords     = {thesis_05},
  file         = {D:\03 UofA\06 Reading\_zotfile\Silva\silva2018enhanced.pdf}
}

@article{silva2018multivariate,
  title    = {Multivariate Data Imputation Using {{Gaussian}} Mixture Models},
  author   = {Silva, Diogo S. F. and Deutsch, Clayton V.},
  year     = {2018},
  month    = oct,
  journal  = {Spatial Statistics},
  volume   = {27},
  pages    = {74--90},
  issn     = {2211-6753},
  doi      = {10.1016/j.spasta.2016.11.002},
  urldate  = {2023-08-14},
  abstract = {Availability of high dimensional geological data has become common in the mining and petroleum industries. Data sets are often complex and require advanced multivariate geostatistical techniques. Multivariate data transformation is a common step of such advanced workflows and its application requires equally sampled (isotopic) data at all data locations. Samples with missing variables are common in geological data sets for many reasons. The missing data must be imputed (inferred) to permit the measured data to be used to their full extent. Imputation methods for geological data should address spatial structure and multivariate complexity. The published techniques that account for these considerations make strong assumptions regarding conditional distributions and are computationally demanding in presence of many data. A Gaussian mixture model fitted to the multivariate data is proposed in this paper to provide stability in fitting multivariate data and to significantly improve computational efficiency. The proposed approach is demonstrated using a lateritic Nickel data set. The proposed improvement is shown to decrease computational time by two orders of magnitude for the example while also consistently enhancing results in several performance tests.},
  keywords = {Geostatistics,Missing data analysis,Modeling,Semi-parametric,thesis_05},
  file     = {D\:\\03 UofA\\06 Reading\\_zotfile\\Silva_Deutsch\\silva2018multivariate.pdf;C\:\\Users\\benha\\Zotero\\storage\\NMCSMPRH\\S2211675316301300.html}
}

@techreport{tristar2021,
  title    = {Mineral Resource Update for the Castelo de Sonhos Gold Project, Par{\'a} State, Brazil},
  author   = {{TriStar Gold Inc.}},
  year     = {2021},
  keywords = {thesis_02}
}

@book{tukey1977exploratory,
  title     = {Exploratory Data Analysis},
  author    = {Tukey, John W and others},
  year      = {1977},
  volume    = {2},
  publisher = {{Reading, MA}},
  keywords  = {thesis_02},
  file      = {D:\03 UofA\06 Reading\_zotfile\Tukey_others\tukey1977exploratory.pdf}
}

@techreport{Wilde2007,
  type        = {{{CCG}} Annual Report 9},
  title       = {Wide Array Declustering for Representative Distributions ({{The Ultimate DECLUS Program}})},
  author      = {Wilde, B. J},
  year        = {2007},
  address     = {{Edmonton AB}},
  institution = {{University of Alberta}},
  keywords    = {CCG,thesis_06}
}
