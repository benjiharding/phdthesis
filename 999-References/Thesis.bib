@book{aggarwal2016outlier,
  title = {Outlier {{Analysis}}},
  author = {Aggarwal, Charu C},
  year = {2016},
  publisher = {Springer International Publishing},
  isbn = {978-3-319-47578-3},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Aggarwal\aggarwal2016outlier.pdf}
}

@book{armstrong2011plurigaussian,
  title = {Plurigaussian {{Simulations}} in {{Geosciences}}},
  author = {Armstrong, Margaret and Galli, Alain and Beucher, H{\'e}l{\`e}ne and Loc'h, Gaelle and Renard, Didier and Doligez, Brigitte and Eschard, R{\'e}mi and Geffroy, Francois},
  year = {2011},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-19607-2},
  urldate = {2024-02-14},
  isbn = {978-3-642-19606-5 978-3-642-19607-2},
  langid = {english},
  keywords = {Geostatistics,Mining,Petroleum,Simulations},
  file = {D:\03 UofA\06 Reading\_zotfile\Armstrong et al\armstrong2011plurigaussian.pdf}
}

@article{arroyo2020iterative,
  title = {Iterative Algorithms for Non-Conditional and Conditional Simulation of {{Gaussian}} Random Vectors},
  author = {Arroyo, Daisy and Emery, Xavier},
  year = {2020},
  month = oct,
  journal = {Stochastic Environmental Research and Risk Assessment},
  volume = {34},
  number = {10},
  pages = {1523--1541},
  issn = {1436-3259},
  doi = {10.1007/s00477-020-01875-0},
  urldate = {2024-02-13},
  abstract = {The conditional simulation of Gaussian random vectors is widely used in geostatistical~applications to quantify uncertainty in regionalized phenomena that have been observed at finitely many sampling locations. Two iterative algorithms are presented to deal with such a simulation. The first one is a variation of the propagative version of the Gibbs sampler aimed at simulating the random vector without any conditioning data. The novelty of the presented algorithm stems from the introduction of a relaxation parameter that, if adequately chosen, allows quickening the rates of convergence and mixing of the sampler. The second algorithm is meant to convert the non-conditional simulation into a conditional one, based on the successive over-relaxation method. Again, a relaxation parameter allows quickening the convergence in distribution to the desired conditional random vector. Both algorithms are applicable in a very general setting and avoid the pivoting, inversion, square rooting or decomposition of the variance-covariance matrix of the vector to be simulated, thus reduce the computation costs and memory requirements with respect to other discrete~geostatistical simulation approaches.},
  langid = {english},
  keywords = {Gauss-Seidel method,Gaussian random fields,Gibbs sampler,Mixing,Successive over-relaxation method},
  file = {D:\03 UofA\06 Reading\_zotfile\Arroyo_Emery\arroyo2020iterative.pdf}
}

@techreport{artemis2020,
  title = {Blackwater Gold Project British Columbia - {{NI}} 43-101 Technical Report on Pre-Feasibility Study},
  author = {{Artemis Gold Inc.}},
  year = {2020},
  keywords = {thesis_02}
}

@article{athens2022stochastic,
  title = {Stochastic {{Inversion}} of {{Gravity Data Accounting}} for {{Structural Uncertainty}}},
  author = {Athens, Noah and Caers, Jef},
  year = {2022},
  month = feb,
  journal = {Mathematical Geosciences},
  volume = {54},
  number = {2},
  pages = {413--436},
  issn = {1874-8953},
  doi = {10.1007/s11004-021-09978-2},
  urldate = {2024-04-04},
  abstract = {Conventional gravity inversion techniques have limited ability to quantify structural uncertainty in geologic models. In this paper, a stochastic framework is proposed that directly incorporates fault-related and density-related uncertainty into the inversion process. The approach uses Monte Carlo simulation to generate model realizations and the gradual deformation method to further refine models to match observed data. To guarantee that model realizations are structurally restorable, fault displacements are generated using a kinematic modeling approach in which fault model properties such as the number of faults, location, dip, slip, and orientation are considered uncertain. Using a synthetic case study problem, a reference gravity field was inverted to generate a suite of posterior model realizations. Analysis of the posterior models was used to create a fault probability map as well as quantify the distribution of slip and dip of faults in three zones of deformation. Uncertainty in density values was found to be greatly reduced in the top 250~m depth, suggesting limited sensitivity to deeper sources in this example. Following the synthetic case study problem, the inversion approach was applied to a field-observed gravity profile in Dixie Valley, Nevada, and the inversion results were compared to a previously published forward gravity model. By generating a suite of posterior models, structural uncertainty can be better assessed to make more informed decisions in a host of subsurface modeling problems.},
  langid = {english},
  keywords = {Gravity modeling,Inverse modeling,Structural modeling,Uncertainty},
  file = {D:\03 UofA\06 Reading\_zotfile\Athens_Caers\athens2022stochastic.pdf}
}

@phdthesis{babakhani2014geostatistical,
  title = {Geostatistical {{Modeling}} in {{Presence}} of {{Extreme Values}}},
  author = {Babakhani, Mahshid},
  year = 2014,
  doi = {10.7939/R3VQ2SJ85},
  urldate = {2023-11-15},
  abstract = {Geostatistical modeling in presence of extreme values needs special attention. Certain extreme high values known as outliers require...},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Babakhani\babakhani2014geostatistical.pdf}
}

@article{balkaya20173d,
  title = {{{3D}} Non-Linear Inversion of Magnetic Anomalies Caused by Prismatic Bodies Using Differential Evolution Algorithm},
  author = {Balkaya, {\c C}a{\u g}layan and Ekinci, Yunus Levent and G{\"o}kt{\"u}rkler, G{\"o}khan and Turan, Se{\c c}il},
  year = {2017},
  month = jan,
  journal = {Journal of Applied Geophysics},
  volume = {136},
  pages = {372--386},
  issn = {0926-9851},
  doi = {10.1016/j.jappgeo.2016.10.040},
  urldate = {2024-04-04},
  abstract = {3D non-linear inversion of total field magnetic anomalies caused by vertical-sided prismatic bodies has been achieved by differential evolution (DE), which is one of the population-based evolutionary algorithms. We have demonstrated the efficiency of the algorithm on both synthetic and field magnetic anomalies by estimating horizontal distances from the origin in both north and east directions, depths to the top and bottom of the bodies, inclination and declination angles of the magnetization, and intensity of magnetization of the causative bodies. In the synthetic anomaly case, we have considered both noise-free and noisy data sets due to two vertical-sided prismatic bodies in a non-magnetic medium. For the field case, airborne magnetic anomalies originated from intrusive granitoids at the eastern part of the Biga Peninsula (NW Turkey) which is composed of various kinds of sedimentary, metamorphic and igneous rocks, have been inverted and interpreted. Since the granitoids are the outcropped rocks in the field, the estimations for the top depths of two prisms representing the magnetic bodies were excluded during inversion studies. Estimated bottom depths are in good agreement with the ones obtained by a different approach based on 3D modelling of pseudogravity anomalies. Accuracy of the estimated parameters from both cases has been also investigated via probability density functions. Based on the tests in the present study, it can be concluded that DE is a useful tool for the parameter estimation of source bodies using magnetic anomalies.},
  keywords = {Differential evolution,Granitoids,Magnetic anomaly,Metaheuristic,Non-linear inversion,Prismatic bodies},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Balkaya et al\\balkaya20173d.pdf;C\:\\Users\\benha\\Zotero\\storage\\3T2CP34V\\S0926985116304347.html}
}

@techreport{banyan2020,
  title = {{{TECHNICAL REPORT ON THE AURMAC PROPERTY}}, {{MAYO MINING DISTRICT YUKON TERRITORY}}, {{CANADA}}},
  author = {{Banyan Gold Corp.}},
  year = {2020},
  keywords = {thesis_02}
}

@article{bardossy2016random,
  title = {Random {{Mixing}}: {{An Approach}} to {{Inverse Modeling}} for {{Groundwater Flow}} and {{Transport Problems}}},
  shorttitle = {Random {{Mixing}}},
  author = {B{\'a}rdossy, Andr{\'a}s and H{\"o}rning, Sebastian},
  year = {2016},
  month = sep,
  journal = {Transport in Porous Media},
  volume = {114},
  number = {2},
  pages = {241--259},
  issn = {1573-1634},
  doi = {10.1007/s11242-015-0608-4},
  urldate = {2024-02-15},
  abstract = {This paper presents a novel methodology for inverse modeling of groundwater flow and transport problems in a Monte Carlo framework, i.e., multiple solutions to the inverse problem are generated. The methodology is based on the concept of random mixing of spatial random fields. The conditional target hydraulic transmissivity field is obtained as a linear combination of unconditional spatial random fields. The corresponding weights of the linear combination are selected such that the spatial variability of the hydraulic transmissivities as well as the actual observed transmissivity values are reproduced. The constraints related to the hydraulic head and contaminant concentration observations are nonlinear. In order to fulfill these constraints, a specific property of the presented approach is used. A connected domain of fields fulfilling all linear constraints is identified. This domain includes an infinite number of realizations, and in this domain, the head and concentration deviations are minimized using standard continuous optimization techniques. The methodology uses spatial copulas to describe the spatial dependence structure. A combination with multiple point statistics allows inversion under specific structural constraints.},
  langid = {english},
  keywords = {Copula,Inverse modeling,Multiple point statistics,Random mixing},
  file = {D:\03 UofA\06 Reading\_zotfile\Bárdossy_Hörning\bardossy2016random.pdf}
}

@book{barnett1984outliers,
  title = {Outliers in Statistical Data},
  author = {Barnett, Vic and Lewis, Toby},
  year = {1984},
  journal = {Wiley Series in Probability and Mathematical Statistics. Applied Probability and Statistics},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Barnett_Lewis\barnett1984outliers.pdf}
}

@article{barnett2014projection,
  title = {Projection {{Pursuit Multivariate Transform}}},
  author = {Barnett, Ryan M. and Manchuk, John G. and Deutsch, Clayton V.},
  year = {2014},
  month = apr,
  journal = {Mathematical Geosciences},
  volume = {46},
  number = {3},
  pages = {337--359},
  issn = {1874-8953},
  doi = {10.1007/s11004-013-9497-7},
  urldate = {2022-09-20},
  abstract = {Transforming complex multivariate geological data to a Gaussian distribution is an important and challenging problem in geostatistics. A~variety of transforms are available for this goal, but struggle with high dimensional data sets. Projection pursuit density estimation (PPDE) is a well-established nonparametric method for estimating the joint density of multivariate data. A~central component of the PPDE algorithm transforms the original data toward a multivariate Gaussian distribution. The PPDE approach is modified to map complex data to a multivariate Gaussian distribution within a geostatistical modeling context. Traditional modeling may then take place on the transformed Gaussian data, with a back-transform used to return simulated variables to their original units. This approach is referred to as the projection pursuit multivariate transform (PPMT). The PPMT shows the potential to be an effective means for modeling high dimensional and complex geologic data. The PPMT algorithm is developed before discussing considerations and limitations. A~case study compares modeling results against more common techniques to demonstrate the value and place of the PPMT within geostatistics.},
  langid = {english},
  keywords = {Geostatistical Modeling,Kernel Density Estimation,Projection Index,Projection Pursuit,Radial Point Interpolation Method},
  file = {D:\03 UofA\06 Reading\_zotfile\Barnett et al\barnett2014projection.pdf}
}

@article{barnett2015multivariate,
  title = {Multivariate {{Imputation}} of {{Unequally Sampled Geological Variables}}},
  author = {Barnett, Ryan M. and Deutsch, Clayton V.},
  year = {2015},
  month = oct,
  journal = {Mathematical Geosciences},
  volume = {47},
  number = {7},
  pages = {791--817},
  issn = {1874-8953},
  doi = {10.1007/s11004-014-9580-8},
  urldate = {2023-08-14},
  abstract = {Unequally sampled data pose a practical and significant problem for geostatistical modeling. Multivariate transformations are frequently applied in modeling workflows to reproduce the multivariate relationships of geological data. Unfortunately, these transformations may only be applied to data observations that sample all of the variables. In the case of unequal sampling, practitioners must decide between excluding incomplete observations and imputing (inferring) the missing values. While imputation is recommended by missing data theorists, the use of deterministic methods such as regression is generally discouraged. Instead, techniques such as multiple imputation (MI) are advocated to increase the accuracy, decrease the bias, and capture the uncertainty of imputed values. As missing data theory has received little attention within geostatistical literature and practice, MI has not been adapted from its conventional form to be suitable for geological data. To address this, geostatistical algorithms are integrated within an MI framework to produce parametric and non-parametric methods. Synthetic and geometallurgical case studies are used to demonstrate the feasibility of each method, where techniques that use both spatial and colocated information are shown to outperform the alternatives.},
  langid = {english},
  keywords = {Geostatistics,Missing data analysis,Modeling,Statistics,thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Barnett_Deutsch\barnett2015multivariate.pdf}
}

@book{bellman1961adaptive,
  title = {Adaptive Control Processes: {{A}} Guided Tour},
  author = {Bellman, Richard E.},
  year = {1961},
  publisher = {Princeton University Press},
  address = {Princeton},
  doi = {doi:10.1515/9781400874668},
  urldate = {2024-04-19},
  isbn = {978-1-4008-7466-8},
  file = {D:\03 UofA\06 Reading\_zotfile\Bellman\bellman1961adaptive.pdf}
}

@article{bilal2020differential,
  title = {Differential {{Evolution}}: {{A}} Review of More than Two Decades of Research},
  shorttitle = {Differential {{Evolution}}},
  author = {{Bilal} and Pant, Millie and Zaheer, Hira and {Garcia-Hernandez}, Laura and Abraham, Ajith},
  year = {2020},
  month = apr,
  journal = {Engineering Applications of Artificial Intelligence},
  volume = {90},
  pages = {103479},
  issn = {0952-1976},
  doi = {10.1016/j.engappai.2020.103479},
  urldate = {2024-03-15},
  abstract = {Since its inception in 1995, Differential Evolution (DE) has emerged as one of the most frequently used algorithms for solving complex optimization problems. Its flexibility and versatility have prompted several customized variants of DE for solving a variety of real life and test problems. The present study, surveys the near 25 years of existence of DE. In this extensive survey, 283 research articles have been covered and the journey of DE is shown through its basic aspects like population generation, mutation schemes, crossover schemes, variation in parameters and hybridized variants along with various successful applications of DE. This study also provides some key bibliometric indicators like highly cited papers having citations more than 500, publication trend since 1996, journal citations etc. The main aim of the present document is to serve as an extended summary of 25 years of existence of DE, intended for dissemination to interested parties. It is expected that the present survey would generate interest among the new users towards the philosophy of DE and would also guide the experience researchers.},
  keywords = {Crossover,Differential evolution,Meta-heuristics,Mutation,Selection},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Bilal et al\\bilal2020differential.pdf;C\:\\Users\\benha\\Zotero\\storage\\BHNXG4EA\\S095219762030004X.html}
}

@article{boisvert2007multiplepoint,
  title = {Multiple-{{Point Statistics}} for {{Training Image Selection}}},
  author = {Boisvert, Jeff B. and Pyrcz, Michael J. and Deutsch, Clayton V.},
  year = {2007},
  month = dec,
  journal = {Natural Resources Research},
  volume = {16},
  number = {4},
  pages = {313--321},
  issn = {1573-8981},
  doi = {10.1007/s11053-008-9058-9},
  urldate = {2022-05-26},
  abstract = {Selecting a training image (TI) that is representative of the target spatial phenomenon (reservoir, mineral deposit, soil type, etc.) is essential for an effective application of multiple-point statistics (MPS) simulation. It is often possible to narrow potential TIs to a general subset based on the available geological knowledge; however, this is largely subjective. A method is presented that compares the distribution of runs and the multiple-point density function from available exploration data and TIs. The difference in the MPS can be used to select the TI that is most representative of the data set. This tool may be applied to further narrow a suite of TIs for a more realistic model of spatial uncertainty. In addition, significant differences between the spatial statistics of local conditioning data and a TI may lead to artifacts in MPS. The utilization of this tool will identify contradictions between conditioning data and TIs. TI selection is demonstrated for a deepwater reservoir with 32 wells.},
  langid = {english},
  keywords = {Estimation,Geostatistics,Reserves,Runs,Uncertainty},
  file = {D:\03 UofA\06 Reading\_zotfile\Boisvert et al\boisvert2007multiplepoint.pdf}
}

@techreport{cardinal2019,
  title = {Namdini Gold Project Feasibility Study {{NI}} 43-101 Technical Report, Ghana, West Africa},
  author = {{Cardinal Resources}},
  year = {2019},
  keywords = {thesis_02}
}

@techreport{cartier2020,
  title = {{{NI}} 43-101 Technical Report and Mineral Resource Estimate for the Central, North and South Gold Corridors on the Chimo Mine Project, Qu{\'e}bec, Canada},
  author = {{Cartier Resources Inc.}},
  year = {2020},
  keywords = {thesis_02}
}

@misc{carvalho2017overview,
  title = {An {{Overview}} of {{Multiple Indicator Kriging}}},
  author = {Carvalho, Dhaniel and Deutsch, Clayton V},
  year = {2017},
  month = jan,
  urldate = {2022-10-03},
  howpublished = {https://geostatisticslessons.com/lessons/mikoverview},
  keywords = {thesis_02},
  file = {C:\Users\benha\Zotero\storage\J53QYQC4\mikoverview.html}
}

@article{chen2008detecting,
  title = {On Detecting Spatial Outliers},
  author = {Chen, Dechang and Lu, Chang-Tien and Kou, Yufeng and Chen, Feng},
  year = {2008},
  journal = {Geoinformatica},
  volume = {12},
  number = {4},
  pages = {455--475},
  publisher = {Springer},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Chen et al\\chen2008detecting.pdf;C\:\\Users\\benha\\Zotero\\storage\\25ZTKSQN\\s10707-007-0038-8.html}
}

@book{chiles2012geostatistics,
  title = {Geostatistics: {{Modeling Spatial Uncertainty}}},
  author = {Chil{\`e}s, Jean-Paul and Delfiner, Pierre},
  year = {2012},
  publisher = {John Wiley \& Sons},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Chilès_Delfiner\chiles2012geostatistics.pdf}
}

@book{chilès2012geostatistics,
  title = {Geostatistics: {{Modeling Spatial Uncertainty}}, {{Second Edition}}},
  author = {Chil{\`e}s, Jean-Paul and Delfiner, Pierre},
  year = {2012},
  edition = {2nd},
  publisher = {John Wiley \& Sons, Inc.},
  isbn = {978-0-470-18315-1},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Chilès_Delfiner\chilès2012geostatistics.pdf}
}

@techreport{cim2019,
  title = {{{CIM}} Estimation of Mineral Resources \& Mineral Reserves Best Practice Guidelines},
  author = {{CIM Mineral Resource \& Mineral Reserve Committee}},
  year = {2019},
  month = nov,
  institution = {{Canadian Institute of Mining, Metallurgy and Petroleum}},
  keywords = {thesis_02}
}

@article{clifton2014extending,
  title = {Extending the {{Generalised Pareto Distribution}} for {{Novelty Detection}} in {{High-Dimensional Spaces}}},
  author = {Clifton, David A. and Clifton, Lei and Hugueny, Samuel and Tarassenko, Lionel},
  year = {2014},
  month = mar,
  journal = {Journal of Signal Processing Systems},
  volume = {74},
  number = {3},
  pages = {323--339},
  issn = {1939-8115},
  doi = {10.1007/s11265-013-0835-2},
  urldate = {2022-01-14},
  abstract = {Novelty detection involves the construction of a ``model of normality'', and then classifies test data as being either ``normal'' or ``abnormal'' with respect to that model. For this reason, it is often termed one-class classification. The approach is suitable for cases in which examples of ``normal'' behaviour are commonly available, but in which cases of ``abnormal'' data are comparatively rare. When performing novelty detection, we are typically most interested in the tails of the normal model, because it is in these tails that a decision boundary between ``normal'' and ``abnormal'' areas of data space usually lies. Extreme value statistics provides an appropriate theoretical framework for modelling the tails of univariate (or low-dimensional) distributions, using the generalised Pareto distribution (GPD), which can be demonstrated to be the limiting distribution for data occurring within the tails of most practically-encountered probability distributions. This paper provides an extension of the GPD, allowing the modelling of probability distributions of arbitrarily high dimension, such as occurs when using complex, multimodel, multivariate distributions for performing novelty detection in most real-life cases. We demonstrate our extension to the GPD using examples from patient physiological monitoring, in which we have acquired data from hospital patients in large clinical studies of high-acuity wards, and in which we wish to determine ``abnormal'' patient data, such that early warning of patient physiological deterioration may be provided.},
  langid = {english},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Clifton et al\clifton2014extending.pdf}
}

@book{conn2009introduction,
  title = {Introduction to Derivative-Free Optimization},
  author = {Conn, Andrew R and Scheinberg, Katya and Vicente, Luis N},
  year = {2009},
  publisher = {SIAM}
}

@article{costa2003reducing,
  title = {Reducing the Impact of Outliers in Ore Reserves Estimation},
  author = {Costa, Joao Felipe},
  year = {2003},
  journal = {Mathematical geology},
  volume = {35},
  number = {3},
  pages = {323--345},
  publisher = {Springer},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Costa\\costa2003reducing.pdf;C\:\\Users\\benha\\Zotero\\storage\\VBTPGIRW\\A1023822315523.html}
}

@article{davis1987production,
  title = {Production of Conditional Simulations via the {{LU}} Triangular Decomposition of the Covariance Matrix},
  author = {Davis, Michael W.},
  year = {1987},
  month = feb,
  journal = {Mathematical Geology},
  volume = {19},
  number = {2},
  pages = {91--98},
  issn = {1573-8868},
  doi = {10.1007/BF00898189},
  urldate = {2023-08-17},
  abstract = {This paper reviews the turning band method and fast Fourier transform method of producing a nonconditional simulation of a multinormal random function with a given covariance structure. A review of the two common methods of conditioning the simulation to honor the data shows that they are formally equivalent. Another method for directly pondering a conditional simulation based on the LU triangular decomposition of the covariance matrix is presented. Computational and implementation difficulties are discussed.},
  langid = {english},
  keywords = {conditional simulation,fast Fourier transform,geostatistics,kriging},
  file = {D:\03 UofA\06 Reading\_zotfile\Davis\davis1987productiona.pdf}
}

@article{davison2015statistics,
  title = {Statistics of Extremes},
  author = {Davison, Anthony C and Huser, Rapha{\"e}l},
  year = {2015},
  journal = {Annual Review of Statistics and its Application},
  volume = {2},
  pages = {203--235},
  publisher = {Annual Reviews},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Davison_Huser\davison2015statistics.pdf}
}

@book{dehaan2007extreme,
  title = {Extreme Value Theory: An Introduction},
  author = {De Haan, Laurens and Ferreira, Ana},
  year = {2007},
  publisher = {Springer Science \& Business Media},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\De Haan_Ferreira\dehaan2007extreme.pdf}
}

@phdthesis{deutsch1992annealing,
  title = {Annealing Techniques Applied to Reservoir Modeling and the Integration of Geological and Engineering (Well Test) Data},
  author = {Deutsch, Clayton Vernon},
  year = {1992},
  school = {stanford university},
  file = {D:\03 UofA\06 Reading\_zotfile\Deutsch\deutsch1992annealing.pdf}
}

@article{deutsch1992geostatistical,
  title = {Geostatistical Software Library and User's Guide},
  author = {Deutsch, Clayton V. and Journel, Andre G.},
  year = {1992},
  journal = {New York},
  volume = {119},
  number = {147}
}

@article{deutsch2007recall,
  title = {A {{Recall}} of {{Factorial Kriging}} with {{Examples}} and a {{Modified Version}} of Kt3d},
  author = {Deutsch, Clayton V},
  year = {2007},
  pages = {8},
  langid = {english},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Deutsch\deutsch2007recall.pdf}
}

@article{deutsch2010display,
  title = {Display of Cross Validation/Jackknife Results},
  author = {Deutsch, Clayton V},
  year = {2010},
  journal = {Centre for Computational Geostatistics Annual Report},
  volume = {12},
  number = {406},
  pages = {1--4},
  file = {D:\03 UofA\06 Reading\_zotfile\Deutsch\deutsch2010display.pdf}
}

@article{drumond2019using,
  title = {Using {{Mahalanobis Distance}} to {{Detect}} and {{Remove Outliers}} in {{Experimental Covariograms}}},
  author = {Drumond, David Alvarenga and Rolo, Roberto Mentzingen and Costa, Jo{\~a}o Felipe Coimbra Leite},
  year = {2019},
  month = jan,
  journal = {Natural Resources Research},
  volume = {28},
  number = {1},
  pages = {145--152},
  issn = {1573-8981},
  doi = {10.1007/s11053-018-9399-y},
  urldate = {2022-01-13},
  abstract = {Experimental variograms are crucial for most geostatistical studies.In kriging, for example, the variography has a direct influence on the interpolation weights. Despite the great importance of variogram estimators in predicting geostatistical features, they are commonly influenced by outliers in the dataset. The effect of some randomly spatially distributed outliers can mask the pattern of the experimental variogram and produce a destructuration effect, implying that the true data spatial continuity cannot be reproduced. In this paper, an algorithm to detect and remove the effect of outliers in experimental variograms using the Mahalanobis distance is proposed. An example of the algorithm's application is presented, showing that the developed technique is able to satisfactorily detect and remove outliers from a variogram.},
  langid = {english},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Drumond et al\drumond2019using.pdf}
}

@article{dubey2022activation,
  title = {Activation Functions in Deep Learning: {{A}} Comprehensive Survey and Benchmark},
  shorttitle = {Activation Functions in Deep Learning},
  author = {Dubey, Shiv Ram and Singh, Satish Kumar and Chaudhuri, Bidyut Baran},
  year = {2022},
  month = sep,
  journal = {Neurocomputing},
  volume = {503},
  pages = {92--108},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2022.06.111},
  urldate = {2024-03-13},
  abstract = {Neural networks have shown tremendous growth in recent years to solve numerous problems. Various types of neural networks have been introduced to deal with different types of problems. However, the main goal of any neural network is to transform the non-linearly separable input data into more linearly separable abstract features using a hierarchy of layers. These layers are combinations of linear and nonlinear functions. The most popular and common non-linearity layers are activation functions (AFs), such as Logistic Sigmoid, Tanh, ReLU, ELU, Swish and Mish. In this paper, a comprehensive overview and survey is presented for AFs in neural networks for deep learning. Different classes of AFs such as Logistic Sigmoid and Tanh based, ReLU based, ELU based, and Learning based are covered. Several characteristics of AFs such as output range, monotonicity, and smoothness are also pointed out. A performance comparison is also performed among 18 state-of-the-art AFs with different networks on different types of data. The insights of AFs are presented to benefit the researchers for doing further research and practitioners to select among different choices. The code used for experimental comparison is released at: https://github.com/shivram1987/ActivationFunctions.},
  keywords = {Activation Functions,Convolutional neural networks,Deep learning,Neural networks,Overview,Recurrent Neural Networks},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Dubey et al\\dubey2022activation.pdf;C\:\\Users\\benha\\Zotero\\storage\\ZZFULDLK\\S0925231222008426.html}
}

@article{dutaut2021new,
  title = {A New Grade-Capping Approach Based on Coarse Duplicate Data Correlation},
  author = {Dutaut, R. V. and Marcotte, D.},
  year = {2021},
  month = may,
  journal = {Journal of the Southern African Institute of Mining and Metallurgy},
  volume = {121},
  number = {5},
  pages = {193--200},
  publisher = {{The Southern African Institute of Mining and Metallurgy}},
  issn = {2225-6253},
  doi = {10.17159/2411-9717/1379/2021},
  urldate = {2023-11-19},
  file = {D:\03 UofA\06 Reading\_zotfile\Dutaut_Marcotte\dutaut2021new.pdf}
}

@book{eidsvik2015value,
  title = {Value of Information in the Earth Sciences: {{Integrating}} Spatial Modeling and Decision Analysis},
  author = {Eidsvik, Jo and Mukerji, Tapan and Bhattacharjya, Debarun},
  year = {2015},
  publisher = {Cambridge University Press}
}

@techreport{eldorado2020,
  title = {Technical Report Ki{\c s}lada{\u g} Gold Mine Turkey},
  author = {{Eldorado Gold Corporation}},
  year = {2020},
  keywords = {thesis_02}
}

@article{emery2014simulating,
  title = {Simulating {{Large Gaussian Random Vectors Subject}} to {{Inequality Constraints}} by {{Gibbs Sampling}}},
  author = {Emery, Xavier and Arroyo, Daisy and Pel{\'a}ez, Mar{\'i}a},
  year = {2014},
  month = apr,
  journal = {Mathematical Geosciences},
  volume = {46},
  number = {3},
  pages = {265--283},
  issn = {1874-8953},
  doi = {10.1007/s11004-013-9495-9},
  urldate = {2023-08-14},
  abstract = {The Gibbs sampler is an iterative algorithm used to simulate Gaussian random vectors subject to inequality constraints. This algorithm relies on the fact that the distribution of a vector component conditioned by the other components is Gaussian, the mean and variance of which are obtained by solving a kriging system. If the number of components is large, kriging is usually applied with a moving search neighborhood, but this practice can make the simulated vector not reproduce the target correlation matrix. To avoid these problems, variations of the Gibbs sampler are presented. The conditioning to inequality constraints on the vector components can be achieved by simulated annealing or by restricting the transition matrix of the iterative algorithm. Numerical experiments indicate that both approaches provide realizations that reproduce the correlation matrix of the Gaussian random vector, but some conditioning constraints may not be satisfied when using simulated annealing. On the contrary, the restriction of the transition matrix manages to satisfy all the constraints, although at the cost of a large number of iterations.},
  langid = {english},
  keywords = {Gaussian random field,Gibbs sampler,Kriging neighborhood,Markov chain,Restriction of transition matrix,Simulated annealing,thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Emery et al\emery2014simulating.pdf}
}

@book{everitt2010cambridge,
  title = {The Cambridge Dictionary of Statistics},
  author = {Everitt, B.S. and Skrondal, A.},
  year = {2010},
  publisher = {Cambridge University Press},
  isbn = {978-0-521-76699-9},
  lccn = {2010502891},
  keywords = {thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Everitt_Skrondal\everitt2010cambridge.pdf}
}

@article{filzmoser2020multivariate,
  title = {Multivariate {{Outlier Detection}} in {{Applied Data Analysis}}: {{Global}}, {{Local}}, {{Compositional}} and {{Cellwise Outliers}}},
  shorttitle = {Multivariate {{Outlier Detection}} in {{Applied Data Analysis}}},
  author = {Filzmoser, Peter and Gregorich, Mariella},
  year = {2020},
  month = nov,
  journal = {Mathematical Geosciences},
  volume = {52},
  number = {8},
  pages = {1049--1066},
  issn = {1874-8953},
  doi = {10.1007/s11004-020-09861-6},
  urldate = {2024-03-12},
  abstract = {Outliers are encountered in all practical situations of data analysis, regardless of the discipline of application. However, the term outlier is not uniformly defined across all these fields since the differentiation between regular and irregular behaviour is naturally embedded in the subject area under consideration. Generalized approaches for outlier identification have to be modified to allow the diligent search for potential outliers. Therefore, an overview of different techniques for multivariate outlier detection is presented within the scope of selected kinds of data frequently found in the field of geosciences. In particular, three common types of data in geological studies are explored: spatial, compositional and flat data. All of these formats motivate new outlier concepts, such as local outlyingness, where the spatial information of the data is used to define a neighbourhood structure. Another type are compositional data, which nicely illustrate the fact that some kinds of data require not only adaptations to standard outlier approaches, but also transformations of the data itself before conducting the outlier search. Finally, the very recently developed concept of cellwise outlyingness, typically used for high-dimensional data, allows one to identify atypical cells in a data matrix. In practice, the different data formats can be mixed, and it is demonstrated in various examples how to proceed in such situations.},
  langid = {english},
  keywords = {Cellwise outliers,Compositional data analysis,Local outlyingness,Multivariate outlier detection,Robust statistics},
  file = {D:\03 UofA\06 Reading\_zotfile\Filzmoser_Gregorich\filzmoser2020multivariate.pdf}
}

@techreport{fiore2021,
  title = {{{NI}} 43-101 Updated Technical Report on Resources and Reserves Pan Gold Project White Pine County, Nevada},
  author = {{Fiore Gold Ltd.}},
  year = {2021},
  keywords = {thesis_02}
}

@inproceedings{fisher1928limiting,
  title = {Limiting Forms of the Frequency Distribution of the Largest or Smallest Member of a Sample},
  booktitle = {Mathematical Proceedings of the {{Cambridge}} Philosophical Society},
  author = {Fisher, Ronald Aylmer and Tippett, Leonard Henry Caleb},
  year = {1928},
  volume = {24},
  pages = {180--190},
  publisher = {Cambridge University Press},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Fisher_Tippett\fisher1928limiting.pdf}
}

@misc{fisher2019all,
  title = {All {{Models}} Are {{Wrong}}, but {{Many}} Are {{Useful}}: {{Learning}} a {{Variable}}'s {{Importance}} by {{Studying}} an {{Entire Class}} of {{Prediction Models Simultaneously}}},
  shorttitle = {All {{Models}} Are {{Wrong}}, but {{Many}} Are {{Useful}}},
  author = {Fisher, Aaron and Rudin, Cynthia and Dominici, Francesca},
  year = {2019},
  month = dec,
  number = {arXiv:1801.01489},
  eprint = {1801.01489},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1801.01489},
  urldate = {2023-08-10},
  abstract = {Variable importance (VI) tools describe how much covariates contribute to a prediction model's accuracy. However, important variables for one well-performing model (for example, a linear model \$f({\textbackslash}mathbf\{x\})={\textbackslash}mathbf\{x\}\^{}\{T\}{\textbackslash}beta\$ with a fixed coefficient vector \${\textbackslash}beta\$) may be unimportant for another model. In this paper, we propose model class reliance (MCR) as the range of VI values across all well-performing model in a prespecified class. Thus, MCR gives a more comprehensive description of importance by accounting for the fact that many prediction models, possibly of different parametric forms, may fit the data well. In the process of deriving MCR, we show several informative results for permutation-based VI estimates, based on the VI measures used in Random Forests. Specifically, we derive connections between permutation importance estimates for a single prediction model, U-statistics, conditional variable importance, conditional causal effects, and linear model coefficients. We then give probabilistic bounds for MCR, using a novel, generalizable technique. We apply MCR to a public data set of Broward County criminal records to study the reliance of recidivism prediction models on sex and race. In this application, MCR can be used to help inform VI for unknown, proprietary models.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Methodology},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Fisher et al\\fisher2019all.pdf;C\:\\Users\\benha\\Zotero\\storage\\48WPPFJ8\\1801.html}
}

@article{fourie2019limiting,
  title = {Limiting the Influence of Extreme Grades in Ordinary Kriged Estimates},
  author = {Fourie, A. and Morgan, C. and Minnitt, R.C.A.},
  year = {2019},
  journal = {Journal of the Southern African Institute of Mining and Metallurgy},
  volume = {119},
  number = {4},
  issn = {22256253, 24119717},
  doi = {10.17159/2411-9717/18/090/2019},
  urldate = {2021-10-14},
  langid = {english},
  file = {C:\Users\benha\Zotero\storage\HAKN5DWN\Fourie et al. - 2019 - Limiting the influence of extreme grades in ordina.pdf}
}

@article{frechet1927loi,
  title = {Sur La Loi de Probabilit{\'e} de l'{\'e}cart Maximum},
  author = {Fr{\'e}chet, Maurice},
  year = {1927},
  journal = {Ann. Soc. Math. Polon.},
  volume = {6},
  pages = {93--116}
}

@book{fu2003distribution,
  title = {Distribution {{Theory}} of {{Runs}} and {{Patterns}} and {{Its Applications}}: {{A Finite Markov Chain Imbedding Approach}}},
  shorttitle = {Distribution {{Theory}} of {{Runs}} and {{Patterns}} and {{Its Applications}}},
  author = {Fu, James C and Lou, W Y Wendy},
  year = {2003},
  month = jul,
  publisher = {WORLD SCIENTIFIC},
  doi = {10.1142/4669},
  urldate = {2022-04-27},
  isbn = {978-981-02-4587-0 978-981-277-920-5},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Fu_Lou\fu2003distribution.pdf}
}

@article{geman1984stochastic,
  title = {Stochastic {{Relaxation}}, {{Gibbs Distributions}}, and the {{Bayesian Restoration}} of {{Images}}},
  author = {Geman, Stuart and Geman, Donald},
  year = {1984},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-6},
  number = {6},
  pages = {721--741},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.1984.4767596},
  abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution,thesis_05},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Geman_Geman\\geman1984stochastic.pdf;C\:\\Users\\benha\\Zotero\\storage\\YY8YSXS4\\4767596.html}
}

@article{georgioudakis2020comparative,
  title = {A {{Comparative Study}} of {{Differential Evolution Variants}} in {{Constrained Structural Optimization}}},
  author = {Georgioudakis, Manolis and Plevris, Vagelis},
  year = {2020},
  journal = {Frontiers in Built Environment},
  volume = {6},
  issn = {2297-3362},
  urldate = {2023-08-08},
  abstract = {Differential evolution (DE) is a population-based metaheuristic search algorithm that optimizes a problem by iteratively improving a candidate solution based on an evolutionary process. Such algorithms make few or no assumptions about the underlying optimization problem and can quickly explore very large design spaces. DE is arguably one of the most versatile and stable population-based search algorithms that exhibits robustness to multi-modal problems. In the field of structural engineering, most practical optimization problems are associated with one or several behavioral constraints. Constrained optimization problems are quite challenging to solve due to their complexity and high nonlinearity. In this work we examine the performance of several DE variants, namely the standard DE, the composite DE (CODE), the adaptive DE with optional external archive (JADE) and the self-adaptive DE (JDE and SADE), for handling constrained structural optimization problems associated with truss structures. The performance of each DE variant is evaluated by using five well-known benchmark structures in 2D and 3D. The evaluation is done on the basis of final optimum result and the rate of convergence. Valuable conclusions are obtained from the statistical analysis which can help a structural engineer in practice to choose the suitable algorithm for such kind of problems.},
  file = {D:\03 UofA\06 Reading\_zotfile\Georgioudakis_Plevris\georgioudakis2020comparative.pdf}
}

@book{geron2019hands,
  title = {Hands-on Machine Learning with {{Scikit-Learn}}, {{Keras}}, and {{TensorFlow}}: {{Concepts}}, Tools, and Techniques to Build Intelligent Systems},
  author = {G{\'e}ron, Aur{\'e}lien},
  year = {2019},
  publisher = {" O'Reilly Media, Inc."}
}

@article{gilli2006application,
  title = {An Application of Extreme Value Theory for Measuring Financial Risk},
  author = {Gilli, Manfred and Kellezi, Evis},
  year = {2006},
  journal = {Computational Economics},
  volume = {27},
  number = {2},
  pages = {207--228},
  publisher = {Springer},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Gilli_others\gilli2006application.pdf}
}

@article{giraud2019integration,
  title = {Integration of Geoscientific Uncertainty into Geophysical Inversion by Means of Local Gradient Regularization},
  author = {Giraud, Jeremie and Lindsay, Mark and Ogarko, Vitaliy and Jessell, Mark and Martin, Roland and {Pakyuz-Charrier}, Evren},
  year = {2019},
  month = jan,
  journal = {Solid Earth},
  volume = {10},
  number = {1},
  pages = {193--210},
  publisher = {Copernicus GmbH},
  issn = {1869-9510},
  doi = {10.5194/se-10-193-2019},
  urldate = {2024-04-10},
  abstract = {We introduce a workflow integrating geological modelling uncertainty information to constrain gravity inversions. We test and apply this approach to the Yerrida Basin (Western Australia), where we focus on prospective greenstone belts beneath sedimentary cover. Geological uncertainty information is extracted from the results of a probabilistic geological modelling process using geological field data and their inferred accuracy as inputs. The uncertainty information is utilized to locally adjust the weights of a minimum-structure gradient-based regularization function constraining geophysical inversion. Our results demonstrate that this technique allows geophysical inversion to update the model preferentially in geologically less certain areas. It also indicates that inverted models are consistent with both the probabilistic geological model and geophysical data of the area, reducing interpretation uncertainty. The interpretation of inverted models reveals that the recovered greenstone belts may be shallower and thinner than previously thought.},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Giraud et al\giraud2019integration.pdf}
}

@article{gnedenko1943distribution,
  title = {Sur {{La Distribution Limite Du Terme Maximum D}}'{{Une Serie Aleatoire}}},
  author = {Gnedenko, B.},
  year = {1943},
  journal = {Annals of Mathematics},
  volume = {44},
  number = {3},
  eprint = {1968974},
  eprinttype = {jstor},
  pages = {423--453},
  publisher = {Annals of Mathematics},
  issn = {0003-486X},
  doi = {10.2307/1968974},
  urldate = {2021-10-28},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Gnedenko\gnedenko1943distribution.pdf}
}

@incollection{gomez-hernandez1993joint,
  title = {Joint {{Sequential Simulation}} of {{MultiGaussian Fields}}},
  booktitle = {Geostatistics {{Tr{\'o}ia}} '92: {{Volume}} 1},
  author = {{G{\'o}mez-Hern{\'a}ndez}, J. Jaime and Journel, Andr{\'e} G.},
  editor = {Soares, Amilcar},
  year = {1993},
  series = {Quantitative {{Geology}} and {{Geostatistics}}},
  pages = {85--94},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-011-1739-5_8},
  urldate = {2023-08-17},
  abstract = {The sequential simulation algorithm can be used for the generation of conditional realizations from either a multiGaussian random function or any non-Gaussian random function as long as its conditional distributions can be derived. The multivariate probability density function (pdf) that fully describes a random function can be written as the product of a set of univariate conditional pdfs. Drawing realizations from the multivariate pdf amounts to drawing sequentially from that series of univariate conditional pdfs. Similarly, the joint multivariate pdf of several random functions can be written as the product of a series of univariate conditional pdfs. The key step consists of the derivation of the conditional pdfs. In the case of a multiGaussian fields, these univariate conditional pdfs are known to be Gaussian with mean and variance given by the solution of a set of normal equations also known as simple cokriging equations. Sequential simulation is preferred to other techniques, such as turning bands, because of its ease of use and extreme flexibility.},
  isbn = {978-94-011-1739-5},
  langid = {english},
  keywords = {Conditional Distribution,Conditioning Data,Exponential Type,Search Neighborhood,Sequential Simulation},
  file = {D:\03 UofA\06 Reading\_zotfile\Gómez-Hernández_Journel\gomez-hernandez1993joint.pdf}
}

@article{gomez-hernandez1998be,
  title = {To Be or Not to Be Multi-{{Gaussian}}? {{A}} Reflection on Stochastic Hydrogeology},
  shorttitle = {To Be or Not to Be Multi-{{Gaussian}}?},
  author = {{G{\'o}mez-Hern{\'a}ndez}, J. Jaime and Wen, Xian-Huan},
  year = {1998},
  month = feb,
  journal = {Advances in Water Resources},
  volume = {21},
  number = {1},
  pages = {47--61},
  issn = {0309-1708},
  doi = {10.1016/S0309-1708(96)00031-0},
  urldate = {2024-02-14},
  abstract = {The multivariate Gaussian random function model is commonly used in stochastic hydrogeology to model spatial variability of log-conductivity. The multi-Gaussian model is attractive because it is fully characterized by an expected value and a covariance function or matrix, hence its mathematical simplicity and easy inference. Field data may support a Gaussian univariate distribution for log hydraulic conductivity, but, in general, there are not enough field data to support a multi-Gaussian distribution. A univariate Gaussian distribution does not imply a multi-Gaussian model. In fact, many multivariate models can share the same Gaussian histogram and covariance function, yet differ by their patterns of spatial continuity at different threshold values. Hence the decision to use a multi-Gaussian model to represent the uncertainty associated with the spatial heterogeneity of log-conductivity is not databased. Of greatest concern is the fact that a multi-Gaussian model implies the minimal spatial correlation of extreme values, a feature critical for mass transport and a feature that may be in contradiction with some geological settings, e.g. channeling. The possibility for high conductivity values to be spatially correlated should not be discarded by adopting a congenial model just because data shortage prevents refuting it. In this study, three alternatives to a multi-Gaussian model, all sharing the same Gaussian histogram and the same covariance function, but with different continuity patterns for extreme values, were considered to model the spatial variability of log-conductivity. The three alternative models, plus the traditional multi-Gaussian model, are used to perform Monte Carlo analyses of groundwater travel times from a hypothetical nuclear repository to the ground surface through a synthetic formation similar to the Finnsj{\"o}n site in Sweden. The results show that the groundwater travel times predicted by the multi-Gaussian model could be ten times slower than those predicted by the other models. The probabilities of very short travel times could be severely underestimated using the multi-Gaussian model. Consequently, if field measured data are not sufficient to determine the higher-order moments necessary to validate the multi-Gaussian model --- which is the usual situation in practice --- other alternative models to the multi-Gaussian one ought to be considered.},
  keywords = {geostatistics,Heterogeneity,mass transport,Monte Carlo simulation,non-multi-Gaussian,risk analysis,stochastic simulation,travel time,uncertainty},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Gómez-Hernández_Wen\\gomez-hernandez1998be.pdf;C\:\\Users\\benha\\Zotero\\storage\\RK8KZZ6J\\S0309170896000310.html}
}

@article{goovaerts1992factorial,
  title = {Factorial Kriging Analysis: A Useful Tool for Exploring the Structure of Multivariate Spatial Soil Information},
  shorttitle = {Factorial Kriging Analysis},
  author = {Goovaerts, P.},
  year = {1992},
  journal = {Journal of Soil Science},
  volume = {43},
  number = {4},
  pages = {597--619},
  issn = {1365-2389},
  doi = {10.1111/j.1365-2389.1992.tb00163.x},
  urldate = {2021-10-16},
  abstract = {Most studies of relations between soil properties fail to take account of their regionalized nature because of the lack of appropriate methods. This paper describes a geostatistical technique, factorial kriging analysis, that bridges the gap between classical multivariate analysis and a univariate geostatistical approach. The basic feature of the method is the fitting of a linear model of coregionalization, i.e. all experimental simple and cross-variograms are modelled with a linear combination of basic variogram functions. A particular variance-covariance matrix, the coregionalization matrix, can then be associated with each spatial scale defined by the range of the basic variogram function. Each coregionalization matrix describes relationships between variables at a given spatial scale. A principal component analysis of these matrices produces a set of components, the regionalized factors, that reflect the main features of the multivariate information for each spatial scale and whose scores are estimated by cokriging. The technique is described and illustrated with three case studies based on a simulated data set and soil survey data. The results are compared with those of the principal component analysis of the variance-covariance matrix and the variogram matrices.},
  langid = {english},
  keywords = {thesis_05},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Goovaerts\\goovaerts1992factorial.pdf;C\:\\Users\\benha\\Zotero\\storage\\RI54W7CF\\j.1365-2389.1992.tb00163.html}
}

@book{goovaerts1997geostatistics,
  title = {Geostatistics for Natural Resources Evaluation},
  author = {Goovaerts, Pierre},
  year = {1997},
  publisher = {Oxford University Press on Demand},
  file = {C:\Users\benha\Zotero\storage\6WBXREIM\books.html}
}

@incollection{guardiano1993multivariate,
  title = {Multivariate {{Geostatistics}}: {{Beyond Bivariate Moments}}},
  shorttitle = {Multivariate {{Geostatistics}}},
  booktitle = {Geostatistics {{Tr{\'o}ia}} '92},
  author = {Guardiano, Felipe B. and Srivastava, R. Mohan},
  editor = {Gradstein, F. M. and Soares, Amilcar},
  year = {1993},
  volume = {5},
  pages = {133--144},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-011-1739-5_12},
  urldate = {2022-05-26},
  isbn = {978-0-7923-2157-6 978-94-011-1739-5},
  langid = {english},
  file = {C:\Users\benha\Zotero\storage\Z8UQKRWQ\Guardiano and Srivastava - 1993 - Multivariate Geostatistics Beyond Bivariate Momen.pdf}
}

@book{gumbel1958statistics,
  title = {Statistics of Extremes},
  author = {Gumbel, Emil Julius},
  year = {1958},
  publisher = {Courier Corporation},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Gumbel\gumbel1958statistics.pdf}
}

@phdthesis{guthke2013non,
  title = {Non-Multi-{{Gaussian}} Spatial Structures: Process-Driven Natural Genesis, Manifestation, Modeling Approaches, and Influences on Dependent Processes},
  author = {Guthke, Philipp},
  year = {2013},
  file = {D:\03 UofA\06 Reading\_zotfile\Guthke\guthke2013non.pdf}
}

@article{guthke2017link,
  title = {On the Link between Natural Emergence and Manifestation of a Fundamental Non-{{Gaussian}} Geostatistical Property: {{Asymmetry}}},
  shorttitle = {On the Link between Natural Emergence and Manifestation of a Fundamental Non-{{Gaussian}} Geostatistical Property},
  author = {Guthke, Philipp and B{\'a}rdossy, Andr{\'a}s},
  year = {2017},
  month = may,
  journal = {Spatial Statistics},
  volume = {20},
  pages = {1--29},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2017.01.003},
  urldate = {2024-02-14},
  abstract = {The geostatistical workflow of data analysis, model fitting, and subsequent interpolation or simulation has recently been enhanced by several methods. These methods can be summarized under the terms 'rank-order geostatistics', for the empirical analysis part of the workflow, and 'copula geostatistics', for the theoretical foundation and the modeling (interpolation or simulation). Besides taking into account non-Gaussianity, the main advantage of this alternative way to treat geostatistical problems is the descriptive power and standardized interpretability. This paper addresses the empirical analysis part of the workflow. We investigate the interplay between structural features, statistical properties, and underlying dynamic processes of a realization of a spatial field. (1) In the first part of this paper we recapitulate and consolidate the advances in the empirical analysis part of the geostatistical workflow and put them into context of 'classical' geostatistics. We place particular emphasis on the theoretical foundation of so called asymmetry functions, because in our opinion they are the necessary first step away from Gaussian geostatistics. (2) In the second part, we rigorously analyze how specific types of structural features are related to the asymmetry of a spatial field. In the geostatistical tradition of interpreting the shape of variograms or correlation functions, we give examples of how to interpret different shapes of the asymmetry function. (3) We subsequently report how dynamic processes naturally lead to the emergence of asymmetrical (non-Gaussian) spatial structures. To demonstrate these findings, we investigate the manifestation of different spatial data sets (land surface elevation, groundwater contamination, grades of an undergraduate exam) and relate the non-Gaussian structural features to the underlying dynamic processes. Numerical process models are utilized to manifest evidence of how realistic processes naturally lead to complex non-Gaussian structures. The key purpose of this paper is to show that asymmetry is a fundamental geostatistical property and a result of different kinds of spatial processes.},
  keywords = {Asymmetry function,Copula geostatistics,Manifestation,Non-multi-Gaussian,Rank-order geostatistics,Spatial process},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Guthke_Bárdossy\\guthke2017link.pdf;C\:\\Users\\benha\\Zotero\\storage\\7USWKD8Y\\S2211675317300258.html}
}

@article{hadavand2023spatial,
  title = {Spatial Multivariate Data Imputation Using Deep Learning and Lambda Distribution},
  author = {Hadavand, Mostafa and Deutsch, Clayton V.},
  year = {2023},
  month = aug,
  journal = {Computers \& Geosciences},
  volume = {177},
  pages = {105376},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2023.105376},
  urldate = {2024-02-14},
  abstract = {Artificial neural networks (ANNs) are often used to establish a mapping between an input data set and a corresponding output. There are many applications that rely on quantifying the conditional distribution of the output given the input data set. This is often referred to as aleatoric uncertainty associated with variability of the outcome due to inherently random effects. In this paper, deep learning is used to quantify moments of the conditional distribution of a missing variable based on homotopic multivariate observations. The lambda distribution is then used to parametrize the conditional distribution based on the provided moments. Geostatistical quantification of spatial continuity complements the multivariate conditional distribution through Bayesian updating to inform multiple data imputation that accounts for the uncertainty associated with the missing variable(s). Geological data are often incomplete, and data imputation is an essential step to avoid excluding heterotopic data. The proposed data imputation framework trains multi layer perceptron (MLP) neural networks to characterize multivariate relationships inferred from homotopic training data. A case study is conducted using geological data from a lateritic Nickle deposit to demonstrate application of the proposed methodology.},
  keywords = {Gaussian mixture model,Geostatistics,Simulation},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Hadavand_Deutsch\\hadavand2023spatial.pdf;C\:\\Users\\benha\\Zotero\\storage\\ZEKJPSLQ\\S0098300423000808.html}
}

@article{harding2023probabilistic,
  title = {Probabilistic {{Modeling}} of the {{Round Mountain Gold Deposit}}: A {{Case Study}}},
  shorttitle = {Probabilistic {{Modeling}} of the {{Round Mountain Gold Deposit}}},
  author = {Harding, Ben and Lagos, Rodolfo and Pfeiffer, Nicos and Deutsch, Clayton V.},
  year = {2023},
  month = oct,
  journal = {Mining, Metallurgy \& Exploration},
  volume = {40},
  number = {5},
  pages = {1987--2006},
  issn = {2524-3470},
  doi = {10.1007/s42461-023-00787-1},
  urldate = {2024-04-23},
  abstract = {This paper documents a probabilistic resource modeling workflow for the Round Mountain epithermal gold deposit. The set of categorical and continuous variable simulated realizations provides a model of variability and uncertainty given the current orebody knowledge. These realizations can be used to quantify and understand expected deviations in reconciliation during mining and provide a more accurate measure of expected gold than an estimated model. Gold mineralization at Round Mountain is primarily contained within tertiary tuff units, which dip gently to the west and thicken towards the southern part of the orebody. Domain boundaries are modeled as combinations of lithology and alteration; alteration domains are constrained to be within the tuffs. Large-scale geologic uncertainty is strongly influenced by parameter uncertainty, particularly the input histogram. The spatial bootstrap characterizes prior global uncertainty in the input histogram for categorical and continuous variables. Categorical models are generated using hierarchical truncated pluri-Gaussian (HTPG) simulation. Continuous variable simulation is carried out within the simulated domain boundaries using trend models to account for non-stationarity.},
  langid = {english},
  keywords = {Gaussian simulation,Geostatistics,Hierarchical truncated pluri-Gaussian,Resources},
  file = {D:\03 UofA\06 Reading\_zotfile\Harding et al\harding2023probabilistic.pdf}
}

@article{hawkins1984robust,
  title = {Robust Kriging---{{A}} Proposal},
  author = {Hawkins, Douglas M. and Cressie, Noel},
  year = {1984},
  month = jan,
  journal = {Journal of the International Association for Mathematical Geology},
  volume = {16},
  number = {1},
  pages = {3--18},
  issn = {1573-8868},
  doi = {10.1007/BF01036237},
  urldate = {2023-11-15},
  abstract = {Geological data frequently have a heavy-tailed normal-in-the-middle distribution, which gives rise to grade distributions that appear to be normal except for the occurrence of a few outliers. This same situation also applies to log-transformed data to which lognormal kriging is to be applied. For such data, linear kriging is nonrobust in that (1)kriged estimates tend to infinity as the outliers do, and (2)it is also not minimum mean squared error. The more general nonlinear method of disjunctive kriging is even more nonrobust, computationally more laborious, and in the end need not produce better practical answers. We propose a robust kriging method for such nearly normal data based on linear kriging of an editing of the data. It is little more laborious than conventional linear kriging and, used in conjunction with a robust estimator of the variogram, provides good protection against the effects of data outliers. The method is also applicable to time series analysis.},
  langid = {english},
  keywords = {Geostatistics,kriging,robust estimation,time series},
  file = {D:\03 UofA\06 Reading\_zotfile\Hawkins_Cressie\hawkins1984robust.pdf}
}

@inproceedings{hazan2012extreme,
  title = {Extreme Value Statistics for Vibration Spectra Outlier Detection},
  booktitle = {International Conference on Condition Monitoring and Machinery Failure Prevention Technologies},
  author = {Hazan, Aur{\'e}lien and Lacaille, J{\'e}r{\^o}me and Madani, Kurosh},
  year = {2012},
  pages = {p--1},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Hazan et al\hazan2012extreme.pdf}
}

@article{hodge2004survey,
  title = {A Survey of Outlier Detection Methodologies},
  author = {Hodge, Victoria and Austin, Jim},
  year = {2004},
  journal = {Artificial intelligence review},
  volume = {22},
  number = {2},
  pages = {85--126},
  publisher = {Springer},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Hodge_Austin\hodge2004survey.pdf}
}

@article{hong2007improved,
  title = {Improved {{Factorial Kriging}} for {{Feature Identification}} and {{Extraction}}},
  author = {Hong, Sahyun and Deutsch, Clayton V},
  year = {2007},
  pages = {16},
  langid = {english},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Hong_Deutsch\hong2007improved.pdf}
}

@article{jha2022comparative,
  title = {A Comparative Study on Outlier Detection Techniques for Noisy Production Data from Unconventional Shale Reservoirs},
  author = {Jha, H. S. and Khanal, A. and Seikh, H. M. D. and Lee, W. J.},
  year = {2022},
  month = sep,
  journal = {Journal of Natural Gas Science and Engineering},
  volume = {105},
  pages = {104720},
  issn = {1875-5100},
  doi = {10.1016/j.jngse.2022.104720},
  urldate = {2023-11-20},
  abstract = {Decline curve analyses (DCA) and rate transient analyses (RTA) are widely used to characterize the fluid flow through porous media and forecast future production. Oil and gas production data are routinely analyzed for history matching and optimizing the well stimulation methods in hydrocarbon exploration and production lifecycle. However, outliers add significant uncertainty and non-uniqueness to results from production data analysis. This study provides a structured and comprehensive overview of five widely used outlier detection (OD) techniques for identifying and removing outliers in production data. Each OD technique measures deviation differently and, therefore, has a different outcome even when applied to the same dataset, creating the need to test several methods and find the optimal technique for identifying and removing outliers from production data. First, we generated production data from a typical multi-fractured horizontal well using a numerical reservoir simulator and added random noise to the data. Then, we used five different OD techniques to identify the prelabeled outliers from the synthetic production data. Finally, we identified the best-performing OD algorithm by comparing the various evaluation metrics such as the mean absolute error (MAE), precision, sensitivity, and F1 score. Results showed that the angle-based OD (ABOD) had the best MAE, precision, sensitivity, and F1 score of 8\%, 85\%, 98\%, and 0.90, respectively. The next best-performing OD technique was distance-based OD (DBOD), with MAE, precision, sensitivity, and F1 score of 16\%, 71\%, 100\%, and 0.83, respectively. We tested the ABOD method on several field production datasets by assuming different outlier thresholds (fraction of the data points likely to be outliers). Visual inspection of the processed data showed that the ABOD method effectively identified and removed the outliers from a relatively clean dataset (outlier threshold of 20\%) and a highly noisy dataset (outlier threshold of 80\%). This algorithm is intuitive and can effectively identify and remove outliers from the field production data to improve production forecasting, reserves estimation, and rate transient analysis for multi-fractured horizontal oil and gas reservoirs.},
  keywords = {Noisy data,Outlier detection,Production data analysis,Production forecasting,Shale Gas,Unconventional Reservoirs},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Jha et al\\jha2022comparative.pdf;C\:\\Users\\benha\\Zotero\\storage\\854V3YY2\\S1875510022003080.html}
}

@article{journel1974geostatistics,
  title = {Geostatistics for {{Conditional Simulation}} of {{Ore Bodies}}},
  author = {Journel, A. G.},
  year = {1974},
  month = aug,
  journal = {Economic Geology},
  volume = {69},
  number = {5},
  pages = {673--687},
  issn = {0361-0128},
  doi = {10.2113/gsecongeo.69.5.673},
  urldate = {2022-08-30},
  abstract = {Simulation techniques are frequently used to solve various problems of operational research for the mining industry and more generally in earth sciences (hydrogeology, gravimetry, meteorology, etc.). First, the model to be simulated is characterized; for example, the spatial dispersion of grades in an ore body. Then a simulation technique is devised, which must be operational, particularly in terms of computer time. The efficiency of the simulation produced is obviously linked to the capacity of the model to fit the main characteristics of the revealed reality. One of the most important of these characteristics, namely the spatial autocorrelation of variables, is often ignored by the models commonly presented in classical literature.The originality of conditional simulation derives: (1) from the fact that these simulations meet the particular spatial autocorrelation function (covariance or variogram) which characterizes the reality observed; (2) from the conditionalization of the experimental data, i.e., the simulated values at data locations equal the experimental values; and (3) from the possibility of working in real three-dimensional space. The simulation technique proposed (turning-bands method) consists of simulating on lines (one-dimensional space) and then turning these lines in three-dimensional space. This procedure avoids the well-known explosion of computer time and memories involved in classical procedures extended to several dimensions. The originality of using conditional simulation techniques with regard to spectral analysis techniques is presented in the third point.},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Journel\\journel1974geostatistics.pdf;C\:\\Users\\benha\\Zotero\\storage\\DGCFIMF5\\Geostatistics-for-Conditional-Simulation-of-Ore.html}
}

@article{journel1983nonparametric,
  title = {Nonparametric Estimation of Spatial Distributions},
  author = {Journel, A. G.},
  year = {1983},
  month = jun,
  journal = {Journal of the International Association for Mathematical Geology},
  volume = {15},
  number = {3},
  pages = {445--468},
  issn = {1573-8868},
  doi = {10.1007/BF01031292},
  urldate = {2021-10-22},
  abstract = {The indicator approach, whereby the data are used through their rank order, allows a nonparametric approach to the data bivariate distribution. Such rich structural information allows a nonparametric risk-qualified, estimation of local and global spatial distributions.},
  langid = {english},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Journel\journel1983nonparametric.pdf}
}

@article{journel1989nongaussian,
  title = {Non-{{Gaussian}} Data Expansion in the {{Earth Sciences}}},
  author = {Journel, A. G. and Alabert, F.},
  year = {1989},
  journal = {Terra Nova},
  volume = {1},
  number = {2},
  pages = {123--134},
  issn = {1365-3121},
  doi = {10.1111/j.1365-3121.1989.tb00344.x},
  urldate = {2021-10-22},
  abstract = {A formalism is proposed to generate alternative equiprobable images of an underlying population spatial distribution. The resulting images honour data values at their locations and reflect important characteristics of the data such as patterns of spatial connectivity of extreme-values. The formalism capitalizes on a coding of all information available into bits (0-l), which are then processed all together accounting for their patterns of correlation in space. Such common coding allows accounting for qualitative information, possibly of an interpretative nature, to complement the usually sparse hard data available in Earth Sciences applications. The approach proposed, although of a probabilistic nature, does not call for any Gaussian-type modelling or hypothesis.},
  langid = {english},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Journel_Alabert\\journel1989nongaussian.pdf;C\:\\Users\\benha\\Zotero\\storage\\BCVDMGVT\\j.1365-3121.1989.tb00344.html}
}

@article{journel1993entropy,
  title = {Entropy and Spatial Disorder},
  author = {Journel, Andr{\'e} G. and Deutsch, Clayton V.},
  year = {1993},
  month = apr,
  journal = {Mathematical Geology},
  volume = {25},
  number = {3},
  pages = {329--355},
  issn = {1573-8868},
  doi = {10.1007/BF00901422},
  urldate = {2021-10-22},
  abstract = {The majority of geostatistical estimation and simulation algorithms rely on a covariance model as the sole characteristic of the spatial distribution of the attribute under study. The limitation to a single covariance implicitly calls for a multivariate Gaussian model for either the attribute itself or for its normal scores transform. The Gaussian model could be justified on the basis that it is both analytically simple and it is a maximum entropy model, i.e., a model that minimizes unwarranted structural properties. As a consequence, the Gaussian model also maximizes spatial disorder (beyond the imposed covariance) which can cause flow simulation results performed on multiple stochastic images to be very similar; thus, the space of response uncertainty could be too narrow entailing a misleading sense of safety. The ability of the sole covariance to adequately describe spatial distributions for flow studies, and the assumption that maximum spatial disorder amounts to either no additional information or a safe prior hypothesis are questioned. This paper attempts to clarify the link between entropy and spatial disorder and to provide, through a detailed case study, an appreciation for the impact of entropy of prior random function models on the resulting response distributions.},
  langid = {english},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Journel_Deutsch\journel1993entropy.pdf}
}

@article{kerrou2008issues,
  title = {Issues in Characterizing Heterogeneity and Connectivity in Non-{{multiGaussian}} Media},
  author = {Kerrou, Jaouher and Renard, Philippe and Hendricks Franssen, Harrie-Jan and Lunati, Ivan},
  year = {2008},
  month = jan,
  journal = {Advances in Water Resources},
  volume = {31},
  number = {1},
  pages = {147--159},
  issn = {0309-1708},
  doi = {10.1016/j.advwatres.2007.07.002},
  urldate = {2024-04-11},
  abstract = {The performances of kriging, stochastic simulations and sequential self-calibration inversion are assessed when characterizing a non-multiGaussian synthetic 2D braided channel aquifer. The comparison is based on a series of criteria such as the reproduction of the original reference transmissivity or head fields, but also in terms of accuracy of flow and transport (capture zone) forecasts when the flow conditions are modified. We observe that the errors remain large even for a dense data network. In addition some unexpected behaviours are observed when large transmissivity datasets are used. In particular, we observe an increase of the bias with the number of transmissivity data and an increasing uncertainty with the number of head data. This is interpreted as a consequence of the use of an inadequate multiGaussian stochastic model that is not able to reproduce the connectivity of the original field.},
  keywords = {Aquifer characterization,Connectivity,Inverse,Kriging,Multiple-point statistics,Stochastic simulations,Uncertainty,Well-capture zones},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Kerrou et al\\kerrou2008issues.pdf;C\:\\Users\\benha\\Zotero\\storage\\XLBNEDXZ\\S0309170807001236.html}
}

@inproceedings{lantuejoul2012simulation,
  title = {Simulation of a {{Gaussian}} Random Vector: A Propagative Version of the {{Gibbs}} Sampler},
  booktitle = {The 9th International Geostatistics Congress},
  author = {Lantu{\'e}joul, Christian and Desassis, Nicolas},
  year = {2012},
  pages = {174--181},
  file = {D:\03 UofA\06 Reading\_zotfile\Lantuéjoul_Desassis\lantuejoul2012simulation.pdf}
}

@article{lauzon2020calibration,
  title = {Calibration of Random Fields by a Sequential Spectral Turning Bands Method},
  author = {Lauzon, Dany and Marcotte, Denis},
  year = {2020},
  month = feb,
  journal = {Computers \& Geosciences},
  volume = {135},
  pages = {104390},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2019.104390},
  urldate = {2024-02-13},
  abstract = {A new algorithm for calibration of conditional realizations to measured or desired response functions is presented. The Sequential-Spectral Turning Bands Method (S-STBM) builds the field by choosing the phase of each new cosine function such that the observed field response functions become increasingly calibrated. The phase selection has little influence on the spatial correlation structure but can help to meet other objectives. Conditioning by kriging is used in the algorithm main loop to impose exact hard data reproduction. A first case study illustrates the performance of the algorithm for a cyclic and asymmetric field. S-STBM is shown to reproduce similarly or better the directional asymmetry than calibrated realizations obtained by FFTMA-SA. A training image (TI) with connected low values provides the second case study where the target is the reproduction of non-centered third-order spatial moments. A third case study shows the effectiveness of the S-STBM algorithm to calibrate a Gaussian field to tracer tests. Contrary to FFTMA-SA, S-STBM works on irregular grids. Its computational complexity of O(n) and small memory requirement makes it an attractive method for calibration.},
  keywords = {Conditional simulation,Constructive calibration,High-order statistics,Spectral turning bands},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Lauzon_Marcotte\\lauzon2020calibration.pdf;C\:\\Users\\benha\\Zotero\\storage\\WKMIAIZG\\S0098300419306752.html}
}

@article{lauzon2020sequential,
  title = {The Sequential Spectral Turning Band Simulator as an Alternative to {{Gibbs}} Sampler in Large Truncated- or Pluri- {{Gaussian}} Simulations},
  author = {Lauzon, Dany and Marcotte, Denis},
  year = {2020},
  month = nov,
  journal = {Stochastic Environmental Research and Risk Assessment},
  volume = {34},
  number = {11},
  pages = {1939--1951},
  issn = {1436-3259},
  doi = {10.1007/s00477-020-01850-9},
  urldate = {2024-02-13},
  abstract = {The Sequential Spectral Turning Bands Method (S-STBM) builds Gaussian random fields (GRF) calibrated to desired response functions. An interesting application of S-STBM concerns the simulation of GRF subject to inequality constraints. S-STBM works by choosing the phase of each cosine function of the STBM algorithm instead of perturbating nodes of the GRF many thousand times using conditional distributions as in Gibbs sampler. Each chosen phase increasingly constrains the nodes to the desired inequalities. A method based on the sequential Gaussian simulation is introduced to accelerate convergence at the end of the process. Examples shown compare S-STBM approach to Gibbs sampler. Orders of magnitude reduction in computation time is achieved with our spectral method. Furthermore, examples show that the phase selection has no significant influence on the spatial correlation. Our approach is easily generalized to pluriGaussian simulations. Compared to Gibbs sampler, S-STBM is not limited to small systems (no memory limitation) and its complexity of O(n) makes it an efficient tool to simulate large GRF subject to inequality constraints.},
  langid = {english},
  keywords = {Gibbs Sampler,Inequality constraints,PluriGaussian simulation,Sequential Gaussian simulation,Spectral simulation,Truncated Gaussian random field},
  file = {D:\03 UofA\06 Reading\_zotfile\Lauzon_Marcotte\lauzon2020sequential.pdf}
}

@article{lauzon2023joint,
  title = {Joint Hydrofacies-Hydraulic Conductivity Modeling Based on a Constructive Spectral Algorithm Constrained by Transient Head Data},
  author = {Lauzon, Dany and Marcotte, Denis},
  year = {2023},
  month = sep,
  journal = {Hydrogeology Journal},
  volume = {31},
  number = {6},
  pages = {1647--1664},
  issn = {1435-0157},
  doi = {10.1007/s10040-023-02638-1},
  urldate = {2024-02-15},
  abstract = {A constructive spectral method is presented to jointly calibrate hydrofacies and hydraulic conductivity to transient pressure heads. The method iteratively constructs Gaussian random fields to model the spatial correlation of hydraulic conductivity and hydrofacies using pluriGaussian simulation. Borehole conditioning is done quickly by replacing the slow Gibbs sampler method with an approach that is based on calibrating the underlying Gaussian fields that are subject to inequality constraints. Calibration to transient pressure heads is performed by shallow optimization of the phase vectors of the continuous spectral method. A parameterization technique makes it possible to reduce phase vector optimization from multivariate to univariate. The algorithm is tested on two-dimensional (2D) and 3D synthetic regional aquifers made of three hydrofacies. It reduced the objective function by one order of magnitude in one hundred iterations. The tests on the 2D aquifers indicated that the transient hydraulic heads alone cannot provide much information about hydrofacies. However, combining them with hydrofacies observations from boreholes results in improved hydrofacies identification compared to when only borehole data are used. Similar results were obtained in the 3D aquifer case, although the improvement in aquifer identification was less pronounced. The spectral method presented makes it possible to calibrate complex aquifers to transient heads using a limited number of calls to the flow simulator. Doing so helps to characterize sub-surface heterogeneity and assess the uncertainty and geological risks associated with groundwater flow.},
  langid = {english},
  keywords = {Data assimilation,Geostatistics,Inverse modeling,Parameter uncertainty assessment,Stochastic hydrogeology},
  file = {D:\03 UofA\06 Reading\_zotfile\Lauzon_Marcotte\lauzon2023joint.pdf}
}

@article{leuangthong2004minimum,
  title = {Minimum {{Acceptance Criteria}} for {{Geostatistical Realizations}}},
  author = {Leuangthong, Oy and McLennan, Jason A. and Deutsch, Clayton V.},
  year = {2004},
  month = sep,
  journal = {Natural Resources Research},
  volume = {13},
  number = {3},
  pages = {131--141},
  issn = {1573-8981},
  doi = {10.1023/B:NARR.0000046916.91703.bb},
  urldate = {2024-03-07},
  abstract = {Geostatistical simulation is being used increasingly for numerical modeling of natural phenomena. The development of simulation as an alternative to kriging is the result of improved characterization of heterogeneity and a model of joint uncertainty. The popularity of simulation has increased in both mining and petroleum industries. Simulation is widely available in commercial software. Many of these software packages, however, do not necessarily provide the tools for careful checking of the geostatistical realizations prior to their use in decision-making. Moreover, practitioners may not understand all that should be checked. There are some basic checks that should be performed on all geostatistical models. This paper identifies (1) the minimum criteria that should be met by all geostatistical simulation models, and (2) the checks required to verify that these minimum criteria are satisfied. All realizations should honor the input information including the geological interpretation, the data values at their locations, the data distribution, and the correlation structure, within ``acceptable'' statistical fluctuations. Moreover, the uncertainty measured by the differences between simulated realizations should be a reasonable measure of uncertainty. A number of different applications are shown to illustrate the various checks. These checks should be an integral part of any simulation modeling work flow.},
  langid = {english},
  keywords = {Model validation,simulation,verification},
  file = {D:\03 UofA\06 Reading\_zotfile\Leuangthong et al\leuangthong2004minimum.pdf}
}

@article{leuangthong2015dealing,
  title = {Dealing with High-Grade Data in Resource Estimation},
  author = {Leuangthong, O. and Nowak, M.},
  year = {2015},
  journal = {Journal of the Southern African Institute of Mining and Metallurgy},
  volume = {115},
  number = {1},
  pages = {27--36},
  publisher = {{The Southern African Institute of Mining and Metallurgy}},
  keywords = {thesis_02},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Leuangthong_Nowak\\leuangthong2015dealing.pdf;C\:\\Users\\benha\\Zotero\\storage\\MIJ9JM8Z\\scielo.html}
}

@article{li2022ecod,
  title = {{{ECOD}}: {{Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions}}},
  shorttitle = {{{ECOD}}},
  author = {Li, Zheng and Zhao, Yue and Hu, Xiyang and Botta, Nicola and Ionescu, Cezar and Chen, George H.},
  year = {2022},
  month = mar,
  journal = {arXiv:2201.00382 [cs, stat]},
  eprint = {2201.00382},
  primaryclass = {cs, stat},
  urldate = {2022-05-06},
  abstract = {Outlier detection refers to the identification of data points that deviate from a general data distribution. Existing unsupervised approaches often suffer from high computational cost, complex hyperparameter tuning, and limited interpretability, especially when working with large, high-dimensional datasets. To address these issues, we present a simple yet effective algorithm called ECOD (Empirical-Cumulative-distribution-based Outlier Detection), which is inspired by the fact that outliers are often the "rare events" that appear in the tails of a distribution. In a nutshell, ECOD first estimates the underlying distribution of the input data in a nonparametric fashion by computing the empirical cumulative distribution per dimension of the data. ECOD then uses these empirical distributions to estimate tail probabilities per dimension for each data point. Finally, ECOD computes an outlier score of each data point by aggregating estimated tail probabilities across dimensions. Our contributions are as follows: (1) we propose a novel outlier detection method called ECOD, which is both parameter-free and easy to interpret; (2) we perform extensive experiments on 30 benchmark datasets, where we find that ECOD outperforms 11 state-of-the-art baselines in terms of accuracy, efficiency, and scalability; and (3) we release an easy-to-use and scalable (with distributed support) Python implementation for accessibility and reproducibility.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning,Statistics - Applications,Statistics - Machine Learning},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Li et al\\li2022ecod.pdf;C\:\\Users\\benha\\Zotero\\storage\\PUJ47SQ5\\2201.html}
}

@article{linde2015geological,
  title = {Geological Realism in Hydrogeological and Geophysical Inverse Modeling: {{A}} Review},
  shorttitle = {Geological Realism in Hydrogeological and Geophysical Inverse Modeling},
  author = {Linde, Niklas and Renard, Philippe and Mukerji, Tapan and Caers, Jef},
  year = {2015},
  month = dec,
  journal = {Advances in Water Resources},
  volume = {86},
  pages = {86--101},
  issn = {0309-1708},
  doi = {10.1016/j.advwatres.2015.09.019},
  urldate = {2024-04-10},
  abstract = {Scientific curiosity, exploration of georesources and environmental concerns are pushing the geoscientific research community toward subsurface investigations of ever-increasing complexity. This review explores various approaches to formulate and solve inverse problems in ways that effectively integrate geological concepts with geophysical and hydrogeological data. Modern geostatistical simulation algorithms can produce multiple subsurface realizations that are in agreement with conceptual geological models and statistical rock physics can be used to map these realizations into physical properties that are sensed by the geophysical or hydrogeological data. The inverse problem consists of finding one or an ensemble of such subsurface realizations that are in agreement with the data. The most general inversion frameworks are presently often computationally intractable when applied to large-scale problems and it is necessary to better understand the implications of simplifying (1) the conceptual geological model (e.g., using model compression); (2) the physical forward problem (e.g., using proxy models); and (3) the algorithm used to solve the inverse problem (e.g., Markov chain Monte Carlo or local optimization methods) to reach practical and robust solutions given today's computer resources and knowledge. We also highlight the need to not only use geophysical and hydrogeological data for parameter estimation purposes, but also to use them to falsify or corroborate alternative geological scenarios.},
  keywords = {Geophysics,Geostatistics,Hydrogeology,Hydrogeophysics,Inverse problems,Markov chain Monte Carlo},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Linde et al\\linde2015geological2.pdf;C\:\\Users\\benha\\Zotero\\storage\\G29QIUAJ\\S0309170815002262.html}
}

@book{little2002statistical,
  title = {Statistical {{Analysis}} with {{Missing Data}}},
  author = {Little, Roderick J. A. and Rubin, Donald B.},
  year = {2002},
  edition = {1},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781119013563},
  urldate = {2023-08-14},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Little_Rubin\\little2002statistical.pdf;C\:\\Users\\benha\\Zotero\\storage\\T5FRK54J\\9781119013563.html}
}

@book{little2019statistical,
  title = {Statistical Analysis with Missing Data},
  author = {Little, Roderick J. A. and Rubin, Donald B.},
  year = {2019},
  series = {Wiley Series in Probability and Statistics},
  edition = {3},
  publisher = {Wiley},
  isbn = {0-470-52679-3 978-1-118-59601-2 978-1-118-59569-5 978-0-470-52679-8},
  file = {D:\03 UofA\06 Reading\_zotfile\Roderick J. A. Little\little2019statistical.pdf}
}

@incollection{machado2012field,
  title = {Field {{Parametric Geostatistics}}---{{A Rigorous Theory}} to {{Solve Problems}} of {{Highly Skewed Distributions}}},
  booktitle = {Geostatistics {{Oslo}} 2012},
  author = {Machado, Rochana S and Armony, Miguel and Costa, Jo{\~a}o Felipe Coimbra Leite},
  year = {2012},
  pages = {383--395},
  publisher = {Springer},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Machado et al\machado2012field.pdf}
}

@article{madani2021enhanced,
  title = {Enhanced Conditional {{Co-Gibbs}} Sampling Algorithm for Data Imputation},
  author = {Madani, Nasser and Bazarbekov, Talgatbek},
  year = {2021},
  month = mar,
  journal = {Computers \& Geosciences},
  volume = {148},
  pages = {104655},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2020.104655},
  urldate = {2024-02-14},
  abstract = {The Gibbs sampler is an iterative algorithm for data imputation of a random vector at locations where values of the variable of interest are missing. In this algorithm, the simulated values converge to a Gaussian random vector distribution with zero mean and a given covariance matrix obtained by solving a simple kriging system through several iterations. In a bivariate dataset, if the principal variable for imputation depends on an auxiliary variable that is more abundant at the sample locations, this algorithm fails to produce the local and spatial cross-correlation structures. To overcome this impediment, a variant of the Gibbs sampler, the conditional Co-Gibbs sampler, has been proposed in this study, where simple kriging is replaced by three alternative cokriging paradigms: multicollocated cokriging, collocated cokriging, and homotopic cokriging. The algorithm was examined for an actual case study to statistically evaluate its performance. The results indicate that the conditional Co-Gibbs sampler with multicollocated cokriging outperformed the alternatives, including simple kriging where data imputation occurred as a consequence of ignoring the influence of the auxiliary variable, partially or totally. In addition, a computer software, provided as an open-source executable file, was used to implement the proposed algorithm for data imputation in bivariate cases.},
  keywords = {Algorithms,Data processing,Geology,Geostatistics,Spatial statistics},
  file = {D:\03 UofA\06 Reading\_zotfile\Madani_Bazarbekov\madani2021enhanced.pdf}
}

@article{maleki2014capping,
  title = {Capping and Kriging Grades with Long-Tailed Distributions},
  author = {Maleki, M. and Madani, N. and Emery, X.},
  year = {2014},
  journal = {Journal of the Southern African Institute of Mining and Metallurgy},
  volume = {114},
  number = {3},
  pages = {255--263},
  publisher = {{The Southern African Institute of Mining and Metallurgy}},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Maleki et al\\maleki2014capping.pdf;C\:\\Users\\benha\\Zotero\\storage\\UDIIMC5J\\scielo.html}
}

@article{matheron1963principles,
  title = {Principles of Geostatistics},
  author = {Matheron, Georges},
  year = {1963},
  journal = {Economic geology},
  volume = {58},
  number = {8},
  pages = {1246--1266},
  publisher = {Society of Economic Geologists},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Matheron\\matheron1963principles.pdf;C\:\\Users\\benha\\Zotero\\storage\\FHBA3RRH\\Principles-of-geostatistics.html}
}

@techreport{matheron1982factorial,
  title = {Pour Une Analyse Krigeante Des Donn{\'e}es R{\'e}gionalis{\'e}es},
  author = {Matheron, Georges},
  year = {1982},
  number = {N-732},
  institution = {Ecole des Mines de Paris},
  urldate = {2021-10-28},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Matheron\matheron1982factorial.pdf}
}

@book{matheron2019matheron,
  title = {Matheron's {{Theory}} of {{Regionalised Variables}}},
  author = {Matheron, Georges},
  editor = {{Pawlowsky-Glahn}, Vera and Serra, Jean},
  year = {2019},
  series = {International {{Association}} for {{Mathematical Geology Studies}} in {{Mathematical Geology}}},
  publisher = {Oxford University Press},
  address = {Oxford},
  doi = {10.1093/oso/9780198835660.001.0001},
  urldate = {2021-10-26},
  abstract = {This book has never been published before, although its contents have provided the basis for hundreds of papers, theses, and books on geostatistics. The chapters are based on the lectures of a summer course given by Georges Matheron in 1970; initially written in French, they were translated into English by Charles Huijbregts. They do not contain mathematical technicalities or practical case studies; instead, they present major topics like estimation variances, kriging systems, mining estimation, and intrinsic theory, all of which are established by simple proofs. The reader is invited to wonder about the physical meaning of the notions Matheron deals with. When Matheron wrote these lectures, he considered the theory of linear geostatistics complete; however, what was an ending for Matheron has been the starting point for most geostatisticians. Many discovered the book's content indirectly, via the many borrowings one can find in several books; in such a situation, it is always instructive to come back to the original document, where the author's motivations, his physical intuitions, and his thoughts on the meaning of what he does are detailed. The decision to publish this book was motivated by the desire to introduce Matheron's work to a larger audience. The book has remained faithful to the original notes while introducing a common structure for the chapters and sections, numbering equations sequentially within each chapter, numbering the figures (most of which were redrawn) sequentially, and adding captions. In addition, Matheron's comments on the exercises, or suggestions for solutions, have been added.},
  isbn = {978-0-19-883566-0},
  langid = {english},
  keywords = {extension variance,intrinsic theory,kriging,linear geostatistics,mining estimation},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Matheron et al\matheron2019matheron2.pdf}
}

@article{mclachlan2019finite,
  title = {Finite {{Mixture Models}}},
  author = {McLachlan, Geoffrey J. and Lee, Sharon X. and Rathnayake, Suren I.},
  year = {2019},
  month = mar,
  journal = {Annual Review of Statistics and Its Application},
  volume = {6},
  number = {Volume 6, 2019},
  pages = {355--378},
  publisher = {Annual Reviews},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-031017-100325},
  urldate = {2024-04-03},
  abstract = {The important role of finite mixture models in the statistical analysis of data is underscored by the ever-increasing rate at which articles on mixture applications appear in the statistical and general scientific literature. The aim of this article is to provide an up-to-date account of the theory and methodological developments underlying the applications of finite mixture models. Because of their flexibility, mixture models are being increasingly exploited as a convenient, semiparametric way in which to model unknown distributional shapes. This is in addition to their obvious applications where there is group-structure in the data or where the aim is to explore the data for such structure, as in a cluster analysis. It has now been three decades since the publication of the monograph by McLachlan \&amp; Basford (1988) with an emphasis on the potential usefulness of mixture models for inference and clustering. Since then, mixture models have attracted the interest of many researchers and have found many new and interesting fields of application. Thus, the literature on mixture models has expanded enormously, and as a consequence, the bibliography here can only provide selected coverage.},
  langid = {english},
  file = {C:\Users\benha\Zotero\storage\4RTEK94L\annurev-statistics-031017-100325.html}
}

@techreport{medgold2021,
  title = {{{PRELIMINARY ECONOMIC ASSESSMENT AND NI}} 43-101 {{TECHNICAL REPORT FOR THE MEDGOLD TLAMINO PROJECT LICENCES}}, {{SERBIA}}},
  author = {{Medgold Resources Corp.}},
  year = {2021},
  keywords = {thesis_02}
}

@article{mises1936distribution,
  title = {La Distribution de La plus Grande de n Valeurs},
  author = {von Mises, R},
  year = {1936},
  journal = {Rev. Math. Interbalcanic Union},
  volume = {1},
  pages = {141--160}
}

@article{mohamed2014rdel,
  title = {{{RDEL}}: {{Restart Differential Evolution}} Algorithm with {{Local Search Mutation}} for Global Numerical Optimization},
  shorttitle = {{{RDEL}}},
  author = {Mohamed, Ali Wagdy},
  year = {2014},
  month = nov,
  journal = {Egyptian Informatics Journal},
  volume = {15},
  number = {3},
  pages = {175--188},
  issn = {1110-8665},
  doi = {10.1016/j.eij.2014.07.001},
  urldate = {2023-08-08},
  abstract = {In this paper, a novel version of Differential Evolution (DE) algorithm based on a couple of local search mutation and a restart mechanism for solving global numerical optimization problems over continuous space is presented. The proposed algorithm is named as Restart Differential Evolution algorithm with Local Search Mutation (RDEL). In RDEL, inspired by Particle Swarm Optimization (PSO), a novel local mutation rule based on the position of the best and the worst individuals among the entire population of a particular generation is introduced. The novel local mutation scheme is joined with the basic mutation rule through a linear decreasing function. The proposed local mutation scheme is proven to enhance local search tendency of the basic DE and speed up the convergence. Furthermore, a restart mechanism based on random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme is combined to avoid stagnation and/or premature convergence. Additionally, an exponent increased crossover probability rule and a uniform scaling factors of DE are introduced to promote the diversity of the population and to improve the search process, respectively. The performance of RDEL is investigated and compared with basic differential evolution, and state-of-the-art parameter adaptive differential evolution variants. It is discovered that the proposed modifications significantly improve the performance of DE in terms of quality of solution, efficiency and robustness.},
  langid = {english},
  keywords = {Differential evolution,Evolutionary computation,Global numerical optimization,Local search mutation,Restart mechanism},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Mohamed\\mohamed2014rdel.pdf;C\:\\Users\\benha\\Zotero\\storage\\4D5QJGVC\\S1110866514000279.html}
}

@article{mood1940distribution,
  title = {The {{Distribution Theory}} of {{Runs}}},
  author = {Mood, A. M.},
  year = {1940},
  journal = {The Annals of Mathematical Statistics},
  volume = {11},
  number = {4},
  eprint = {2235718},
  eprinttype = {jstor},
  pages = {367--392},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  urldate = {2022-04-21},
  file = {D:\03 UofA\06 Reading\_zotfile\Mood\mood1940distribution.pdf}
}

@misc{mullner2011modern,
  title = {Modern Hierarchical, Agglomerative Clustering Algorithms},
  author = {M{\"u}llner, Daniel},
  year = {2011},
  month = sep,
  number = {arXiv:1109.2378},
  eprint = {1109.2378},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-12-11},
  abstract = {This paper presents algorithms for hierarchical, agglomerative clustering which perform most efficiently in the general-purpose setup that is given in modern standard software. Requirements are: (1) the input data is given by pairwise dissimilarities between data points, but extensions to vector data are also discussed (2) the output is a "stepwise dendrogram", a data structure which is shared by all implementations in current standard software. We present algorithms (old and new) which perform clustering in this setting efficiently, both in an asymptotic worst-case analysis and from a practical point of view. The main contributions of this paper are: (1) We present a new algorithm which is suitable for any distance update scheme and performs significantly better than the existing algorithms. (2) We prove the correctness of two algorithms by Rohlf and Murtagh, which is necessary in each case for different reasons. (3) We give well-founded recommendations for the best current algorithms for the various agglomerative clustering schemes.},
  archiveprefix = {arxiv},
  keywords = {62H30,Computer Science - Data Structures and Algorithms,I.5.3,Statistics - Machine Learning,thesis_06},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Müllner\\mullner2011modern.pdf;C\:\\Users\\benha\\Zotero\\storage\\RBT9X7UZ\\1109.html}
}

@article{nava-flores2023high,
  title = {High {{Resolution Model}} of the {{Vinton Salt-Dome Cap Rock}} by {{Joint Inversion}} of the {{Full Tensor Gravity Gradient Data}} with the {{Simulated Annealing Global Optimization Method}}},
  author = {{Nava-Flores}, Mauricio and {Ortiz-Alem{\'a}n}, Carlos and {Urrutia-Fucugauchi}, Jaime},
  year = {2023},
  month = mar,
  journal = {Pure and Applied Geophysics},
  volume = {180},
  number = {3},
  pages = {983--1014},
  issn = {1420-9136},
  doi = {10.1007/s00024-023-03227-9},
  urldate = {2024-04-04},
  abstract = {We present a 3D high-resolution modeling methodology based on the interpretation of gravity gradient data and its joint inversion with the simulated annealing (SA) global optimization method. The geometry of the model, used as computational domain in the solution of the forward and inverse problems, is defined with an irregular ensemble of cubic prisms that recreates the interpreted shape of the target, derived from the results of applying different interpretation methods to the gravity gradient data. In our inversion approach, the linear inverse problem resulting from the domain discretization is not solved. Instead, the cost function is explored with the SA algorithm, its low misfit region is identified, and models belonging to it are selected for obtaining the mean model, which represents the most likely model among them, as well as for estimating its uncertainty. The SA inversion algorithm we applied was numerically optimized to reduce the computational burden required by the forward problem, and it was driven by optimal tuning parameters, determined by a parametric analysis. Tests on synthetic data show the efficiency of our methodology to obtain a model that approximates the synthetic target and the usefulness of the estimated uncertainty to complement the interpretation. Finally, by applying our methodology to gravity gradient data acquired over the Vinton dome located in Louisiana, USA, we obtained results that are in agreement with geological information and previous studies.},
  langid = {english},
  keywords = {3D gravity gradient modeling,gravity gradient data processing,joint inversion,simulated annealing},
  file = {D:\03 UofA\06 Reading\_zotfile\Nava-Flores et al\nava-flores2023high.pdf}
}

@article{neves2015geostatistical,
  title = {Geostatistical {{Analysis}} in {{Extremes}}: {{An Overview}}},
  author = {Neves, M Manuela},
  year = {2015},
  journal = {Mathematics of Energy and Climate Change},
  pages = {229--245},
  publisher = {Springer},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Neves\neves2015geostatistical.pdf}
}

@techreport{ngm2020,
  title = {{{TECHNICAL REPORT ON THE CARLIN COMPLEX}}, {{EUREKA AND ELKO COUNTIES}}, {{STATE OF NEVADA}}, {{USA}}},
  author = {{Nevada Gold Mines LLC}},
  year = {2020},
  keywords = {thesis_02}
}

@inproceedings{nowak2008generalized,
  title = {Generalized Binary Search},
  booktitle = {2008 46th {{Annual Allerton Conference}} on {{Communication}}, {{Control}}, and {{Computing}}},
  author = {Nowak, Robert},
  year = {2008},
  month = sep,
  pages = {568--574},
  doi = {10.1109/ALLERTON.2008.4797609},
  urldate = {2024-02-17},
  abstract = {This paper studies a generalization of the classic binary search problem of locating a desired value within a sorted list. The classic problem can be viewed as determining the correct one-dimensional, binary-valued threshold function from a finite class of such functions based on queries taking the form of point samples of the function. The classic problem is also equivalent to a simple binary encoding of the threshold location. This paper extends binary search to learning more general binary-valued functions. Specifically, if the set of target functions and queries satisfy certain geometrical relationships, then an algorithm, based on selecting a query that is maximally discriminating at each step, will determine the correct function in a number of steps that is logarithmic in the number of functions under consideration. Examples of classes satisfying the geometrical relationships include linear separators in multiple dimensions. Extensions to handle noise are also discussed. Possible applications include machine learning, channel coding, and sequential experimental design.},
  keywords = {Channel coding,Design for experiments,Feedback,Machine learning,Particle separators,Probability distribution,Sampling methods,Search problems,thesis_05,Uncertainty},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Nowak\\nowak2008generalized.pdf;C\:\\Users\\benha\\Zotero\\storage\\4QDUPKVN\\4797609.html}
}

@inproceedings{nowak2013suggestions,
  title = {Suggestions for Good Capping Practices from Historical Literature},
  booktitle = {Proceedings of the 23rd {{World Mining Congress}} 2013},
  author = {Nowak, M. and Leuangthong, O. and Srivastava, R. M.},
  year = {2013},
  publisher = {{Canadian Institute of Mining, Metallurgy and Petroleum Montreal}},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Nowak et al\nowak2013suggestions.pdf}
}

@incollection{nowak2019optimal,
  title = {Optimal Drill Hole Spacing for Resource Classification},
  booktitle = {Mining {{Goes Digital}}},
  author = {Nowak, Marek and Leuangthong, Oy},
  year = {2019},
  publisher = {CRC Press},
  abstract = {Regulatory bodies around the world have relied on similar definitions for mineral resource categories, and subdivide mineral resources in order of increasing geological confidence: Inferred, Indicated and Measured. Major investment and development decisions are based on a correct assignment of a resource to a proper category. The progression to mineral reserves reporting requires at least the categorization of Indicated and/or Measured resources. As such, the assignment of a mineral resource to an Indicated category should be recognized as a necessary step to advance towards the feasibility of a project.                      Allocation of mineral resource categories often relies on some geostatistical tools, of which drill hole spacing is perhaps most common. This paper looks at procedures to determine the optimal drill hole spacing required for allocation of a portion of resources to an Indicated category in metal deposits. These procedures are differentiated into two main groups based on their simplicity and stage of application: (1) general assessment of adequate drill hole spacing; and (2) local assessment of uncertainty on estimated grade within large panels representing monthly or quarterly production. At an early exploration stage general assessment of optimal drill hole spacing for an assignment to an Indicated category is quite adequate. On the other hand, at a pre-feasibility stage simulation studies represent the best tool for resource categorization. Practical examples from a case study the authors have worked on will be presented.},
  isbn = {978-0-429-32077-4},
  file = {D:\03 UofA\06 Reading\_zotfile\Nowak_Leuangthong\nowak2019optimal.pdf}
}

@article{ortiz2002calculation,
  title = {Calculation of {{Uncertainty}} in the {{Variogram}}},
  author = {Ortiz, Juli{\'a}n and Deutsch, Clayton V.},
  year = {2002},
  month = feb,
  journal = {Mathematical Geology},
  volume = {34},
  number = {2},
  pages = {169--183},
  issn = {1573-8868},
  doi = {10.1023/A:1014412218427},
  urldate = {2024-03-26},
  abstract = {There are often limited data available in early stages of geostatistical modeling. This leads to considerable uncertainty in statistical parameters including the variogram. This article presents an approach to calculate the uncertainty in the variogram. A methodology to transfer this uncertainty through geostatistical simulation and decision making is also presented.},
  langid = {english},
  keywords = {decision making,multi-Gaussian,multipoint statistics},
  file = {D:\03 UofA\06 Reading\_zotfile\Ortiz_Deutsch\ortiz2002calculation.pdf}
}

@phdthesis{ortiz2003characterization,
  title = {Characterization of High Order Correlation for Enhanced Indicator Simulation.},
  author = {Ortiz, Juli{\'a}n},
  year = {2003},
  file = {D:\03 UofA\06 Reading\_zotfile\Ortiz\ortiz2003characterization2.pdf}
}

@techreport{osiko2020,
  title = {{{NI}} 43-101 Technical Report and Mineral Resource Estimate for the Cariboo Gold Project, British Columbia, Canada},
  author = {{Osisko Gold Royalties Ltd}},
  year = {2020},
  keywords = {thesis_02}
}

@article{pang2022deep,
  title = {Deep {{Learning}} for {{Anomaly Detection}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{Anomaly Detection}}},
  author = {Pang, Guansong and Shen, Chunhua and Cao, Longbing and van den Hengel, Anton},
  year = {2022},
  month = mar,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {2},
  eprint = {2007.02500},
  primaryclass = {cs, stat},
  pages = {1--38},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3439950},
  urldate = {2024-04-16},
  abstract = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This paper surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in three high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages and disadvantages, and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Pang et al\\pang2022deep.pdf;C\:\\Users\\benha\\Zotero\\storage\\5VKTMXJ2\\2007.html}
}

@article{pardo-iguzquiza2012varboot,
  title = {{{VARBOOT}}: {{A}} Spatial Bootstrap Program for Semivariogram Uncertainty Assessment},
  shorttitle = {{{VARBOOT}}},
  author = {{Pardo-Ig{\'u}zquiza}, Eulogio and Olea, Ricardo A.},
  year = {2012},
  month = apr,
  journal = {Computers \& Geosciences},
  volume = {41},
  pages = {188--198},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2011.09.002},
  urldate = {2024-03-26},
  abstract = {In applied geostatistics, the semivariogram is commonly estimated from experimental data, producing an empirical semivariogram for a specified number of discrete lags. In a second stage, a model defined by a few parameters is fitted to the empirical semivariogram. As the experimental data are usually few and sparsely located, there is considerable uncertainty about the calculated semivariogram values (uncertainty of the empirical semivariogram) and about the parameters of any model fitted to them (uncertainty of the estimated model parameters). In this paper, the uncertainty in the modeling of the empirical semivariogram is numerically assessed by the generalized bootstrap, which is an extension of the classic bootstrap procedure modified for spatially correlated data. A computer program is described and provided for the assessment of those uncertainties. In particular, the program provides for the empirical semivariogram: the standard errors, the bootstrap percentile confidence intervals, the complete variance--covariance matrix, standard deviation correlation matrix. A public domain, natural dataset is used to illustrate the performance of the program. A promising result is that, for any distance, the median of the bootstrap distribution for the empirical semivariogram approximates more closely the underlying semivariogram than the estimate derived from the empirical sample.},
  keywords = {Bootstrap percentile confidence interval,Correlated data,Model parameter uncertainty,Spatial covariance,Standard error},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Pardo-Igúzquiza_Olea\\pardo-iguzquiza2012varboot.pdf;C\:\\Users\\benha\\Zotero\\storage\\CKS5E4DN\\S0098300411003025.html}
}

@article{parker1991statistical,
  title = {Statistical Treatment of Outlier Data in Epithermal Gold Deposit Reserve Estimation},
  author = {Parker, {\relax HM}},
  year = {1991},
  journal = {Mathematical Geology},
  volume = {23},
  number = {2},
  pages = {175--199},
  publisher = {Springer},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Parker\parker1991statistical.pdf}
}

@techreport{parker2006,
  title = {Technical Report of the Rock Creek Property, Nome, Alaska, {{USA}}},
  author = {Parker, {\relax HM}},
  year = {2006},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Parker\parker2006.pdf}
}

@article{parrish1997geologist,
  title = {Geologist's Gordian Knot: {{To}} Cut or Not to Cut},
  author = {Parrish, I.S},
  year = {1997},
  journal = {Mining Engineering},
  volume = {49},
  pages = {45--49},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Parrish\parrish1997geologist.pdf}
}

@techreport{pasofino2020,
  title = {{{DUGBE GOLD PROJECT}}, {{LIBERIA NI}} 43-101 {{TECHNICAL REPORT}}},
  author = {{Pasofino Gold Ltd.}},
  year = {2020}
}

@article{pickands1975statistical,
  title = {Statistical Inference Using Extreme Order Statistics},
  author = {Pickands, James},
  year = {1975},
  journal = {Annals of statistics},
  volume = {3},
  number = {1},
  pages = {119--131},
  publisher = {Institute of Mathematical Statistics},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Pickands_others\pickands1975statistical.pdf}
}

@phdthesis{pinto2020independent,
  title = {Independent {{Factor Simulation}} for {{Improved Multivariate Geostatistics}}},
  author = {Pinto, Felipe Cabral},
  year = {2020},
  langid = {english},
  school = {University of Alberta},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Pinto\pinto2020independent.pdf}
}

@article{piotrowski2017review,
  title = {Review of {{Differential Evolution}} Population Size},
  author = {Piotrowski, Adam P.},
  year = {2017},
  month = feb,
  journal = {Swarm and Evolutionary Computation},
  volume = {32},
  pages = {1--24},
  issn = {2210-6502},
  doi = {10.1016/j.swevo.2016.05.003},
  urldate = {2023-12-06},
  abstract = {Population size of Differential Evolution (DE) algorithms is often specified by user and remains fixed during run. During the first decade since the introduction of DE the opinion that its population size should be related to the problem dimensionality prevailed, later the approaches to DE population size setting diversified. In large number of recently introduced DE algorithms the population size is considered to be problem-independent and often fixed to 100 or 50 individuals, but alongside a number of DE variants with flexible population size have been proposed. The present paper briefly reviews the opinions regarding DE population size setting and verifies the impact of the population size on the performance of DE algorithms. Ten DE algorithms with fixed population size, each with at least five different population size settings, and four DE algorithms with flexible population size are tested on CEC2005 benchmarks and CEC2011 real-world problems. It is found that the inappropriate choice of the population size may severely hamper the performance of each DE algorithm. Although the best choice of the population size depends on the specific algorithm, number of allowed function calls and problem to be solved, some rough guidelines may be sketched. When the maximum number of function calls is set to classical values, i.e. those specified for CEC2005 and CEC2011 competitions, for low-dimensional problems (with dimensionality below 30) the population size equal to 100 individuals is suggested; population sizes smaller than 50 are rarely advised. For higher-dimensional artificial problems the population size should often depend on the problem dimensionality d and be set to 3d--5d. Unfortunately, setting proper population size for higher-dimensional real-world problems (d{$>$}40) turns out too problem and algorithm-dependent to give any general guide; 200 individuals may be a first guess, but many DE approaches would need a much different choice, ranging from 50 to 10d. However, quite clear relation between the population size and the convergence speed has been found, showing that the fewer function calls are available, the lower population sizes perform better. Based on the extensive experimental results the use of adaptive population size is highly recommended, especially for higher-dimensional and real-world problems. However, which specific algorithms with population size adaptation perform better depends on the number of function calls allowed.},
  keywords = {Adaptive control parameters,Differential Evolution,Evolutionary Algorithms,Metaheuristics,Population size},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Piotrowski\\piotrowski2017review.pdf;C\:\\Users\\benha\\Zotero\\storage\\9Z4QG6EA\\S2210650216300268.html}
}

@techreport{pretium2020,
  title = {Technical Report on the Brucejack Gold Mine, Northwest British Columbia},
  author = {{Pretium Resources Inc.}},
  year = {2020},
  keywords = {thesis_02}
}

@incollection{price2013differential,
  title = {Differential {{Evolution}}},
  booktitle = {Handbook of {{Optimization}}: {{From Classical}} to {{Modern Approach}}},
  author = {Price, Kenneth V.},
  editor = {Zelinka, Ivan and Sn{\'a}{\v s}el, V{\'a}clav and Abraham, Ajith},
  year = {2013},
  pages = {187--214},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-30504-7_8},
  urldate = {2024-03-15},
  abstract = {After an introduction that includes a discussion of the classic random walk, this paper presents a step-by-step development of the differential evolution (DE) global numerical optimization algorithm. Five fundamental DE strategies, each more complex than the last, are evaluated based on their conformance to invariance and symmetry principles, degree of control parameter dependence, computational efficiency and response to randomization. Optimal control parameter settings for the family of convex, quadratic functions are empirically derived.},
  isbn = {978-3-642-30504-7},
  langid = {english},
  keywords = {Differential Evolution,Differential Evolution Algorithm,Random Walk,Success Performance,Target Vector},
  file = {D:\03 UofA\06 Reading\_zotfile\Price\price2013differential.pdf}
}

@book{pyrcz2014geostatistical,
  title = {Geostatistical Reservoir Modeling},
  author = {Pyrcz, Michael J. and Deutsch, Clayton V.},
  year = {2014},
  publisher = {Oxford university press},
  file = {C:\Users\benha\Zotero\storage\3MK9UYA7\books.html}
}

@article{qu2018geostatistical,
  title = {Geostatistical {{Simulation}} with a {{Trend Using Gaussian Mixture Models}}},
  author = {Qu, Jianan and Deutsch, Clayton V.},
  year = {2018},
  month = jul,
  journal = {Natural Resources Research},
  volume = {27},
  number = {3},
  pages = {347--363},
  issn = {1573-8981},
  doi = {10.1007/s11053-017-9354-3},
  urldate = {2022-09-20},
  abstract = {Geostatistics applies statistics to quantitatively describe geological sites and assess the uncertainty due to incomplete sampling. Strong assumptions are required regarding the location independence of statistical parameters to construct numerical models with geostatistical tools. Most geological data exhibit large-scale deterministic trends together with short-scale variations. Such location dependence violates the common geostatistical assumption of stationarity. The trend-like deterministic features should be modeled prior to conventional geostatistical prediction and accounted for in subsequent geostatistical calculations. The challenge of using a trend in geostatistical simulation algorithms for the continuous variable is the subject of this paper. A stepwise conditional transformation with a Gaussian mixture model is considered to provide a stable and artifact-free numerical model. The complex features of the regionalized variable in the presence of a trend are removed in the forward transformation and restored in the back transformation. The Gaussian mixture model provides a seamless bin-free approach to transformation. Data from a copper deposit were used as an example. These data show an apparent trend unsuitable for conventional geostatistical algorithms. The result shows that the proposed algorithm leads to improved geostatistical models.},
  langid = {english},
  keywords = {Non-stationary regionalized variable,Sequential Gaussian simulation,Stepwise conditional transformation},
  file = {D:\03 UofA\06 Reading\_zotfile\Qu_Deutsch\qu2018geostatistical.pdf}
}

@article{qu2021anomaly,
  title = {Anomaly {{Detection}} in {{Hyperspectral Imagery Based}} on {{Gaussian Mixture Model}}},
  author = {Qu, Jiahui and Du, Qian and Li, Yunsong and Tian, Long and Xia, Haoming},
  year = {2021},
  month = nov,
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {59},
  number = {11},
  pages = {9504--9517},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2020.3038722},
  urldate = {2024-04-18},
  abstract = {Hyperspectral images (HSIs) with rich spectral information have been widely used in many fields. Anomaly detection is one of the most interesting and important applications. In this article, a novel Gaussian mixture model (GMM)-based anomaly detection (GMMD) method for HSI is proposed. The main contributions of this article are a new GMM-based extraction approach for extracting the anomaly pixels and an effective GMM-based weighting approach for fusing the extracted anomaly results. Specifically, based on the fact that the spectral values of anomaly pixels in some bands are different from those of background pixels, we propose a GMM-based anomaly extraction approach in which the HSI is characterized by the GMM and the anomaly pixels are extracted by a range prescribed by the GMM parameters. In order to fuse the extracted anomaly results, the GMM-based weighting method is introduced to adaptively construct the detection map. The detection map is rectified by using a guided filter to obtain the final anomaly detection map. Experimental results conducted on four hyperspectral data sets demonstrate the superior performance of the proposed GMMD method.},
  keywords = {Anomaly detection,anomaly extraction,band fusion,Correlation,Gaussian distribution,Gaussian mixture model,Gaussian mixture model (GMM),hyperspectral image (HSI),Hyperspectral imaging,Partitioning algorithms,Rivers},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Qu et al\\qu2021anomaly.pdf;C\:\\Users\\benha\\Zotero\\storage\\ZKRFD2JZ\\9277875.html}
}

@book{reiss2007statistical,
  title = {Statistical {{Analysis}} of {{Extreme Values}}: {{With Applications}} to {{Insurance}}, {{Finance}}, {{Hydrology}} and {{Other Fields}}},
  author = {Reiss, Rolf-Dieter and Thomas, Michael},
  year = {2007},
  publisher = {Springer Science \& Business Media},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Reiss_Thomas\reiss2007statistical.pdf}
}

@article{renard2011conditioning,
  title = {Conditioning {{Facies Simulations}} with {{Connectivity Data}}},
  author = {Renard, Philippe and Straubhaar, Julien and Caers, Jef and Mariethoz, Gr{\'e}goire},
  year = {2011},
  month = nov,
  journal = {Mathematical Geosciences},
  volume = {43},
  number = {8},
  pages = {879--903},
  issn = {1874-8961, 1874-8953},
  doi = {10.1007/s11004-011-9363-4},
  urldate = {2022-04-28},
  abstract = {When characterizing and simulating underground reservoirs for flow simulations, one of the key characteristics that needs to be reproduced accurately is its connectivity. More precisely, field observations frequently allow the identification of specific points in space that are connected. For example, in hydrogeology, tracer tests are frequently conducted that show which springs are connected to which sink-hole. Similarly well tests often allow connectivity information in a petroleum reservoir to be provided.},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Renard et al\renard2011conditioning.pdf}
}

@article{renard2013connectivity,
  title = {Connectivity Metrics for Subsurface Flow and Transport},
  author = {Renard, Philippe and Allard, Denis},
  year = {2013},
  month = jan,
  journal = {Advances in Water Resources},
  series = {35th {{Year Anniversary Issue}}},
  volume = {51},
  pages = {168--196},
  issn = {0309-1708},
  doi = {10.1016/j.advwatres.2011.12.001},
  urldate = {2024-02-14},
  abstract = {Understanding the role of connectivity for the characterization of heterogeneous porous aquifers or reservoirs is a very active and new field of research. In that framework, connectivity metrics are becoming important tools to describe a reservoir. In this paper, we provide a review of the various metrics that were proposed so far, and we classify them in four main groups. We define first the static connectivity metrics which depend only on the connectivity structure of the parameter fields (hydraulic conductivity or geological facies). By contrast, dynamic connectivity metrics are related to physical processes such as flow or transport. The dynamic metrics depend on the problem configuration and on the specific physics that is considered. Most dynamic connectivity metrics are directly expressed as a function of an upscaled physical parameter describing the overall behavior of the media. Another important distinction is that connectivity metrics can either be global or localized. The global metrics are not related to a specific location while the localized metrics relate to one or several specific points in the field. Using these metrics to characterize a given aquifer requires the possibility to measure dynamic connectivity metrics in the field, to relate them with static connectivity metrics, and to constrain models with those information. Some tools are already available for these different steps and reviewed here, but they are not yet routinely integrated in practical applications. This is why new steps should be added in hydrogeological studies to infer the connectivity structure and to better constrain the models. These steps must include specific field methodologies, interpretation techniques, and modeling tools to provide more realistic and more reliable forecasts in a broad range of applications.},
  keywords = {Connectivity,Effective permeability,Euler number,Heterogeneous media,Percolation,Review},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Renard_Allard\\renard2013connectivity.pdf;C\:\\Users\\benha\\Zotero\\storage\\RNC93ULY\\S0309170811002223.html}
}

@article{rios2013derivativefree,
  title = {Derivative-Free Optimization: A Review of Algorithms and Comparison of Software Implementations},
  shorttitle = {Derivative-Free Optimization},
  author = {Rios, Luis Miguel and Sahinidis, Nikolaos V.},
  year = {2013},
  month = jul,
  journal = {Journal of Global Optimization},
  volume = {56},
  number = {3},
  pages = {1247--1293},
  issn = {1573-2916},
  doi = {10.1007/s10898-012-9951-y},
  urldate = {2024-03-15},
  abstract = {This paper addresses the solution of bound-constrained optimization problems using algorithms that require only the availability of objective function values but no derivative information. We refer to these algorithms as derivative-free algorithms. Fueled by a growing number of applications in science and engineering, the development of derivative-free optimization algorithms has long been studied, and it has found renewed interest in recent time. Along with many derivative-free algorithms, many software implementations have also appeared. The paper presents a review of derivative-free algorithms, followed by a systematic comparison of 22 related implementations using a test set of 502 problems. The test bed includes convex and nonconvex problems, smooth as well as nonsmooth problems. The algorithms were tested under the same conditions and ranked under several criteria, including their ability to find near-global solutions for nonconvex problems, improve a given starting point, and refine a near-optimal solution. A total of 112,448 problem instances were solved. We find that the ability of all these solvers to obtain good solutions diminishes with increasing problem size. For the problems used in this study, TOMLAB/MULTIMIN, TOMLAB/GLCCLUSTER, MCS and TOMLAB/LGO are better, on average, than other derivative-free solvers in terms of solution quality within 2,500 function evaluations. These global solvers outperform local solvers even for convex problems. Finally, TOMLAB/OQNLP, NEWUOA, and TOMLAB/MULTIMIN show superior performance in terms of refining a near-optimal solution.},
  langid = {english},
  keywords = {Derivative-free algorithms,Direct search methods,Surrogate models},
  file = {D:\03 UofA\06 Reading\_zotfile\Rios_Sahinidis\rios2013derivativefree.pdf}
}

@article{rivoirard2013topcut,
  title = {A Top-Cut Model for Deposits with Heavy-Tailed Grade Distribution},
  author = {Rivoirard, Jacques and Demange, Claude and Freulon, Xavier and L{\'e}cureuil, Aur{\'e}lie and Bellot, Nicolas},
  year = {2013},
  journal = {Mathematical geosciences},
  volume = {45},
  number = {8},
  pages = {967--982},
  publisher = {Springer},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Rivoirard et al\rivoirard2013topcut.pdf}
}

@article{roberts1999novelty,
  title = {Novelty Detection Using Extreme Value Statistics},
  author = {Roberts, Stephen J},
  year = {1999},
  journal = {IEE Proceedings-Vision, Image and Signal Processing},
  volume = {146},
  number = {3},
  pages = {124--129},
  publisher = {IET},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Roberts\roberts1999novelty.pdf}
}

@article{roberts2000extreme,
  title = {Extreme Value Statistics for Novelty Detection in Biomedical Data Processing},
  author = {Roberts, Stephen J},
  year = {2000},
  journal = {IEE Proceedings-Science, Measurement and Technology},
  volume = {147},
  number = {6},
  pages = {363--367},
  publisher = {IET},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Roberts\roberts2000extreme.pdf}
}

@incollection{rojas1996backpropagation,
  title = {The {{Backpropagation Algorithm}}},
  booktitle = {Neural {{Networks}}: {{A Systematic Introduction}}},
  author = {Rojas, Ra{\'u}l},
  editor = {Rojas, Ra{\'u}l},
  year = {1996},
  pages = {149--182},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-61068-4_7},
  urldate = {2024-03-13},
  abstract = {We saw in the last chapter that multilayered networks are capable of computing a wider range of Boolean functions than networks with a single layer of computing units. However the computational effort needed for finding the correct combination of weights increases substantially when more parameters and more complicated topologies are considered. In this chapter we discuss a popular learning method capable of handling such large learning problems---the backpropagation algorithm. This numerical method was used by different research communities in different contexts, was discovered and rediscovered, until in 1985 it found its way into connectionist AI mainly through the work of the PDP group [382]. It has been one of the most studied and used algorithms for neural networks learning ever since.},
  isbn = {978-3-642-61068-4},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Rojas\rojas1996backpropagation.pdf}
}

@inproceedings{roscoe1996cutting,
  title = {Cutting Curves for Grade Estimation and Grade Control in Gold Mines},
  booktitle = {98th Annual General Meeting},
  author = {Roscoe, W.E},
  year = {1996},
  month = apr,
  publisher = {{Canadian Institute of Mining, Metallurgy and Petroleum}},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Roscoe\roscoe1996cutting.pdf}
}

@book{rossi2013mineral,
  title = {Mineral Resource Estimation},
  author = {Rossi, Mario E. and Deutsch, Clayton V.},
  year = {2013},
  publisher = {Springer Science \& Business Media},
  file = {C:\Users\benha\Zotero\storage\V3SMKWS5\books.html}
}

@article{rukhin2010statistical,
  title = {A {{Statistical Test Suite}} for {{Random}} and {{Pseudorandom Number Generators}} for {{Cryptographic Applications}}},
  author = {Rukhin, Andrew and Soto, Juan and Nechvatal, James and Barker, Elaine and Leigh, Stefan and Levenson, Mark and Banks, David and Heckert, Alan and Dray, James},
  year = {2010},
  pages = {131},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Rukhin et al\rukhin2010statistical.pdf}
}

@article{schlather2003dependence,
  title = {A Dependence Measure for Multivariate and Spatial Extreme Values: {{Properties}} and Inference},
  author = {Schlather, Martin and Tawn, Jonathan A},
  year = {2003},
  journal = {Biometrika},
  volume = {90},
  number = {1},
  pages = {139--156},
  publisher = {Oxford University Press},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Schlather_Tawn\schlather2003dependence.pdf}
}

@book{sen2013global,
  title = {Global {{Optimization Methods}} in {{Geophysical Inversion}}},
  author = {Sen, Mrinal K. and Stoffa, Paul L.},
  year = {2013},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511997570},
  urldate = {2024-04-11},
  abstract = {Providing an up-to-date overview of the most popular global optimization methods used in interpreting geophysical observations, this new edition includes a detailed description of the theoretical development underlying each method and a thorough explanation of the design, implementation and limitations of algorithms. New and expanded chapters provide details of recently developed methods, such as the neighborhood algorithm, particle swarm optimization, hybrid Monte Carlo and multi-chain MCMC methods. Other chapters include new examples of applications, from uncertainty in climate modeling to whole Earth studies. Several different examples of geophysical inversion, including joint inversion of disparate geophysical datasets, are provided to help readers design algorithms for their own applications. This is an authoritative and valuable text for researchers and graduate students in geophysics, inverse theory and exploration geoscience, and an important resource for professionals working in engineering and petroleum exploration.},
  isbn = {978-1-107-01190-8},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Sen_Stoffa\\sen2013global.pdf;C\:\\Users\\benha\\Zotero\\storage\\X9HZ8INL\\C2B23286E6BCC2177117431CB568101C.html}
}

@article{sharma2020activation,
  title = {{{ACTIVATION FUNCTIONS IN NEURAL NETWORKS}}},
  author = {Sharma, Siddharth and Sharma, Simone and Athaiya, Anidhya},
  year = {2020},
  month = may,
  journal = {International Journal of Engineering Applied Sciences and Technology},
  volume = {04},
  number = {12},
  pages = {310--316},
  issn = {24552143},
  doi = {10.33564/IJEAST.2020.v04i12.054},
  urldate = {2024-03-13},
  abstract = {Artificial Neural Networks are inspired from the human brain and the network of neurons present in the brain. The information is processed and passed on from one neuron to another through neuro synaptic junctions. Similarly, in artificial neural networks there are different layers of cells arranged and connected to each other. The output/information from the inner layers of the neural network are passed on to the next layers and finally to the outermost layer which gives the output. The input to the outer layer is provided nonlinearity to inner layers' output so that it can be further processed. In an Artificial Neural Network, activation functions are very important as they help in learning and making sense of non-linear and complicated mappings between the inputs and corresponding outputs.},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Sharma et al\sharma2020activation.pdf}
}

@inproceedings{siffer2017anomaly,
  title = {Anomaly Detection in Streams with Extreme Value Theory},
  booktitle = {Proceedings of the 23rd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Siffer, Alban and Fouque, Pierre-Alain and Termier, Alexandre and Largouet, Christine},
  year = {2017},
  pages = {1067--1075},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Siffer et al\siffer2017anomaly.pdf}
}

@article{silva2017multiple,
  title = {Multiple Imputation Framework for Data Assignment in Truncated Pluri-{{Gaussian}} Simulation},
  author = {Silva, Diogo S. F. and Deutsch, Clayton V.},
  year = {2017},
  month = nov,
  journal = {Stochastic Environmental Research and Risk Assessment},
  volume = {31},
  number = {9},
  pages = {2251--2263},
  issn = {1436-3259},
  doi = {10.1007/s00477-016-1309-4},
  urldate = {2023-08-14},
  abstract = {Truncated pluri-Gaussian simulation (TPGS) is suitable for the simulation of categorical variables that show natural ordering as the TPGS technique can consider transition probabilities. The TPGS assumes that categorical variables are the result of the truncation of underlying latent variables. In practice, only the categorical variables are observed. This translates the practical application of TPGS into a missing data problem in which all latent variables are missing. Latent variables are required at data locations in order to condition categorical realizations to observed categorical data. The imputation of missing latent variables at data locations is often achieved by either assigning constant values or spatially simulating latent variables subject to categorical observations. Realizations of latent variables can be used to condition all model realizations. Using a single realization or a constant value to condition all realizations is the same as assuming that latent variables are known at the data locations and this assumption affects uncertainty near data locations. The techniques for imputation of latent variables in TPGS framework are investigated in this article and their impact on uncertainty of simulated categorical models and possible effects on factors affecting decision making are explored. It is shown that the use of single realization of latent variables leads to underestimation of uncertainty and overestimation of measured resources while the use constant values for latent variables may lead to considerable over or underestimation of measured resources. The results highlight the importance of multiple data imputation in the context of TPGS.},
  langid = {english},
  keywords = {Geomodeling,Geostatistics,Gibbs sampler,Missing data analysis,thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Silva_Deutsch\silva2017multiple.pdf}
}

@misc{silva2018enhanced,
  title = {Enhanced {{Geologic Modeling}} of {{Multiple Categorical Variables}}},
  author = {Silva, Diogo},
  year = 2018,
  journal = {ERA},
  doi = {10.7939/R30G3HD9R},
  urldate = {2023-08-15},
  abstract = {Widely spaced data sets from drilling are used in the mining and petroleum industries to model subsurface resources. These data sets have...},
  howpublished = {https://era.library.ualberta.ca/items/9ab8ab60-cb8f-4d7d-9551-3c602956b0ad},
  langid = {english},
  keywords = {thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Silva\silva2018enhanced.pdf}
}

@article{silva2018multivariate,
  title = {Multivariate Data Imputation Using {{Gaussian}} Mixture Models},
  author = {Silva, Diogo S. F. and Deutsch, Clayton V.},
  year = {2018},
  month = oct,
  journal = {Spatial Statistics},
  volume = {27},
  pages = {74--90},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2016.11.002},
  urldate = {2023-08-14},
  abstract = {Availability of high dimensional geological data has become common in the mining and petroleum industries. Data sets are often complex and require advanced multivariate geostatistical techniques. Multivariate data transformation is a common step of such advanced workflows and its application requires equally sampled (isotopic) data at all data locations. Samples with missing variables are common in geological data sets for many reasons. The missing data must be imputed (inferred) to permit the measured data to be used to their full extent. Imputation methods for geological data should address spatial structure and multivariate complexity. The published techniques that account for these considerations make strong assumptions regarding conditional distributions and are computationally demanding in presence of many data. A Gaussian mixture model fitted to the multivariate data is proposed in this paper to provide stability in fitting multivariate data and to significantly improve computational efficiency. The proposed approach is demonstrated using a lateritic Nickel data set. The proposed improvement is shown to decrease computational time by two orders of magnitude for the example while also consistently enhancing results in several performance tests.},
  keywords = {Geostatistics,Missing data analysis,Modeling,Semi-parametric,thesis_05},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Silva_Deutsch\\silva2018multivariate.pdf;C\:\\Users\\benha\\Zotero\\storage\\NMCSMPRH\\S2211675316301300.html}
}

@article{silva2021classification,
  title = {On the Classification and Treatment of Outliers in a Spatial Context: {{A Bayesian Updating}} Approach},
  shorttitle = {On the Classification and Treatment of Outliers in a Spatial Context},
  author = {Silva, Victor Miguel},
  year = {2021},
  month = jul,
  journal = {REM - International Engineering Journal},
  volume = {74},
  pages = {379--389},
  publisher = {Funda{\c c}{\~a}o Gorceix},
  issn = {2448-167X},
  doi = {10.1590/0370-44672021740003},
  urldate = {2022-01-17},
  abstract = {Abstract Checking and treating extreme values is commonplace in modelling workflows. The main methods to manage outliers may be categorized into graphical, Kriging- and simulation-based approaches. While graphical methods usually classify outliers from a global perspective, geostatistical methods evaluate outliers in a local context. Ordinary-Kriging based approaches are affected by conditional bias associated with the distribution tail(s), impacting on the correct classification of extreme values; the simulation method is based on the fact that geostatistical simulation is robust for outlier values. However, this approach ignores the interaction among outliers in the same neighborhood. The proposed approach considers that there are two values available at every sampled position, the sampled value and the conditional probability estimated from nearby data through cross-validation; the sampled value. Each value outside the user-defined threshold is classified as an outlier and is edited by merging the sampled and kriged value through Bayesian Updating. The proposed method is performed in normal-score units using Simple Kriging to (i) correctly estimate conditional distributions in the cross-validation step; (ii) avoid conditional bias; and (iii) minimize the outlier influence on experimental-variogram modelling. The proposed method is compared to three other widely used methods in a case study of a gold deposit. The proposed method substantially improved the local accuracy and reduced the number of misclassified blocks of a reference model.},
  langid = {english},
  keywords = {Bayesian updating,extreme values,geostatistics,outliers},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Silva\\silva2021classification.pdf;C\:\\Users\\benha\\Zotero\\storage\\ECSJQ6GY\\Q9gywB7zhHZHnpRHfcmq8bF.html}
}

@article{solow1985bootstrapping,
  title = {Bootstrapping Correlated Data},
  author = {Solow, Andrew R.},
  year = {1985},
  month = oct,
  journal = {Journal of the International Association for Mathematical Geology},
  volume = {17},
  number = {7},
  pages = {769--775},
  issn = {1573-8868},
  doi = {10.1007/BF01031616},
  urldate = {2024-04-15},
  langid = {english},
  keywords = {bootstrap,estimation variance,sampling distribution},
  file = {D:\03 UofA\06 Reading\_zotfile\Solow\solow1985bootstrapping.pdf}
}

@book{tarantola2005inverse,
  title = {Inverse Problem Theory and Methods for Model Parameter Estimation},
  author = {Tarantola, Albert},
  year = {2005},
  eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898717921},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898717921},
  file = {D:\03 UofA\06 Reading\_zotfile\Tarantola\tarantola2005inverse.pdf}
}

@techreport{tristar2021,
  title = {Mineral Resource Update for the Castelo de Sonhos Gold Project, Par{\'a} State, Brazil},
  author = {{TriStar Gold Inc.}},
  year = {2021},
  keywords = {thesis_02}
}

@book{tukey1977exploratory,
  title = {Exploratory Data Analysis},
  author = {Tukey, John W},
  year = {1977},
  volume = {2},
  publisher = {Reading, MA},
  keywords = {thesis_02},
  file = {D:\03 UofA\06 Reading\_zotfile\Tukey_others\tukey1977exploratory.pdf}
}

@article{vincent2021mik,
  title = {{{MIK}} vs {{MG}} in {{Non-Gaussian Environments}}},
  author = {Vincent, Jeremy and Deutsch, Clayton},
  year = {2021},
  pages = {13},
  langid = {english},
  file = {D:\03 UofA\06 Reading\_zotfile\Vincent_Deutsch\vincent2021mik.pdf}
}

@phdthesis{vincent2021multipleindicator,
  title = {Multiple-{{Indicator Kriging}} of {{Gaussian}} and {{Non-Gaussian Data}}},
  author = {Vincent, Jeremy D.},
  year = {2021},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Vincent\\vincent2021multipleindicator.pdf;C\:\\Users\\benha\\Zotero\\storage\\F8QA2H3Y\\60c554b1-02e4-40c0-b8c7-233eb3f0babe.html}
}

@incollection{wackernagel1988geostatistical,
  title = {Geostatistical {{Techniques}} for {{Interpreting Multivariate Spatial Information}}},
  booktitle = {Quantitative {{Analysis}} of {{Mineral}} and {{Energy Resources}}},
  author = {Wackernagel, Hans},
  editor = {Chung, C. F. and Fabbri, A. G. and {Sinding-Larsen}, R.},
  year = {1988},
  series = {{{NATO ASI Series}}},
  pages = {393--409},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-009-4029-1_24},
  urldate = {2021-11-04},
  abstract = {Several geostatistical techniques for exploring the structure of spatially distributed multivariate data are presented. The techniques are based on a combination of variogram modelling, principal component analysis and cokriging. Some possibilities to map the essential features of the multivariate spatial structure of the data are discussed. An example using geochemical data is given with an interpretation.},
  isbn = {978-94-009-4029-1},
  langid = {english},
  keywords = {Distance Class,Experimental Variogram,Geostatistical Technique,Spatial Component,Variogram Model},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Wackernagel\wackernagel1988geostatistical.pdf}
}

@article{wang2019progress,
  title = {Progress in Outlier Detection Techniques: {{A}} Survey},
  author = {Wang, Hongzhi and Bah, Mohamed Jaward and Hammad, Mohamed},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {107964--108000},
  publisher = {IEEE},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Wang et al\wang2019progress.pdf}
}

@techreport{Wilde2007,
  type = {{{CCG}} Annual Report 9},
  title = {Wide Array Declustering for Representative Distributions ({{The Ultimate DECLUS Program}})},
  author = {Wilde, B. J},
  year = {2007},
  address = {Edmonton AB},
  institution = {University of Alberta},
  keywords = {CCG,thesis_06}
}

@article{yan2020multivariate,
  title = {Multivariate Transformed {{Gaussian}} Processes},
  author = {Yan, Yuan and Jeong, Jaehong and Genton, Marc G.},
  year = {2020},
  journal = {Japanese Journal of Statistics and Data Science},
  volume = {3},
  number = {1},
  pages = {129--152},
  publisher = {Springer},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Yan et al\\yan2020multivariate.pdf;C\:\\Users\\benha\\Zotero\\storage\\VQFWCZQ8\\s42081-019-00068-6.html}
}

@article{zhou2014inverse,
  title = {Inverse Methods in Hydrogeology: {{Evolution}} and Recent Trends},
  shorttitle = {Inverse Methods in Hydrogeology},
  author = {Zhou, Haiyan and {G{\'o}mez-Hern{\'a}ndez}, J. Jaime and Li, Liangping},
  year = {2014},
  month = jan,
  journal = {Advances in Water Resources},
  volume = {63},
  pages = {22--37},
  issn = {0309-1708},
  doi = {10.1016/j.advwatres.2013.10.014},
  urldate = {2024-02-15},
  abstract = {Parameter identification is an essential step in constructing a groundwater model. The process of recognizing model parameter values by conditioning on observed data of the state variable is referred to as the inverse problem. A series of inverse methods has been proposed to solve the inverse problem, ranging from trial-and-error manual calibration to the current complex automatic data assimilation algorithms. This paper does not attempt to be another overview paper on inverse models, but rather to analyze and track the evolution of the inverse methods over the last decades, mostly within the realm of hydrogeology, revealing their transformation, motivation and recent trends. Issues confronted by the inverse problem, such as dealing with multiGaussianity and whether or not to preserve the prior statistics are discussed.},
  keywords = {Data assimilation,Groundwater modeling,Heterogeneity,Parameter identification,Uncertainty},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Zhou et al\\zhou2014inverse2.pdf;C\:\\Users\\benha\\Zotero\\storage\\W3HDII2X\\S0309170813002017.html}
}
