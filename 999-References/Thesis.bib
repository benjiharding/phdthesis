@book{armstrong2011plurigaussian,
  title = {Plurigaussian {{Simulations}} in {{Geosciences}}},
  author = {Armstrong, Margaret and Galli, Alain and Beucher, H{\'e}l{\`e}ne and Loc'h, Gaelle and Renard, Didier and Doligez, Brigitte and Eschard, R{\'e}mi and Geffroy, Francois},
  year = {2011},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-19607-2},
  urldate = {2024-02-14},
  isbn = {978-3-642-19606-5 978-3-642-19607-2},
  langid = {english},
  keywords = {Geostatistics,Mining,Petroleum,Simulations},
  file = {D:\03 UofA\06 Reading\_zotfile\Armstrong et al\armstrong2011plurigaussian.pdf}
}

@article{arroyo2020iterative,
  title = {Iterative Algorithms for Non-Conditional and Conditional Simulation of {{Gaussian}} Random Vectors},
  author = {Arroyo, Daisy and Emery, Xavier},
  year = {2020},
  month = oct,
  journal = {Stochastic Environmental Research and Risk Assessment},
  volume = {34},
  number = {10},
  pages = {1523--1541},
  issn = {1436-3259},
  doi = {10.1007/s00477-020-01875-0},
  urldate = {2024-02-13},
  abstract = {The conditional simulation of Gaussian random vectors is widely used in geostatistical~applications to quantify uncertainty in regionalized phenomena that have been observed at finitely many sampling locations. Two iterative algorithms are presented to deal with such a simulation. The first one is a variation of the propagative version of the Gibbs sampler aimed at simulating the random vector without any conditioning data. The novelty of the presented algorithm stems from the introduction of a relaxation parameter that, if adequately chosen, allows quickening the rates of convergence and mixing of the sampler. The second algorithm is meant to convert the non-conditional simulation into a conditional one, based on the successive over-relaxation method. Again, a relaxation parameter allows quickening the convergence in distribution to the desired conditional random vector. Both algorithms are applicable in a very general setting and avoid the pivoting, inversion, square rooting or decomposition of the variance-covariance matrix of the vector to be simulated, thus reduce the computation costs and memory requirements with respect to other discrete~geostatistical simulation approaches.},
  langid = {english},
  keywords = {Gauss-Seidel method,Gaussian random fields,Gibbs sampler,Mixing,Successive over-relaxation method},
  file = {D:\03 UofA\06 Reading\_zotfile\Arroyo_Emery\arroyo2020iterative.pdf}
}

@techreport{artemis2020,
  title = {Blackwater Gold Project British Columbia - {{NI}} 43-101 Technical Report on Pre-Feasibility Study},
  author = {{Artemis Gold Inc.}},
  year = {2020},
  keywords = {thesis_02}
}

@techreport{banyan2020,
  title = {{{TECHNICAL REPORT ON THE AURMAC PROPERTY}}, {{MAYO MINING DISTRICT YUKON TERRITORY}}, {{CANADA}}},
  author = {{Banyan Gold Corp.}},
  year = {2020},
  keywords = {thesis_02}
}

@article{barnett2014projection,
  title = {Projection {{Pursuit Multivariate Transform}}},
  author = {Barnett, Ryan M. and Manchuk, John G. and Deutsch, Clayton V.},
  year = {2014},
  month = apr,
  journal = {Mathematical Geosciences},
  volume = {46},
  number = {3},
  pages = {337--359},
  issn = {1874-8953},
  doi = {10.1007/s11004-013-9497-7},
  urldate = {2022-09-20},
  abstract = {Transforming complex multivariate geological data to a Gaussian distribution is an important and challenging problem in geostatistics. A~variety of transforms are available for this goal, but struggle with high dimensional data sets. Projection pursuit density estimation (PPDE) is a well-established nonparametric method for estimating the joint density of multivariate data. A~central component of the PPDE algorithm transforms the original data toward a multivariate Gaussian distribution. The PPDE approach is modified to map complex data to a multivariate Gaussian distribution within a geostatistical modeling context. Traditional modeling may then take place on the transformed Gaussian data, with a back-transform used to return simulated variables to their original units. This approach is referred to as the projection pursuit multivariate transform (PPMT). The PPMT shows the potential to be an effective means for modeling high dimensional and complex geologic data. The PPMT algorithm is developed before discussing considerations and limitations. A~case study compares modeling results against more common techniques to demonstrate the value and place of the PPMT within geostatistics.},
  langid = {english},
  keywords = {Geostatistical Modeling,Kernel Density Estimation,Projection Index,Projection Pursuit,Radial Point Interpolation Method},
  file = {D:\03 UofA\06 Reading\_zotfile\Barnett et al\barnett2014projection.pdf}
}

@article{barnett2015multivariate,
  title = {Multivariate {{Imputation}} of {{Unequally Sampled Geological Variables}}},
  author = {Barnett, Ryan M. and Deutsch, Clayton V.},
  year = {2015},
  month = oct,
  journal = {Mathematical Geosciences},
  volume = {47},
  number = {7},
  pages = {791--817},
  issn = {1874-8953},
  doi = {10.1007/s11004-014-9580-8},
  urldate = {2023-08-14},
  abstract = {Unequally sampled data pose a practical and significant problem for geostatistical modeling. Multivariate transformations are frequently applied in modeling workflows to reproduce the multivariate relationships of geological data. Unfortunately, these transformations may only be applied to data observations that sample all of the variables. In the case of unequal sampling, practitioners must decide between excluding incomplete observations and imputing (inferring) the missing values. While imputation is recommended by missing data theorists, the use of deterministic methods such as regression is generally discouraged. Instead, techniques such as multiple imputation (MI) are advocated to increase the accuracy, decrease the bias, and capture the uncertainty of imputed values. As missing data theory has received little attention within geostatistical literature and practice, MI has not been adapted from its conventional form to be suitable for geological data. To address this, geostatistical algorithms are integrated within an MI framework to produce parametric and non-parametric methods. Synthetic and geometallurgical case studies are used to demonstrate the feasibility of each method, where techniques that use both spatial and colocated information are shown to outperform the alternatives.},
  langid = {english},
  keywords = {Geostatistics,Missing data analysis,Modeling,Statistics,thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Barnett_Deutsch\barnett2015multivariate.pdf}
}

@techreport{cardinal2019,
  title = {Namdini Gold Project Feasibility Study {{NI}} 43-101 Technical Report, Ghana, West Africa},
  author = {{Cardinal Resources}},
  year = {2019},
  keywords = {thesis_02}
}

@techreport{cartier2020,
  title = {{{NI}} 43-101 Technical Report and Mineral Resource Estimate for the Central, North and South Gold Corridors on the Chimo Mine Project, Qu{\'e}bec, Canada},
  author = {{Cartier Resources Inc.}},
  year = {2020},
  keywords = {thesis_02}
}

@misc{carvalho2017overview,
  title = {An {{Overview}} of {{Multiple Indicator Kriging}}},
  author = {Carvalho, Dhaniel and Deutsch, Clayton V},
  year = {2017},
  month = jan,
  urldate = {2022-10-03},
  howpublished = {https://geostatisticslessons.com/lessons/mikoverview},
  keywords = {thesis_02},
  file = {C:\Users\benha\Zotero\storage\J53QYQC4\mikoverview.html}
}

@techreport{cim2019,
  title = {{{CIM}} Estimation of Mineral Resources \& Mineral Reserves Best Practice Guidelines},
  author = {{CIM Mineral Resource \& Mineral Reserve Committee}},
  year = {2019},
  month = nov,
  institution = {{Canadian Institute of Mining, Metallurgy and Petroleum}},
  keywords = {thesis_02}
}

@article{davis1987production,
  title = {Production of Conditional Simulations via the {{LU}} Triangular Decomposition of the Covariance Matrix},
  author = {Davis, Michael W.},
  year = {1987},
  month = feb,
  journal = {Mathematical Geology},
  volume = {19},
  number = {2},
  pages = {91--98},
  issn = {1573-8868},
  doi = {10.1007/BF00898189},
  urldate = {2023-08-17},
  abstract = {This paper reviews the turning band method and fast Fourier transform method of producing a nonconditional simulation of a multinormal random function with a given covariance structure. A review of the two common methods of conditioning the simulation to honor the data shows that they are formally equivalent. Another method for directly pondering a conditional simulation based on the LU triangular decomposition of the covariance matrix is presented. Computational and implementation difficulties are discussed.},
  langid = {english},
  keywords = {conditional simulation,fast Fourier transform,geostatistics,kriging},
  file = {D:\03 UofA\06 Reading\_zotfile\Davis\davis1987productiona.pdf}
}

@article{deutsch2010display,
  title = {Display of Cross Validation/Jackknife Results},
  author = {Deutsch, Clayton V},
  year = {2010},
  journal = {Centre for Computational Geostatistics Annual Report},
  volume = {12},
  number = {406},
  pages = {1--4},
  file = {D:\03 UofA\06 Reading\_zotfile\Deutsch\deutsch2010display.pdf}
}

@techreport{eldorado2020,
  title = {Technical Report Ki{\c s}lada{\u g} Gold Mine Turkey},
  author = {{Eldorado Gold Corporation}},
  year = {2020},
  keywords = {thesis_02}
}

@article{emery2014simulating,
  title = {Simulating {{Large Gaussian Random Vectors Subject}} to {{Inequality Constraints}} by {{Gibbs Sampling}}},
  author = {Emery, Xavier and Arroyo, Daisy and Pel{\'a}ez, Mar{\'i}a},
  year = {2014},
  month = apr,
  journal = {Mathematical Geosciences},
  volume = {46},
  number = {3},
  pages = {265--283},
  issn = {1874-8953},
  doi = {10.1007/s11004-013-9495-9},
  urldate = {2023-08-14},
  abstract = {The Gibbs sampler is an iterative algorithm used to simulate Gaussian random vectors subject to inequality constraints. This algorithm relies on the fact that the distribution of a vector component conditioned by the other components is Gaussian, the mean and variance of which are obtained by solving a kriging system. If the number of components is large, kriging is usually applied with a moving search neighborhood, but this practice can make the simulated vector not reproduce the target correlation matrix. To avoid these problems, variations of the Gibbs sampler are presented. The conditioning to inequality constraints on the vector components can be achieved by simulated annealing or by restricting the transition matrix of the iterative algorithm. Numerical experiments indicate that both approaches provide realizations that reproduce the correlation matrix of the Gaussian random vector, but some conditioning constraints may not be satisfied when using simulated annealing. On the contrary, the restriction of the transition matrix manages to satisfy all the constraints, although at the cost of a large number of iterations.},
  langid = {english},
  keywords = {Gaussian random field,Gibbs sampler,Kriging neighborhood,Markov chain,Restriction of transition matrix,Simulated annealing,thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Emery et al\emery2014simulating.pdf}
}

@book{everitt2010cambridge,
  title = {The Cambridge Dictionary of Statistics},
  author = {Everitt, B.S. and Skrondal, A.},
  year = {2010},
  publisher = {Cambridge University Press},
  isbn = {978-0-521-76699-9},
  lccn = {2010502891},
  keywords = {thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Everitt_Skrondal\everitt2010cambridge.pdf}
}

@techreport{fiore2021,
  title = {{{NI}} 43-101 Updated Technical Report on Resources and Reserves Pan Gold Project White Pine County, Nevada},
  author = {{Fiore Gold Ltd.}},
  year = {2021},
  keywords = {thesis_02}
}

@article{geman1984stochastic,
  title = {Stochastic {{Relaxation}}, {{Gibbs Distributions}}, and the {{Bayesian Restoration}} of {{Images}}},
  author = {Geman, Stuart and Geman, Donald},
  year = {1984},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-6},
  number = {6},
  pages = {721--741},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.1984.4767596},
  abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution,thesis_05},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Geman_Geman\\geman1984stochastic.pdf;C\:\\Users\\benha\\Zotero\\storage\\YY8YSXS4\\4767596.html}
}

@incollection{gomez-hernandez1993joint,
  title = {Joint {{Sequential Simulation}} of {{MultiGaussian Fields}}},
  booktitle = {Geostatistics {{Tr{\'o}ia}} '92: {{Volume}} 1},
  author = {{G{\'o}mez-Hern{\'a}ndez}, J. Jaime and Journel, Andr{\'e} G.},
  editor = {Soares, Amilcar},
  year = {1993},
  series = {Quantitative {{Geology}} and {{Geostatistics}}},
  pages = {85--94},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-011-1739-5_8},
  urldate = {2023-08-17},
  abstract = {The sequential simulation algorithm can be used for the generation of conditional realizations from either a multiGaussian random function or any non-Gaussian random function as long as its conditional distributions can be derived. The multivariate probability density function (pdf) that fully describes a random function can be written as the product of a set of univariate conditional pdfs. Drawing realizations from the multivariate pdf amounts to drawing sequentially from that series of univariate conditional pdfs. Similarly, the joint multivariate pdf of several random functions can be written as the product of a series of univariate conditional pdfs. The key step consists of the derivation of the conditional pdfs. In the case of a multiGaussian fields, these univariate conditional pdfs are known to be Gaussian with mean and variance given by the solution of a set of normal equations also known as simple cokriging equations. Sequential simulation is preferred to other techniques, such as turning bands, because of its ease of use and extreme flexibility.},
  isbn = {978-94-011-1739-5},
  langid = {english},
  keywords = {Conditional Distribution,Conditioning Data,Exponential Type,Search Neighborhood,Sequential Simulation},
  file = {D:\03 UofA\06 Reading\_zotfile\Gómez-Hernández_Journel\gomez-hernandez1993joint.pdf}
}

@article{goovaerts1992factorial,
  title = {Factorial Kriging Analysis: A Useful Tool for Exploring the Structure of Multivariate Spatial Soil Information},
  shorttitle = {Factorial Kriging Analysis},
  author = {Goovaerts, P.},
  year = {1992},
  journal = {Journal of Soil Science},
  volume = {43},
  number = {4},
  pages = {597--619},
  issn = {1365-2389},
  doi = {10.1111/j.1365-2389.1992.tb00163.x},
  urldate = {2021-10-16},
  abstract = {Most studies of relations between soil properties fail to take account of their regionalized nature because of the lack of appropriate methods. This paper describes a geostatistical technique, factorial kriging analysis, that bridges the gap between classical multivariate analysis and a univariate geostatistical approach. The basic feature of the method is the fitting of a linear model of coregionalization, i.e. all experimental simple and cross-variograms are modelled with a linear combination of basic variogram functions. A particular variance-covariance matrix, the coregionalization matrix, can then be associated with each spatial scale defined by the range of the basic variogram function. Each coregionalization matrix describes relationships between variables at a given spatial scale. A principal component analysis of these matrices produces a set of components, the regionalized factors, that reflect the main features of the multivariate information for each spatial scale and whose scores are estimated by cokriging. The technique is described and illustrated with three case studies based on a simulated data set and soil survey data. The results are compared with those of the principal component analysis of the variance-covariance matrix and the variogram matrices.},
  langid = {english},
  keywords = {thesis_05},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Goovaerts\\goovaerts1992factorial.pdf;C\:\\Users\\benha\\Zotero\\storage\\RI54W7CF\\j.1365-2389.1992.tb00163.html}
}

@article{hadavand2023spatial,
  title = {Spatial Multivariate Data Imputation Using Deep Learning and Lambda Distribution},
  author = {Hadavand, Mostafa and Deutsch, Clayton V.},
  year = {2023},
  month = aug,
  journal = {Computers \& Geosciences},
  volume = {177},
  pages = {105376},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2023.105376},
  urldate = {2024-02-14},
  abstract = {Artificial neural networks (ANNs) are often used to establish a mapping between an input data set and a corresponding output. There are many applications that rely on quantifying the conditional distribution of the output given the input data set. This is often referred to as aleatoric uncertainty associated with variability of the outcome due to inherently random effects. In this paper, deep learning is used to quantify moments of the conditional distribution of a missing variable based on homotopic multivariate observations. The lambda distribution is then used to parametrize the conditional distribution based on the provided moments. Geostatistical quantification of spatial continuity complements the multivariate conditional distribution through Bayesian updating to inform multiple data imputation that accounts for the uncertainty associated with the missing variable(s). Geological data are often incomplete, and data imputation is an essential step to avoid excluding heterotopic data. The proposed data imputation framework trains multi layer perceptron (MLP) neural networks to characterize multivariate relationships inferred from homotopic training data. A case study is conducted using geological data from a lateritic Nickle deposit to demonstrate application of the proposed methodology.},
  keywords = {Gaussian mixture model,Geostatistics,Simulation},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Hadavand_Deutsch\\hadavand2023spatial.pdf;C\:\\Users\\benha\\Zotero\\storage\\ZEKJPSLQ\\S0098300423000808.html}
}

@article{journel1974geostatistics,
  title = {Geostatistics for {{Conditional Simulation}} of {{Ore Bodies}}},
  author = {Journel, A. G.},
  year = {1974},
  month = aug,
  journal = {Economic Geology},
  volume = {69},
  number = {5},
  pages = {673--687},
  issn = {0361-0128},
  doi = {10.2113/gsecongeo.69.5.673},
  urldate = {2022-08-30},
  abstract = {Simulation techniques are frequently used to solve various problems of operational research for the mining industry and more generally in earth sciences (hydrogeology, gravimetry, meteorology, etc.). First, the model to be simulated is characterized; for example, the spatial dispersion of grades in an ore body. Then a simulation technique is devised, which must be operational, particularly in terms of computer time. The efficiency of the simulation produced is obviously linked to the capacity of the model to fit the main characteristics of the revealed reality. One of the most important of these characteristics, namely the spatial autocorrelation of variables, is often ignored by the models commonly presented in classical literature.The originality of conditional simulation derives: (1) from the fact that these simulations meet the particular spatial autocorrelation function (covariance or variogram) which characterizes the reality observed; (2) from the conditionalization of the experimental data, i.e., the simulated values at data locations equal the experimental values; and (3) from the possibility of working in real three-dimensional space. The simulation technique proposed (turning-bands method) consists of simulating on lines (one-dimensional space) and then turning these lines in three-dimensional space. This procedure avoids the well-known explosion of computer time and memories involved in classical procedures extended to several dimensions. The originality of using conditional simulation techniques with regard to spectral analysis techniques is presented in the third point.},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Journel\\journel1974geostatistics.pdf;C\:\\Users\\benha\\Zotero\\storage\\DGCFIMF5\\Geostatistics-for-Conditional-Simulation-of-Ore.html}
}

@article{journel1983nonparametric,
  title = {Nonparametric Estimation of Spatial Distributions},
  author = {Journel, A. G.},
  year = {1983},
  month = jun,
  journal = {Journal of the International Association for Mathematical Geology},
  volume = {15},
  number = {3},
  pages = {445--468},
  issn = {1573-8868},
  doi = {10.1007/BF01031292},
  urldate = {2021-10-22},
  abstract = {The indicator approach, whereby the data are used through their rank order, allows a nonparametric approach to the data bivariate distribution. Such rich structural information allows a nonparametric risk-qualified, estimation of local and global spatial distributions.},
  langid = {english},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Journel\journel1983nonparametric.pdf}
}

@inproceedings{lantuejoul2012simulation,
  title = {Simulation of a {{Gaussian}} Random Vector: A Propagative Version of the {{Gibbs}} Sampler},
  booktitle = {The 9th International Geostatistics Congress},
  author = {Lantu{\'e}joul, Christian and Desassis, Nicolas},
  year = {2012},
  pages = {174--181},
  file = {D:\03 UofA\06 Reading\_zotfile\Lantuéjoul_Desassis\lantuejoul2012simulation.pdf}
}

@article{lauzon2020calibration,
  title = {Calibration of Random Fields by a Sequential Spectral Turning Bands Method},
  author = {Lauzon, Dany and Marcotte, Denis},
  year = {2020},
  month = feb,
  journal = {Computers \& Geosciences},
  volume = {135},
  pages = {104390},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2019.104390},
  urldate = {2024-02-13},
  abstract = {A new algorithm for calibration of conditional realizations to measured or desired response functions is presented. The Sequential-Spectral Turning Bands Method (S-STBM) builds the field by choosing the phase of each new cosine function such that the observed field response functions become increasingly calibrated. The phase selection has little influence on the spatial correlation structure but can help to meet other objectives. Conditioning by kriging is used in the algorithm main loop to impose exact hard data reproduction. A first case study illustrates the performance of the algorithm for a cyclic and asymmetric field. S-STBM is shown to reproduce similarly or better the directional asymmetry than calibrated realizations obtained by FFTMA-SA. A training image (TI) with connected low values provides the second case study where the target is the reproduction of non-centered third-order spatial moments. A third case study shows the effectiveness of the S-STBM algorithm to calibrate a Gaussian field to tracer tests. Contrary to FFTMA-SA, S-STBM works on irregular grids. Its computational complexity of O(n) and small memory requirement makes it an attractive method for calibration.},
  keywords = {Conditional simulation,Constructive calibration,High-order statistics,Spectral turning bands},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Lauzon_Marcotte\\lauzon2020calibration.pdf;C\:\\Users\\benha\\Zotero\\storage\\WKMIAIZG\\S0098300419306752.html}
}

@article{lauzon2020sequential,
  title = {The Sequential Spectral Turning Band Simulator as an Alternative to {{Gibbs}} Sampler in Large Truncated- or Pluri- {{Gaussian}} Simulations},
  author = {Lauzon, Dany and Marcotte, Denis},
  year = {2020},
  month = nov,
  journal = {Stochastic Environmental Research and Risk Assessment},
  volume = {34},
  number = {11},
  pages = {1939--1951},
  issn = {1436-3259},
  doi = {10.1007/s00477-020-01850-9},
  urldate = {2024-02-13},
  abstract = {The Sequential Spectral Turning Bands Method (S-STBM) builds Gaussian random fields (GRF) calibrated to desired response functions. An interesting application of S-STBM concerns the simulation of GRF subject to inequality constraints. S-STBM works by choosing the phase of each cosine function of the STBM algorithm instead of perturbating nodes of the GRF many thousand times using conditional distributions as in Gibbs sampler. Each chosen phase increasingly constrains the nodes to the desired inequalities. A method based on the sequential Gaussian simulation is introduced to accelerate convergence at the end of the process. Examples shown compare S-STBM approach to Gibbs sampler. Orders of magnitude reduction in computation time is achieved with our spectral method. Furthermore, examples show that the phase selection has no significant influence on the spatial correlation. Our approach is easily generalized to pluriGaussian simulations. Compared to Gibbs sampler, S-STBM is not limited to small systems (no memory limitation) and its complexity of O(n) makes it an efficient tool to simulate large GRF subject to inequality constraints.},
  langid = {english},
  keywords = {Gibbs Sampler,Inequality constraints,PluriGaussian simulation,Sequential Gaussian simulation,Spectral simulation,Truncated Gaussian random field},
  file = {D:\03 UofA\06 Reading\_zotfile\Lauzon_Marcotte\lauzon2020sequential.pdf}
}

@article{lauzon2023joint,
  title = {Joint Hydrofacies-Hydraulic Conductivity Modeling Based on a Constructive Spectral Algorithm Constrained by Transient Head Data},
  author = {Lauzon, Dany and Marcotte, Denis},
  year = {2023},
  month = sep,
  journal = {Hydrogeology Journal},
  volume = {31},
  number = {6},
  pages = {1647--1664},
  issn = {1435-0157},
  doi = {10.1007/s10040-023-02638-1},
  urldate = {2024-02-15},
  abstract = {A constructive spectral method is presented to jointly calibrate hydrofacies and hydraulic conductivity to transient pressure heads. The method iteratively constructs Gaussian random fields to model the spatial correlation of hydraulic conductivity and hydrofacies using pluriGaussian simulation. Borehole conditioning is done quickly by replacing the slow Gibbs sampler method with an approach that is based on calibrating the underlying Gaussian fields that are subject to inequality constraints. Calibration to transient pressure heads is performed by shallow optimization of the phase vectors of the continuous spectral method. A parameterization technique makes it possible to reduce phase vector optimization from multivariate to univariate. The algorithm is tested on two-dimensional (2D) and 3D synthetic regional aquifers made of three hydrofacies. It reduced the objective function by one order of magnitude in one hundred iterations. The tests on the 2D aquifers indicated that the transient hydraulic heads alone cannot provide much information about hydrofacies. However, combining them with hydrofacies observations from boreholes results in improved hydrofacies identification compared to when only borehole data are used. Similar results were obtained in the 3D aquifer case, although the improvement in aquifer identification was less pronounced. The spectral method presented makes it possible to calibrate complex aquifers to transient heads using a limited number of calls to the flow simulator. Doing so helps to characterize sub-surface heterogeneity and assess the uncertainty and geological risks associated with groundwater flow.},
  langid = {english},
  keywords = {Data assimilation,Geostatistics,Inverse modeling,Parameter uncertainty assessment,Stochastic hydrogeology},
  file = {D:\03 UofA\06 Reading\_zotfile\Lauzon_Marcotte\lauzon2023joint.pdf}
}

@article{leuangthong2004minimum,
  title = {Minimum {{Acceptance Criteria}} for {{Geostatistical Realizations}}},
  author = {Leuangthong, Oy and McLennan, Jason A. and Deutsch, Clayton V.},
  year = {2004},
  month = sep,
  journal = {Natural Resources Research},
  volume = {13},
  number = {3},
  pages = {131--141},
  issn = {1573-8981},
  doi = {10.1023/B:NARR.0000046916.91703.bb},
  urldate = {2024-03-07},
  abstract = {Geostatistical simulation is being used increasingly for numerical modeling of natural phenomena. The development of simulation as an alternative to kriging is the result of improved characterization of heterogeneity and a model of joint uncertainty. The popularity of simulation has increased in both mining and petroleum industries. Simulation is widely available in commercial software. Many of these software packages, however, do not necessarily provide the tools for careful checking of the geostatistical realizations prior to their use in decision-making. Moreover, practitioners may not understand all that should be checked. There are some basic checks that should be performed on all geostatistical models. This paper identifies (1) the minimum criteria that should be met by all geostatistical simulation models, and (2) the checks required to verify that these minimum criteria are satisfied. All realizations should honor the input information including the geological interpretation, the data values at their locations, the data distribution, and the correlation structure, within ``acceptable'' statistical fluctuations. Moreover, the uncertainty measured by the differences between simulated realizations should be a reasonable measure of uncertainty. A number of different applications are shown to illustrate the various checks. These checks should be an integral part of any simulation modeling work flow.},
  langid = {english},
  keywords = {Model validation,simulation,verification},
  file = {D:\03 UofA\06 Reading\_zotfile\Leuangthong et al\leuangthong2004minimum.pdf}
}

@article{leuangthong2015dealinga,
  title = {Dealing with High-Grade Data in Resource Estimation},
  author = {Leuangthong, O. and Nowak, M.},
  year = {2015},
  journal = {Journal of the Southern African Institute of Mining and Metallurgy},
  volume = {115},
  number = {1},
  pages = {27--36},
  publisher = {{The Southern African Institute of Mining and Metallurgy}},
  keywords = {thesis_02},
  file = {D\:\\03 UofA\\04 Research\\02 PhD\\_zotfile\\Leuangthong_Nowak\\leuangthong2015dealing.pdf;C\:\\Users\\benha\\Zotero\\storage\\MIJ9JM8Z\\scielo.html}
}

@book{little2002statistical,
  title = {Statistical {{Analysis}} with {{Missing Data}}},
  author = {Little, Roderick J. A. and Rubin, Donald B.},
  year = {2002},
  edition = {1},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781119013563},
  urldate = {2023-08-14},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Little_Rubin\\little2002statistical.pdf;C\:\\Users\\benha\\Zotero\\storage\\T5FRK54J\\9781119013563.html}
}

@book{little2019statistical,
  title = {Statistical Analysis with Missing Data},
  author = {Roderick J. A. Little, Donald B. Rubin},
  year = {2019},
  series = {Wiley Series in Probability and Statistics},
  edition = {3},
  publisher = {Wiley},
  isbn = {0-470-52679-3 978-1-118-59601-2 978-1-118-59569-5 978-0-470-52679-8},
  file = {D:\03 UofA\06 Reading\_zotfile\Roderick J. A. Little\little2019statistical.pdf}
}

@article{madani2021enhanced,
  title = {Enhanced Conditional {{Co-Gibbs}} Sampling Algorithm for Data Imputation},
  author = {Madani, Nasser and Bazarbekov, Talgatbek},
  year = {2021},
  month = mar,
  journal = {Computers \& Geosciences},
  volume = {148},
  pages = {104655},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2020.104655},
  urldate = {2024-02-14},
  abstract = {The Gibbs sampler is an iterative algorithm for data imputation of a random vector at locations where values of the variable of interest are missing. In this algorithm, the simulated values converge to a Gaussian random vector distribution with zero mean and a given covariance matrix obtained by solving a simple kriging system through several iterations. In a bivariate dataset, if the principal variable for imputation depends on an auxiliary variable that is more abundant at the sample locations, this algorithm fails to produce the local and spatial cross-correlation structures. To overcome this impediment, a variant of the Gibbs sampler, the conditional Co-Gibbs sampler, has been proposed in this study, where simple kriging is replaced by three alternative cokriging paradigms: multicollocated cokriging, collocated cokriging, and homotopic cokriging. The algorithm was examined for an actual case study to statistically evaluate its performance. The results indicate that the conditional Co-Gibbs sampler with multicollocated cokriging outperformed the alternatives, including simple kriging where data imputation occurred as a consequence of ignoring the influence of the auxiliary variable, partially or totally. In addition, a computer software, provided as an open-source executable file, was used to implement the proposed algorithm for data imputation in bivariate cases.},
  keywords = {Algorithms,Data processing,Geology,Geostatistics,Spatial statistics},
  file = {D:\03 UofA\06 Reading\_zotfile\Madani_Bazarbekov\madani2021enhanced.pdf}
}

@techreport{matheron1982factorial,
  title = {Pour Une Analyse Krigeante Des Donn{\'e}es R{\'e}gionalis{\'e}es},
  author = {Matheron, Georges},
  year = {1982},
  number = {N-732},
  institution = {Ecole des Mines de Paris},
  urldate = {2021-10-28},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Matheron\matheron1982factorial.pdf}
}

@techreport{medgold2021,
  title = {{{PRELIMINARY ECONOMIC ASSESSMENT AND NI}} 43-101 {{TECHNICAL REPORT FOR THE MEDGOLD TLAMINO PROJECT LICENCES}}, {{SERBIA}}},
  author = {{Medgold Resources Corp.}},
  year = {2021},
  keywords = {thesis_02}
}

@misc{mullner2011modern,
  title = {Modern Hierarchical, Agglomerative Clustering Algorithms},
  author = {M{\"u}llner, Daniel},
  year = {2011},
  month = sep,
  number = {arXiv:1109.2378},
  eprint = {1109.2378},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-12-11},
  abstract = {This paper presents algorithms for hierarchical, agglomerative clustering which perform most efficiently in the general-purpose setup that is given in modern standard software. Requirements are: (1) the input data is given by pairwise dissimilarities between data points, but extensions to vector data are also discussed (2) the output is a "stepwise dendrogram", a data structure which is shared by all implementations in current standard software. We present algorithms (old and new) which perform clustering in this setting efficiently, both in an asymptotic worst-case analysis and from a practical point of view. The main contributions of this paper are: (1) We present a new algorithm which is suitable for any distance update scheme and performs significantly better than the existing algorithms. (2) We prove the correctness of two algorithms by Rohlf and Murtagh, which is necessary in each case for different reasons. (3) We give well-founded recommendations for the best current algorithms for the various agglomerative clustering schemes.},
  archiveprefix = {arxiv},
  keywords = {62H30,Computer Science - Data Structures and Algorithms,I.5.3,Statistics - Machine Learning,thesis_06},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Müllner\\mullner2011modern.pdf;C\:\\Users\\benha\\Zotero\\storage\\RBT9X7UZ\\1109.html}
}

@techreport{ngm2020,
  title = {{{TECHNICAL REPORT ON THE CARLIN COMPLEX}}, {{EUREKA AND ELKO COUNTIES}}, {{STATE OF NEVADA}}, {{USA}}},
  author = {{Nevada Gold Mines LLC}},
  year = {2020},
  keywords = {thesis_02}
}

@inproceedings{nowak2008generalized,
  title = {Generalized Binary Search},
  booktitle = {2008 46th {{Annual Allerton Conference}} on {{Communication}}, {{Control}}, and {{Computing}}},
  author = {Nowak, Robert},
  year = {2008},
  month = sep,
  pages = {568--574},
  doi = {10.1109/ALLERTON.2008.4797609},
  urldate = {2024-02-17},
  abstract = {This paper studies a generalization of the classic binary search problem of locating a desired value within a sorted list. The classic problem can be viewed as determining the correct one-dimensional, binary-valued threshold function from a finite class of such functions based on queries taking the form of point samples of the function. The classic problem is also equivalent to a simple binary encoding of the threshold location. This paper extends binary search to learning more general binary-valued functions. Specifically, if the set of target functions and queries satisfy certain geometrical relationships, then an algorithm, based on selecting a query that is maximally discriminating at each step, will determine the correct function in a number of steps that is logarithmic in the number of functions under consideration. Examples of classes satisfying the geometrical relationships include linear separators in multiple dimensions. Extensions to handle noise are also discussed. Possible applications include machine learning, channel coding, and sequential experimental design.},
  keywords = {Channel coding,Design for experiments,Feedback,Machine learning,Particle separators,Probability distribution,Sampling methods,Search problems,thesis_05,Uncertainty},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Nowak\\nowak2008generalized.pdf;C\:\\Users\\benha\\Zotero\\storage\\4QDUPKVN\\4797609.html}
}

@inproceedings{nowak2013suggestions,
  title = {Suggestions for Good Capping Practices from Historical Literature},
  booktitle = {Proceedings of the 23rd {{World Mining Congress}} 2013},
  author = {Nowak, M. and Leuangthong, O. and Srivastava, R. M.},
  year = {2013},
  publisher = {{Canadian Institute of Mining, Metallurgy and Petroleum Montreal}},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Nowak et al\nowak2013suggestions.pdf}
}

@techreport{osiko2020,
  title = {{{NI}} 43-101 Technical Report and Mineral Resource Estimate for the Cariboo Gold Project, British Columbia, Canada},
  author = {{Osisko Gold Royalties Ltd}},
  year = {2020},
  keywords = {thesis_02}
}

@article{parrish1997,
  title = {Geologist's Gordian Knot: {{To}} Cut or Not to Cut},
  author = {Parrish, I.S},
  year = {1997},
  journal = {Mining Engineering},
  volume = {49},
  pages = {45--49},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Parrish\parrish1997geologist.pdf}
}

@techreport{pasofino2020,
  title = {{{DUGBE GOLD PROJECT}}, {{LIBERIA NI}} 43-101 {{TECHNICAL REPORT}}},
  author = {{Pasofino Gold Ltd.}},
  year = {2020}
}

@techreport{pretium2020,
  title = {Technical Report on the Brucejack Gold Mine, Northwest British Columbia},
  author = {{Pretium Resources Inc.}},
  year = {2020},
  keywords = {thesis_02}
}

@article{qu2018geostatistical,
  title = {Geostatistical {{Simulation}} with a {{Trend Using Gaussian Mixture Models}}},
  author = {Qu, Jianan and Deutsch, Clayton V.},
  year = {2018},
  month = jul,
  journal = {Natural Resources Research},
  volume = {27},
  number = {3},
  pages = {347--363},
  issn = {1573-8981},
  doi = {10.1007/s11053-017-9354-3},
  urldate = {2022-09-20},
  abstract = {Geostatistics applies statistics to quantitatively describe geological sites and assess the uncertainty due to incomplete sampling. Strong assumptions are required regarding the location independence of statistical parameters to construct numerical models with geostatistical tools. Most geological data exhibit large-scale deterministic trends together with short-scale variations. Such location dependence violates the common geostatistical assumption of stationarity. The trend-like deterministic features should be modeled prior to conventional geostatistical prediction and accounted for in subsequent geostatistical calculations. The challenge of using a trend in geostatistical simulation algorithms for the continuous variable is the subject of this paper. A stepwise conditional transformation with a Gaussian mixture model is considered to provide a stable and artifact-free numerical model. The complex features of the regionalized variable in the presence of a trend are removed in the forward transformation and restored in the back transformation. The Gaussian mixture model provides a seamless bin-free approach to transformation. Data from a copper deposit were used as an example. These data show an apparent trend unsuitable for conventional geostatistical algorithms. The result shows that the proposed algorithm leads to improved geostatistical models.},
  langid = {english},
  keywords = {Non-stationary regionalized variable,Sequential Gaussian simulation,Stepwise conditional transformation},
  file = {D:\03 UofA\06 Reading\_zotfile\Qu_Deutsch\qu2018geostatistical.pdf}
}

@inproceedings{roscoe1996cutting,
  title = {Cutting Curves for Grade Estimation and Grade Control in Gold Mines},
  booktitle = {98th Annual General Meeting},
  author = {Roscoe, W.E},
  year = {1996},
  month = apr,
  publisher = {{Canadian Institute of Mining, Metallurgy and Petroleum}},
  keywords = {thesis_02},
  file = {D:\03 UofA\04 Research\02 PhD\_zotfile\Roscoe\roscoe1996cutting.pdf}
}

@book{rossi2013mineral,
  title = {Mineral Resource Estimation},
  author = {Rossi, Mario E. and Deutsch, Clayton V.},
  year = {2013},
  publisher = {Springer Science \& Business Media},
  file = {C:\Users\benha\Zotero\storage\V3SMKWS5\books.html}
}

@article{silva2017multiple,
  title = {Multiple Imputation Framework for Data Assignment in Truncated Pluri-{{Gaussian}} Simulation},
  author = {Silva, Diogo S. F. and Deutsch, Clayton V.},
  year = {2017},
  month = nov,
  journal = {Stochastic Environmental Research and Risk Assessment},
  volume = {31},
  number = {9},
  pages = {2251--2263},
  issn = {1436-3259},
  doi = {10.1007/s00477-016-1309-4},
  urldate = {2023-08-14},
  abstract = {Truncated pluri-Gaussian simulation (TPGS) is suitable for the simulation of categorical variables that show natural ordering as the TPGS technique can consider transition probabilities. The TPGS assumes that categorical variables are the result of the truncation of underlying latent variables. In practice, only the categorical variables are observed. This translates the practical application of TPGS into a missing data problem in which all latent variables are missing. Latent variables are required at data locations in order to condition categorical realizations to observed categorical data. The imputation of missing latent variables at data locations is often achieved by either assigning constant values or spatially simulating latent variables subject to categorical observations. Realizations of latent variables can be used to condition all model realizations. Using a single realization or a constant value to condition all realizations is the same as assuming that latent variables are known at the data locations and this assumption affects uncertainty near data locations. The techniques for imputation of latent variables in TPGS framework are investigated in this article and their impact on uncertainty of simulated categorical models and possible effects on factors affecting decision making are explored. It is shown that the use of single realization of latent variables leads to underestimation of uncertainty and overestimation of measured resources while the use constant values for latent variables may lead to considerable over or underestimation of measured resources. The results highlight the importance of multiple data imputation in the context of TPGS.},
  langid = {english},
  keywords = {Geomodeling,Geostatistics,Gibbs sampler,Missing data analysis,thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Silva_Deutsch\silva2017multiple.pdf}
}

@misc{silva2018enhanced,
  title = {Enhanced {{Geologic Modeling}} of {{Multiple Categorical Variables}}},
  author = {Silva, Diogo},
  year = 2018,
  journal = {ERA},
  doi = {10.7939/R30G3HD9R},
  urldate = {2023-08-15},
  abstract = {Widely spaced data sets from drilling are used in the mining and petroleum industries to model subsurface resources. These data sets have...},
  howpublished = {https://era.library.ualberta.ca/items/9ab8ab60-cb8f-4d7d-9551-3c602956b0ad},
  langid = {english},
  keywords = {thesis_05},
  file = {D:\03 UofA\06 Reading\_zotfile\Silva\silva2018enhanced.pdf}
}

@article{silva2018multivariate,
  title = {Multivariate Data Imputation Using {{Gaussian}} Mixture Models},
  author = {Silva, Diogo S. F. and Deutsch, Clayton V.},
  year = {2018},
  month = oct,
  journal = {Spatial Statistics},
  volume = {27},
  pages = {74--90},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2016.11.002},
  urldate = {2023-08-14},
  abstract = {Availability of high dimensional geological data has become common in the mining and petroleum industries. Data sets are often complex and require advanced multivariate geostatistical techniques. Multivariate data transformation is a common step of such advanced workflows and its application requires equally sampled (isotopic) data at all data locations. Samples with missing variables are common in geological data sets for many reasons. The missing data must be imputed (inferred) to permit the measured data to be used to their full extent. Imputation methods for geological data should address spatial structure and multivariate complexity. The published techniques that account for these considerations make strong assumptions regarding conditional distributions and are computationally demanding in presence of many data. A Gaussian mixture model fitted to the multivariate data is proposed in this paper to provide stability in fitting multivariate data and to significantly improve computational efficiency. The proposed approach is demonstrated using a lateritic Nickel data set. The proposed improvement is shown to decrease computational time by two orders of magnitude for the example while also consistently enhancing results in several performance tests.},
  keywords = {Geostatistics,Missing data analysis,Modeling,Semi-parametric,thesis_05},
  file = {D\:\\03 UofA\\06 Reading\\_zotfile\\Silva_Deutsch\\silva2018multivariate.pdf;C\:\\Users\\benha\\Zotero\\storage\\NMCSMPRH\\S2211675316301300.html}
}

@techreport{tristar2021,
  title = {Mineral Resource Update for the Castelo de Sonhos Gold Project, Par{\'a} State, Brazil},
  author = {{TriStar Gold Inc.}},
  year = {2021},
  keywords = {thesis_02}
}

@book{tukey1977exploratory,
  title = {Exploratory Data Analysis},
  author = {Tukey, John W and others},
  year = {1977},
  volume = {2},
  publisher = {Reading, MA},
  keywords = {thesis_02},
  file = {D:\03 UofA\06 Reading\_zotfile\Tukey_others\tukey1977exploratory.pdf}
}

@techreport{Wilde2007,
  type = {{{CCG}} Annual Report 9},
  title = {Wide Array Declustering for Representative Distributions ({{The Ultimate DECLUS Program}})},
  author = {Wilde, B. J},
  year = {2007},
  address = {Edmonton AB},
  institution = {University of Alberta},
  keywords = {CCG,thesis_06}
}
